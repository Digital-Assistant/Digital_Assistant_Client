/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/date-format/lib/index.js":
/*!***********************************************!*\
  !*** ./node_modules/date-format/lib/index.js ***!
  \***********************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction padWithZeros(vNumber, width) {\n  var numAsString = vNumber.toString();\n  while (numAsString.length < width) {\n    numAsString = \"0\" + numAsString;\n  }\n  return numAsString;\n}\n\nfunction addZero(vNumber) {\n  return padWithZeros(vNumber, 2);\n}\n\n/**\n * Formats the TimeOffset\n * Thanks to http://www.svendtofte.com/code/date_format/\n * @private\n */\nfunction offset(timezoneOffset) {\n  var os = Math.abs(timezoneOffset);\n  var h = String(Math.floor(os / 60));\n  var m = String(os % 60);\n  h = (\"0\" + h).slice(-2);\n  m = (\"0\" + m).slice(-2);\n  return timezoneOffset === 0 ? \"Z\" : (timezoneOffset < 0 ? \"+\" : \"-\") + h + \":\" + m;\n}\n\nfunction asString(format, date) {\n  if (typeof format !== \"string\") {\n    date = format;\n    format = module.exports.ISO8601_FORMAT;\n  }\n  if (!date) {\n    date = module.exports.now();\n  }\n\n  // Issue # 14 - Per ISO8601 standard, the time string should be local time\n  // with timezone info.\n  // See https://en.wikipedia.org/wiki/ISO_8601 section \"Time offsets from UTC\"\n\n  var vDay = addZero(date.getDate());\n  var vMonth = addZero(date.getMonth() + 1);\n  var vYearLong = addZero(date.getFullYear());\n  var vYearShort = addZero(vYearLong.substring(2, 4));\n  var vYear = format.indexOf(\"yyyy\") > -1 ? vYearLong : vYearShort;\n  var vHour = addZero(date.getHours());\n  var vMinute = addZero(date.getMinutes());\n  var vSecond = addZero(date.getSeconds());\n  var vMillisecond = padWithZeros(date.getMilliseconds(), 3);\n  var vTimeZone = offset(date.getTimezoneOffset());\n  var formatted = format\n    .replace(/dd/g, vDay)\n    .replace(/MM/g, vMonth)\n    .replace(/y{1,4}/g, vYear)\n    .replace(/hh/g, vHour)\n    .replace(/mm/g, vMinute)\n    .replace(/ss/g, vSecond)\n    .replace(/SSS/g, vMillisecond)\n    .replace(/O/g, vTimeZone);\n  return formatted;\n}\n\nfunction setDatePart(date, part, value, local) {\n  date['set' + (local ? '' : 'UTC') + part](value);\n}\n\nfunction extractDateParts(pattern, str, missingValuesDate) {\n  // Javascript Date object doesn't support custom timezone.  Sets all felds as\n  // GMT based to begin with.  If the timezone offset is provided, then adjust\n  // it using provided timezone, otherwise, adjust it with the system timezone.\n  var local = pattern.indexOf('O') < 0;\n  var monthOverflow = false;\n  var matchers = [\n    {\n      pattern: /y{1,4}/,\n      regexp: \"\\\\d{1,4}\",\n      fn: function(date, value) {\n        setDatePart(date, 'FullYear', value, local);\n      }\n    },\n    {\n      pattern: /MM/,\n      regexp: \"\\\\d{1,2}\",\n      fn: function(date, value) {\n        setDatePart(date, 'Month', (value - 1), local);\n        if (date.getMonth() !== (value - 1)) {\n          // in the event of 31 May --> 31 Feb --> 3 Mar\n          // this is correct behavior if no Date is involved\n          monthOverflow = true;\n        }\n      }\n    },\n    {\n      pattern: /dd/,\n      regexp: \"\\\\d{1,2}\",\n      fn: function(date, value) {\n        // in the event of 31 May --> 31 Feb --> 3 Mar\n        // reset Mar back to Feb, before setting the Date\n        if (monthOverflow) {\n          setDatePart(date, 'Month', (date.getMonth() - 1), local);\n        }\n        setDatePart(date, 'Date', value, local);\n      }\n    },\n    {\n      pattern: /hh/,\n      regexp: \"\\\\d{1,2}\",\n      fn: function(date, value) {\n        setDatePart(date, 'Hours', value, local);\n      }\n    },\n    {\n      pattern: /mm/,\n      regexp: \"\\\\d\\\\d\",\n      fn: function(date, value) {\n        setDatePart(date, 'Minutes', value, local);\n      }\n    },\n    {\n      pattern: /ss/,\n      regexp: \"\\\\d\\\\d\",\n      fn: function(date, value) {\n        setDatePart(date, 'Seconds', value, local);\n      }\n    },\n    {\n      pattern: /SSS/,\n      regexp: \"\\\\d\\\\d\\\\d\",\n      fn: function(date, value) {\n        setDatePart(date, 'Milliseconds', value, local);\n      }\n    },\n    {\n      pattern: /O/,\n      regexp: \"[+-]\\\\d{1,2}:?\\\\d{2}?|Z\",\n      fn: function(date, value) {\n        if (value === \"Z\") {\n          value = 0;\n        }\n        else {\n          value = value.replace(\":\", \"\");\n        }\n        var offset = Math.abs(value);\n        var timezoneOffset = (value > 0 ? -1 :  1 ) * ((offset % 100) + Math.floor(offset / 100) * 60);\n        // Per ISO8601 standard: UTC = local time - offset\n        //\n        // For example, 2000-01-01T01:00:00-0700\n        //   local time: 2000-01-01T01:00:00\n        //   ==> UTC   : 2000-01-01T08:00:00 ( 01 - (-7) = 8 )\n        //\n        // To make it even more confusing, the date.getTimezoneOffset() is\n        // opposite sign of offset string in the ISO8601 standard.  So if offset\n        // is '-0700' the getTimezoneOffset() would be (+)420. The line above\n        // calculates timezoneOffset to matche Javascript's behavior.\n        //\n        // The date/time of the input is actually the local time, so the date\n        // object that was constructed is actually local time even thought the\n        // UTC setters are used.  This means the date object's internal UTC\n        // representation was wrong.  It needs to be fixed by substracting the\n        // offset (or adding the offset minutes as they are opposite sign).\n        //\n        // Note: the time zone has to be processed after all other fields are\n        // set.  The result would be incorrect if the offset was calculated\n        // first then overriden by the other filed setters.\n        date.setUTCMinutes(date.getUTCMinutes() + timezoneOffset);\n      }\n    }\n  ];\n\n  var parsedPattern = matchers.reduce(\n    function(p, m) {\n      if (m.pattern.test(p.regexp)) {\n        m.index = p.regexp.match(m.pattern).index;\n        p.regexp = p.regexp.replace(m.pattern, \"(\" + m.regexp + \")\");\n      } else {\n        m.index = -1;\n      }\n      return p;\n    },\n    { regexp: pattern, index: [] }\n  );\n\n  var dateFns = matchers.filter(function(m) {\n    return m.index > -1;\n  });\n  dateFns.sort(function(a, b) {\n    return a.index - b.index;\n  });\n\n  var matcher = new RegExp(parsedPattern.regexp);\n  var matches = matcher.exec(str);\n  if (matches) {\n    var date = missingValuesDate || module.exports.now();\n    dateFns.forEach(function(f, i) {\n      f.fn(date, matches[i + 1]);\n    });\n\n    return date;\n  }\n\n  throw new Error(\n    \"String '\" + str + \"' could not be parsed as '\" + pattern + \"'\"\n  );\n}\n\nfunction parse(pattern, str, missingValuesDate) {\n  if (!pattern) {\n    throw new Error(\"pattern must be supplied\");\n  }\n\n  return extractDateParts(pattern, str, missingValuesDate);\n}\n\n/**\n * Used for testing - replace this function with a fixed date.\n */\nfunction now() {\n  return new Date();\n}\n\nmodule.exports = asString;\nmodule.exports.asString = asString;\nmodule.exports.parse = parse;\nmodule.exports.now = now;\nmodule.exports.ISO8601_FORMAT = \"yyyy-MM-ddThh:mm:ss.SSS\";\nmodule.exports.ISO8601_WITH_TZ_OFFSET_FORMAT = \"yyyy-MM-ddThh:mm:ss.SSSO\";\nmodule.exports.DATETIME_FORMAT = \"dd MM yyyy hh:mm:ss.SSS\";\nmodule.exports.ABSOLUTETIME_FORMAT = \"hh:mm:ss.SSS\";\n\n\n//# sourceURL=webpack://udan-react/./node_modules/date-format/lib/index.js?");

/***/ }),

/***/ "./node_modules/debug/src/browser.js":
/*!*******************************************!*\
  !*** ./node_modules/debug/src/browser.js ***!
  \*******************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* eslint-env browser */\n\n/**\n * This is the web browser implementation of `debug()`.\n */\n\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = localstorage();\nexports.destroy = (() => {\n\tlet warned = false;\n\n\treturn () => {\n\t\tif (!warned) {\n\t\t\twarned = true;\n\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t}\n\t};\n})();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n\t'#0000CC',\n\t'#0000FF',\n\t'#0033CC',\n\t'#0033FF',\n\t'#0066CC',\n\t'#0066FF',\n\t'#0099CC',\n\t'#0099FF',\n\t'#00CC00',\n\t'#00CC33',\n\t'#00CC66',\n\t'#00CC99',\n\t'#00CCCC',\n\t'#00CCFF',\n\t'#3300CC',\n\t'#3300FF',\n\t'#3333CC',\n\t'#3333FF',\n\t'#3366CC',\n\t'#3366FF',\n\t'#3399CC',\n\t'#3399FF',\n\t'#33CC00',\n\t'#33CC33',\n\t'#33CC66',\n\t'#33CC99',\n\t'#33CCCC',\n\t'#33CCFF',\n\t'#6600CC',\n\t'#6600FF',\n\t'#6633CC',\n\t'#6633FF',\n\t'#66CC00',\n\t'#66CC33',\n\t'#9900CC',\n\t'#9900FF',\n\t'#9933CC',\n\t'#9933FF',\n\t'#99CC00',\n\t'#99CC33',\n\t'#CC0000',\n\t'#CC0033',\n\t'#CC0066',\n\t'#CC0099',\n\t'#CC00CC',\n\t'#CC00FF',\n\t'#CC3300',\n\t'#CC3333',\n\t'#CC3366',\n\t'#CC3399',\n\t'#CC33CC',\n\t'#CC33FF',\n\t'#CC6600',\n\t'#CC6633',\n\t'#CC9900',\n\t'#CC9933',\n\t'#CCCC00',\n\t'#CCCC33',\n\t'#FF0000',\n\t'#FF0033',\n\t'#FF0066',\n\t'#FF0099',\n\t'#FF00CC',\n\t'#FF00FF',\n\t'#FF3300',\n\t'#FF3333',\n\t'#FF3366',\n\t'#FF3399',\n\t'#FF33CC',\n\t'#FF33FF',\n\t'#FF6600',\n\t'#FF6633',\n\t'#FF9900',\n\t'#FF9933',\n\t'#FFCC00',\n\t'#FFCC33'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\n// eslint-disable-next-line complexity\nfunction useColors() {\n\t// NB: In an Electron preload script, document will be defined but not fully\n\t// initialized. Since we know we're in Chrome, we'll just detect this case\n\t// explicitly\n\tif (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n\t\treturn true;\n\t}\n\n\t// Internet Explorer and Edge do not support colors.\n\tif (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\treturn false;\n\t}\n\n\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\treturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t// Is firefox >= v31?\n\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\targs[0] = (this.useColors ? '%c' : '') +\n\t\tthis.namespace +\n\t\t(this.useColors ? ' %c' : ' ') +\n\t\targs[0] +\n\t\t(this.useColors ? '%c ' : ' ') +\n\t\t'+' + module.exports.humanize(this.diff);\n\n\tif (!this.useColors) {\n\t\treturn;\n\t}\n\n\tconst c = 'color: ' + this.color;\n\targs.splice(1, 0, c, 'color: inherit');\n\n\t// The final \"%c\" is somewhat tricky, because there could be other\n\t// arguments passed either before or after the %c, so we need to\n\t// figure out the correct index to insert the CSS into\n\tlet index = 0;\n\tlet lastC = 0;\n\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\tif (match === '%%') {\n\t\t\treturn;\n\t\t}\n\t\tindex++;\n\t\tif (match === '%c') {\n\t\t\t// We only are interested in the *last* %c\n\t\t\t// (the user may have provided their own)\n\t\t\tlastC = index;\n\t\t}\n\t});\n\n\targs.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.debug()` when available.\n * No-op when `console.debug` is not a \"function\".\n * If `console.debug` is not available, falls back\n * to `console.log`.\n *\n * @api public\n */\nexports.log = console.debug || console.log || (() => {});\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\ttry {\n\t\tif (namespaces) {\n\t\t\texports.storage.setItem('debug', namespaces);\n\t\t} else {\n\t\t\texports.storage.removeItem('debug');\n\t\t}\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\nfunction load() {\n\tlet r;\n\ttry {\n\t\tr = exports.storage.getItem('debug');\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n\n\t// If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\tif (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\tr = process.env.DEBUG;\n\t}\n\n\treturn r;\n}\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n\ttry {\n\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t// The Browser also has localStorage in the global context.\n\t\treturn localStorage;\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ \"./node_modules/debug/src/common.js\")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nformatters.j = function (v) {\n\ttry {\n\t\treturn JSON.stringify(v);\n\t} catch (error) {\n\t\treturn '[UnexpectedJSONParseError]: ' + error.message;\n\t}\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/debug/src/browser.js?");

/***/ }),

/***/ "./node_modules/debug/src/common.js":
/*!******************************************!*\
  !*** ./node_modules/debug/src/common.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n */\n\nfunction setup(env) {\n\tcreateDebug.debug = createDebug;\n\tcreateDebug.default = createDebug;\n\tcreateDebug.coerce = coerce;\n\tcreateDebug.disable = disable;\n\tcreateDebug.enable = enable;\n\tcreateDebug.enabled = enabled;\n\tcreateDebug.humanize = __webpack_require__(/*! ms */ \"./node_modules/ms/index.js\");\n\tcreateDebug.destroy = destroy;\n\n\tObject.keys(env).forEach(key => {\n\t\tcreateDebug[key] = env[key];\n\t});\n\n\t/**\n\t* The currently active debug mode names, and names to skip.\n\t*/\n\n\tcreateDebug.names = [];\n\tcreateDebug.skips = [];\n\n\t/**\n\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t*\n\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t*/\n\tcreateDebug.formatters = {};\n\n\t/**\n\t* Selects a color for a debug namespace\n\t* @param {String} namespace The namespace string for the debug instance to be colored\n\t* @return {Number|String} An ANSI color code for the given namespace\n\t* @api private\n\t*/\n\tfunction selectColor(namespace) {\n\t\tlet hash = 0;\n\n\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\thash |= 0; // Convert to 32bit integer\n\t\t}\n\n\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t}\n\tcreateDebug.selectColor = selectColor;\n\n\t/**\n\t* Create a debugger with the given `namespace`.\n\t*\n\t* @param {String} namespace\n\t* @return {Function}\n\t* @api public\n\t*/\n\tfunction createDebug(namespace) {\n\t\tlet prevTime;\n\t\tlet enableOverride = null;\n\t\tlet namespacesCache;\n\t\tlet enabledCache;\n\n\t\tfunction debug(...args) {\n\t\t\t// Disabled?\n\t\t\tif (!debug.enabled) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst self = debug;\n\n\t\t\t// Set `diff` timestamp\n\t\t\tconst curr = Number(new Date());\n\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\tself.diff = ms;\n\t\t\tself.prev = prevTime;\n\t\t\tself.curr = curr;\n\t\t\tprevTime = curr;\n\n\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\targs.unshift('%O');\n\t\t\t}\n\n\t\t\t// Apply any `formatters` transformations\n\t\t\tlet index = 0;\n\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn '%';\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\tconst val = args[index];\n\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\tindex--;\n\t\t\t\t}\n\t\t\t\treturn match;\n\t\t\t});\n\n\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\tlogFn.apply(self, args);\n\t\t}\n\n\t\tdebug.namespace = namespace;\n\t\tdebug.useColors = createDebug.useColors();\n\t\tdebug.color = createDebug.selectColor(namespace);\n\t\tdebug.extend = extend;\n\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\tenumerable: true,\n\t\t\tconfigurable: false,\n\t\t\tget: () => {\n\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\treturn enableOverride;\n\t\t\t\t}\n\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t}\n\n\t\t\t\treturn enabledCache;\n\t\t\t},\n\t\t\tset: v => {\n\t\t\t\tenableOverride = v;\n\t\t\t}\n\t\t});\n\n\t\t// Env-specific initialization logic for debug instances\n\t\tif (typeof createDebug.init === 'function') {\n\t\t\tcreateDebug.init(debug);\n\t\t}\n\n\t\treturn debug;\n\t}\n\n\tfunction extend(namespace, delimiter) {\n\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\tnewDebug.log = this.log;\n\t\treturn newDebug;\n\t}\n\n\t/**\n\t* Enables a debug mode by namespaces. This can include modes\n\t* separated by a colon and wildcards.\n\t*\n\t* @param {String} namespaces\n\t* @api public\n\t*/\n\tfunction enable(namespaces) {\n\t\tcreateDebug.save(namespaces);\n\t\tcreateDebug.namespaces = namespaces;\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\tlet i;\n\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\tconst len = split.length;\n\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tif (!split[i]) {\n\t\t\t\t// ignore empty strings\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\tif (namespaces[0] === '-') {\n\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));\n\t\t\t} else {\n\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t* Disable debug output.\n\t*\n\t* @return {String} namespaces\n\t* @api public\n\t*/\n\tfunction disable() {\n\t\tconst namespaces = [\n\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t].join(',');\n\t\tcreateDebug.enable('');\n\t\treturn namespaces;\n\t}\n\n\t/**\n\t* Returns true if the given mode name is enabled, false otherwise.\n\t*\n\t* @param {String} name\n\t* @return {Boolean}\n\t* @api public\n\t*/\n\tfunction enabled(name) {\n\t\tif (name[name.length - 1] === '*') {\n\t\t\treturn true;\n\t\t}\n\n\t\tlet i;\n\t\tlet len;\n\n\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t/**\n\t* Convert regexp to namespace\n\t*\n\t* @param {RegExp} regxep\n\t* @return {String} namespace\n\t* @api private\n\t*/\n\tfunction toNamespace(regexp) {\n\t\treturn regexp.toString()\n\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t}\n\n\t/**\n\t* Coerce `val`.\n\t*\n\t* @param {Mixed} val\n\t* @return {Mixed}\n\t* @api private\n\t*/\n\tfunction coerce(val) {\n\t\tif (val instanceof Error) {\n\t\t\treturn val.stack || val.message;\n\t\t}\n\t\treturn val;\n\t}\n\n\t/**\n\t* XXX DO NOT USE. This is a temporary stub function.\n\t* XXX It WILL be removed in the next major release.\n\t*/\n\tfunction destroy() {\n\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t}\n\n\tcreateDebug.enable(createDebug.load());\n\n\treturn createDebug;\n}\n\nmodule.exports = setup;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/debug/src/common.js?");

/***/ }),

/***/ "./node_modules/debug/src/index.js":
/*!*****************************************!*\
  !*** ./node_modules/debug/src/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/**\n * Detect Electron renderer / nwjs process, which is node, but we should\n * treat as a browser.\n */\n\nif (typeof process === 'undefined' || process.type === 'renderer' || process.browser === true || process.__nwjs) {\n\tmodule.exports = __webpack_require__(/*! ./browser.js */ \"./node_modules/debug/src/browser.js\");\n} else {\n\tmodule.exports = __webpack_require__(/*! ./node.js */ \"./node_modules/debug/src/node.js\");\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/debug/src/index.js?");

/***/ }),

/***/ "./node_modules/debug/src/node.js":
/*!****************************************!*\
  !*** ./node_modules/debug/src/node.js ***!
  \****************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/**\n * Module dependencies.\n */\n\nconst tty = __webpack_require__(/*! tty */ \"tty\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\n/**\n * This is the Node.js implementation of `debug()`.\n */\n\nexports.init = init;\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.destroy = util.deprecate(\n\t() => {},\n\t'Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.'\n);\n\n/**\n * Colors.\n */\n\nexports.colors = [6, 2, 3, 4, 5, 1];\n\ntry {\n\t// Optional dependency (as in, doesn't need to be installed, NOT like optionalDependencies in package.json)\n\t// eslint-disable-next-line import/no-extraneous-dependencies\n\tconst supportsColor = __webpack_require__(/*! supports-color */ \"./node_modules/supports-color/index.js\");\n\n\tif (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {\n\t\texports.colors = [\n\t\t\t20,\n\t\t\t21,\n\t\t\t26,\n\t\t\t27,\n\t\t\t32,\n\t\t\t33,\n\t\t\t38,\n\t\t\t39,\n\t\t\t40,\n\t\t\t41,\n\t\t\t42,\n\t\t\t43,\n\t\t\t44,\n\t\t\t45,\n\t\t\t56,\n\t\t\t57,\n\t\t\t62,\n\t\t\t63,\n\t\t\t68,\n\t\t\t69,\n\t\t\t74,\n\t\t\t75,\n\t\t\t76,\n\t\t\t77,\n\t\t\t78,\n\t\t\t79,\n\t\t\t80,\n\t\t\t81,\n\t\t\t92,\n\t\t\t93,\n\t\t\t98,\n\t\t\t99,\n\t\t\t112,\n\t\t\t113,\n\t\t\t128,\n\t\t\t129,\n\t\t\t134,\n\t\t\t135,\n\t\t\t148,\n\t\t\t149,\n\t\t\t160,\n\t\t\t161,\n\t\t\t162,\n\t\t\t163,\n\t\t\t164,\n\t\t\t165,\n\t\t\t166,\n\t\t\t167,\n\t\t\t168,\n\t\t\t169,\n\t\t\t170,\n\t\t\t171,\n\t\t\t172,\n\t\t\t173,\n\t\t\t178,\n\t\t\t179,\n\t\t\t184,\n\t\t\t185,\n\t\t\t196,\n\t\t\t197,\n\t\t\t198,\n\t\t\t199,\n\t\t\t200,\n\t\t\t201,\n\t\t\t202,\n\t\t\t203,\n\t\t\t204,\n\t\t\t205,\n\t\t\t206,\n\t\t\t207,\n\t\t\t208,\n\t\t\t209,\n\t\t\t214,\n\t\t\t215,\n\t\t\t220,\n\t\t\t221\n\t\t];\n\t}\n} catch (error) {\n\t// Swallow - we only care if `supports-color` is available; it doesn't have to be.\n}\n\n/**\n * Build up the default `inspectOpts` object from the environment variables.\n *\n *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js\n */\n\nexports.inspectOpts = Object.keys(process.env).filter(key => {\n\treturn /^debug_/i.test(key);\n}).reduce((obj, key) => {\n\t// Camel-case\n\tconst prop = key\n\t\t.substring(6)\n\t\t.toLowerCase()\n\t\t.replace(/_([a-z])/g, (_, k) => {\n\t\t\treturn k.toUpperCase();\n\t\t});\n\n\t// Coerce string value into JS value\n\tlet val = process.env[key];\n\tif (/^(yes|on|true|enabled)$/i.test(val)) {\n\t\tval = true;\n\t} else if (/^(no|off|false|disabled)$/i.test(val)) {\n\t\tval = false;\n\t} else if (val === 'null') {\n\t\tval = null;\n\t} else {\n\t\tval = Number(val);\n\t}\n\n\tobj[prop] = val;\n\treturn obj;\n}, {});\n\n/**\n * Is stdout a TTY? Colored output is enabled when `true`.\n */\n\nfunction useColors() {\n\treturn 'colors' in exports.inspectOpts ?\n\t\tBoolean(exports.inspectOpts.colors) :\n\t\ttty.isatty(process.stderr.fd);\n}\n\n/**\n * Adds ANSI color escape codes if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\tconst {namespace: name, useColors} = this;\n\n\tif (useColors) {\n\t\tconst c = this.color;\n\t\tconst colorCode = '\\u001B[3' + (c < 8 ? c : '8;5;' + c);\n\t\tconst prefix = `  ${colorCode};1m${name} \\u001B[0m`;\n\n\t\targs[0] = prefix + args[0].split('\\n').join('\\n' + prefix);\n\t\targs.push(colorCode + 'm+' + module.exports.humanize(this.diff) + '\\u001B[0m');\n\t} else {\n\t\targs[0] = getDate() + name + ' ' + args[0];\n\t}\n}\n\nfunction getDate() {\n\tif (exports.inspectOpts.hideDate) {\n\t\treturn '';\n\t}\n\treturn new Date().toISOString() + ' ';\n}\n\n/**\n * Invokes `util.format()` with the specified arguments and writes to stderr.\n */\n\nfunction log(...args) {\n\treturn process.stderr.write(util.format(...args) + '\\n');\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\tif (namespaces) {\n\t\tprocess.env.DEBUG = namespaces;\n\t} else {\n\t\t// If you set a process.env field to null or undefined, it gets cast to the\n\t\t// string 'null' or 'undefined'. Just delete instead.\n\t\tdelete process.env.DEBUG;\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n\treturn process.env.DEBUG;\n}\n\n/**\n * Init logic for `debug` instances.\n *\n * Create a new `inspectOpts` object in case `useColors` is set\n * differently for a particular `debug` instance.\n */\n\nfunction init(debug) {\n\tdebug.inspectOpts = {};\n\n\tconst keys = Object.keys(exports.inspectOpts);\n\tfor (let i = 0; i < keys.length; i++) {\n\t\tdebug.inspectOpts[keys[i]] = exports.inspectOpts[keys[i]];\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ \"./node_modules/debug/src/common.js\")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %o to `util.inspect()`, all on a single line.\n */\n\nformatters.o = function (v) {\n\tthis.inspectOpts.colors = this.useColors;\n\treturn util.inspect(v, this.inspectOpts)\n\t\t.split('\\n')\n\t\t.map(str => str.trim())\n\t\t.join(' ');\n};\n\n/**\n * Map %O to `util.inspect()`, allowing multiple lines if needed.\n */\n\nformatters.O = function (v) {\n\tthis.inspectOpts.colors = this.useColors;\n\treturn util.inspect(v, this.inspectOpts);\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/debug/src/node.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/copy/copy-sync.js":
/*!*****************************************************!*\
  !*** ./node_modules/fs-extra/lib/copy/copy-sync.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdirsSync = (__webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\").mkdirsSync)\nconst utimesMillisSync = (__webpack_require__(/*! ../util/utimes */ \"./node_modules/fs-extra/lib/util/utimes.js\").utimesMillisSync)\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/fs-extra/lib/util/stat.js\")\n\nfunction copySync (src, dest, opts) {\n  if (typeof opts === 'function') {\n    opts = { filter: opts }\n  }\n\n  opts = opts || {}\n  opts.clobber = 'clobber' in opts ? !!opts.clobber : true // default to true for now\n  opts.overwrite = 'overwrite' in opts ? !!opts.overwrite : opts.clobber // overwrite falls back to clobber\n\n  // Warn about using preserveTimestamps on 32-bit node\n  if (opts.preserveTimestamps && process.arch === 'ia32') {\n    process.emitWarning(\n      'Using the preserveTimestamps option in 32-bit node is not recommended;\\n\\n' +\n      '\\tsee https://github.com/jprichardson/node-fs-extra/issues/269',\n      'Warning', 'fs-extra-WARN0002'\n    )\n  }\n\n  const { srcStat, destStat } = stat.checkPathsSync(src, dest, 'copy', opts)\n  stat.checkParentPathsSync(src, srcStat, dest, 'copy')\n  return handleFilterAndCopy(destStat, src, dest, opts)\n}\n\nfunction handleFilterAndCopy (destStat, src, dest, opts) {\n  if (opts.filter && !opts.filter(src, dest)) return\n  const destParent = path.dirname(dest)\n  if (!fs.existsSync(destParent)) mkdirsSync(destParent)\n  return getStats(destStat, src, dest, opts)\n}\n\nfunction startCopy (destStat, src, dest, opts) {\n  if (opts.filter && !opts.filter(src, dest)) return\n  return getStats(destStat, src, dest, opts)\n}\n\nfunction getStats (destStat, src, dest, opts) {\n  const statSync = opts.dereference ? fs.statSync : fs.lstatSync\n  const srcStat = statSync(src)\n\n  if (srcStat.isDirectory()) return onDir(srcStat, destStat, src, dest, opts)\n  else if (srcStat.isFile() ||\n           srcStat.isCharacterDevice() ||\n           srcStat.isBlockDevice()) return onFile(srcStat, destStat, src, dest, opts)\n  else if (srcStat.isSymbolicLink()) return onLink(destStat, src, dest, opts)\n  else if (srcStat.isSocket()) throw new Error(`Cannot copy a socket file: ${src}`)\n  else if (srcStat.isFIFO()) throw new Error(`Cannot copy a FIFO pipe: ${src}`)\n  throw new Error(`Unknown file: ${src}`)\n}\n\nfunction onFile (srcStat, destStat, src, dest, opts) {\n  if (!destStat) return copyFile(srcStat, src, dest, opts)\n  return mayCopyFile(srcStat, src, dest, opts)\n}\n\nfunction mayCopyFile (srcStat, src, dest, opts) {\n  if (opts.overwrite) {\n    fs.unlinkSync(dest)\n    return copyFile(srcStat, src, dest, opts)\n  } else if (opts.errorOnExist) {\n    throw new Error(`'${dest}' already exists`)\n  }\n}\n\nfunction copyFile (srcStat, src, dest, opts) {\n  fs.copyFileSync(src, dest)\n  if (opts.preserveTimestamps) handleTimestamps(srcStat.mode, src, dest)\n  return setDestMode(dest, srcStat.mode)\n}\n\nfunction handleTimestamps (srcMode, src, dest) {\n  // Make sure the file is writable before setting the timestamp\n  // otherwise open fails with EPERM when invoked with 'r+'\n  // (through utimes call)\n  if (fileIsNotWritable(srcMode)) makeFileWritable(dest, srcMode)\n  return setDestTimestamps(src, dest)\n}\n\nfunction fileIsNotWritable (srcMode) {\n  return (srcMode & 0o200) === 0\n}\n\nfunction makeFileWritable (dest, srcMode) {\n  return setDestMode(dest, srcMode | 0o200)\n}\n\nfunction setDestMode (dest, srcMode) {\n  return fs.chmodSync(dest, srcMode)\n}\n\nfunction setDestTimestamps (src, dest) {\n  // The initial srcStat.atime cannot be trusted\n  // because it is modified by the read(2) system call\n  // (See https://nodejs.org/api/fs.html#fs_stat_time_values)\n  const updatedSrcStat = fs.statSync(src)\n  return utimesMillisSync(dest, updatedSrcStat.atime, updatedSrcStat.mtime)\n}\n\nfunction onDir (srcStat, destStat, src, dest, opts) {\n  if (!destStat) return mkDirAndCopy(srcStat.mode, src, dest, opts)\n  return copyDir(src, dest, opts)\n}\n\nfunction mkDirAndCopy (srcMode, src, dest, opts) {\n  fs.mkdirSync(dest)\n  copyDir(src, dest, opts)\n  return setDestMode(dest, srcMode)\n}\n\nfunction copyDir (src, dest, opts) {\n  fs.readdirSync(src).forEach(item => copyDirItem(item, src, dest, opts))\n}\n\nfunction copyDirItem (item, src, dest, opts) {\n  const srcItem = path.join(src, item)\n  const destItem = path.join(dest, item)\n  const { destStat } = stat.checkPathsSync(srcItem, destItem, 'copy', opts)\n  return startCopy(destStat, srcItem, destItem, opts)\n}\n\nfunction onLink (destStat, src, dest, opts) {\n  let resolvedSrc = fs.readlinkSync(src)\n  if (opts.dereference) {\n    resolvedSrc = path.resolve(process.cwd(), resolvedSrc)\n  }\n\n  if (!destStat) {\n    return fs.symlinkSync(resolvedSrc, dest)\n  } else {\n    let resolvedDest\n    try {\n      resolvedDest = fs.readlinkSync(dest)\n    } catch (err) {\n      // dest exists and is a regular file or directory,\n      // Windows may throw UNKNOWN error. If dest already exists,\n      // fs throws error anyway, so no need to guard against it here.\n      if (err.code === 'EINVAL' || err.code === 'UNKNOWN') return fs.symlinkSync(resolvedSrc, dest)\n      throw err\n    }\n    if (opts.dereference) {\n      resolvedDest = path.resolve(process.cwd(), resolvedDest)\n    }\n    if (stat.isSrcSubdir(resolvedSrc, resolvedDest)) {\n      throw new Error(`Cannot copy '${resolvedSrc}' to a subdirectory of itself, '${resolvedDest}'.`)\n    }\n\n    // prevent copy if src is a subdir of dest since unlinking\n    // dest in this case would result in removing src contents\n    // and therefore a broken symlink would be created.\n    if (fs.statSync(dest).isDirectory() && stat.isSrcSubdir(resolvedDest, resolvedSrc)) {\n      throw new Error(`Cannot overwrite '${resolvedDest}' with '${resolvedSrc}'.`)\n    }\n    return copyLink(resolvedSrc, dest)\n  }\n}\n\nfunction copyLink (resolvedSrc, dest) {\n  fs.unlinkSync(dest)\n  return fs.symlinkSync(resolvedSrc, dest)\n}\n\nmodule.exports = copySync\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/copy/copy-sync.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/copy/copy.js":
/*!************************************************!*\
  !*** ./node_modules/fs-extra/lib/copy/copy.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdirs = (__webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\").mkdirs)\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\nconst utimesMillis = (__webpack_require__(/*! ../util/utimes */ \"./node_modules/fs-extra/lib/util/utimes.js\").utimesMillis)\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/fs-extra/lib/util/stat.js\")\n\nfunction copy (src, dest, opts, cb) {\n  if (typeof opts === 'function' && !cb) {\n    cb = opts\n    opts = {}\n  } else if (typeof opts === 'function') {\n    opts = { filter: opts }\n  }\n\n  cb = cb || function () {}\n  opts = opts || {}\n\n  opts.clobber = 'clobber' in opts ? !!opts.clobber : true // default to true for now\n  opts.overwrite = 'overwrite' in opts ? !!opts.overwrite : opts.clobber // overwrite falls back to clobber\n\n  // Warn about using preserveTimestamps on 32-bit node\n  if (opts.preserveTimestamps && process.arch === 'ia32') {\n    process.emitWarning(\n      'Using the preserveTimestamps option in 32-bit node is not recommended;\\n\\n' +\n      '\\tsee https://github.com/jprichardson/node-fs-extra/issues/269',\n      'Warning', 'fs-extra-WARN0001'\n    )\n  }\n\n  stat.checkPaths(src, dest, 'copy', opts, (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat, destStat } = stats\n    stat.checkParentPaths(src, srcStat, dest, 'copy', err => {\n      if (err) return cb(err)\n      if (opts.filter) return handleFilter(checkParentDir, destStat, src, dest, opts, cb)\n      return checkParentDir(destStat, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction checkParentDir (destStat, src, dest, opts, cb) {\n  const destParent = path.dirname(dest)\n  pathExists(destParent, (err, dirExists) => {\n    if (err) return cb(err)\n    if (dirExists) return getStats(destStat, src, dest, opts, cb)\n    mkdirs(destParent, err => {\n      if (err) return cb(err)\n      return getStats(destStat, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction handleFilter (onInclude, destStat, src, dest, opts, cb) {\n  Promise.resolve(opts.filter(src, dest)).then(include => {\n    if (include) return onInclude(destStat, src, dest, opts, cb)\n    return cb()\n  }, error => cb(error))\n}\n\nfunction startCopy (destStat, src, dest, opts, cb) {\n  if (opts.filter) return handleFilter(getStats, destStat, src, dest, opts, cb)\n  return getStats(destStat, src, dest, opts, cb)\n}\n\nfunction getStats (destStat, src, dest, opts, cb) {\n  const stat = opts.dereference ? fs.stat : fs.lstat\n  stat(src, (err, srcStat) => {\n    if (err) return cb(err)\n\n    if (srcStat.isDirectory()) return onDir(srcStat, destStat, src, dest, opts, cb)\n    else if (srcStat.isFile() ||\n             srcStat.isCharacterDevice() ||\n             srcStat.isBlockDevice()) return onFile(srcStat, destStat, src, dest, opts, cb)\n    else if (srcStat.isSymbolicLink()) return onLink(destStat, src, dest, opts, cb)\n    else if (srcStat.isSocket()) return cb(new Error(`Cannot copy a socket file: ${src}`))\n    else if (srcStat.isFIFO()) return cb(new Error(`Cannot copy a FIFO pipe: ${src}`))\n    return cb(new Error(`Unknown file: ${src}`))\n  })\n}\n\nfunction onFile (srcStat, destStat, src, dest, opts, cb) {\n  if (!destStat) return copyFile(srcStat, src, dest, opts, cb)\n  return mayCopyFile(srcStat, src, dest, opts, cb)\n}\n\nfunction mayCopyFile (srcStat, src, dest, opts, cb) {\n  if (opts.overwrite) {\n    fs.unlink(dest, err => {\n      if (err) return cb(err)\n      return copyFile(srcStat, src, dest, opts, cb)\n    })\n  } else if (opts.errorOnExist) {\n    return cb(new Error(`'${dest}' already exists`))\n  } else return cb()\n}\n\nfunction copyFile (srcStat, src, dest, opts, cb) {\n  fs.copyFile(src, dest, err => {\n    if (err) return cb(err)\n    if (opts.preserveTimestamps) return handleTimestampsAndMode(srcStat.mode, src, dest, cb)\n    return setDestMode(dest, srcStat.mode, cb)\n  })\n}\n\nfunction handleTimestampsAndMode (srcMode, src, dest, cb) {\n  // Make sure the file is writable before setting the timestamp\n  // otherwise open fails with EPERM when invoked with 'r+'\n  // (through utimes call)\n  if (fileIsNotWritable(srcMode)) {\n    return makeFileWritable(dest, srcMode, err => {\n      if (err) return cb(err)\n      return setDestTimestampsAndMode(srcMode, src, dest, cb)\n    })\n  }\n  return setDestTimestampsAndMode(srcMode, src, dest, cb)\n}\n\nfunction fileIsNotWritable (srcMode) {\n  return (srcMode & 0o200) === 0\n}\n\nfunction makeFileWritable (dest, srcMode, cb) {\n  return setDestMode(dest, srcMode | 0o200, cb)\n}\n\nfunction setDestTimestampsAndMode (srcMode, src, dest, cb) {\n  setDestTimestamps(src, dest, err => {\n    if (err) return cb(err)\n    return setDestMode(dest, srcMode, cb)\n  })\n}\n\nfunction setDestMode (dest, srcMode, cb) {\n  return fs.chmod(dest, srcMode, cb)\n}\n\nfunction setDestTimestamps (src, dest, cb) {\n  // The initial srcStat.atime cannot be trusted\n  // because it is modified by the read(2) system call\n  // (See https://nodejs.org/api/fs.html#fs_stat_time_values)\n  fs.stat(src, (err, updatedSrcStat) => {\n    if (err) return cb(err)\n    return utimesMillis(dest, updatedSrcStat.atime, updatedSrcStat.mtime, cb)\n  })\n}\n\nfunction onDir (srcStat, destStat, src, dest, opts, cb) {\n  if (!destStat) return mkDirAndCopy(srcStat.mode, src, dest, opts, cb)\n  return copyDir(src, dest, opts, cb)\n}\n\nfunction mkDirAndCopy (srcMode, src, dest, opts, cb) {\n  fs.mkdir(dest, err => {\n    if (err) return cb(err)\n    copyDir(src, dest, opts, err => {\n      if (err) return cb(err)\n      return setDestMode(dest, srcMode, cb)\n    })\n  })\n}\n\nfunction copyDir (src, dest, opts, cb) {\n  fs.readdir(src, (err, items) => {\n    if (err) return cb(err)\n    return copyDirItems(items, src, dest, opts, cb)\n  })\n}\n\nfunction copyDirItems (items, src, dest, opts, cb) {\n  const item = items.pop()\n  if (!item) return cb()\n  return copyDirItem(items, item, src, dest, opts, cb)\n}\n\nfunction copyDirItem (items, item, src, dest, opts, cb) {\n  const srcItem = path.join(src, item)\n  const destItem = path.join(dest, item)\n  stat.checkPaths(srcItem, destItem, 'copy', opts, (err, stats) => {\n    if (err) return cb(err)\n    const { destStat } = stats\n    startCopy(destStat, srcItem, destItem, opts, err => {\n      if (err) return cb(err)\n      return copyDirItems(items, src, dest, opts, cb)\n    })\n  })\n}\n\nfunction onLink (destStat, src, dest, opts, cb) {\n  fs.readlink(src, (err, resolvedSrc) => {\n    if (err) return cb(err)\n    if (opts.dereference) {\n      resolvedSrc = path.resolve(process.cwd(), resolvedSrc)\n    }\n\n    if (!destStat) {\n      return fs.symlink(resolvedSrc, dest, cb)\n    } else {\n      fs.readlink(dest, (err, resolvedDest) => {\n        if (err) {\n          // dest exists and is a regular file or directory,\n          // Windows may throw UNKNOWN error. If dest already exists,\n          // fs throws error anyway, so no need to guard against it here.\n          if (err.code === 'EINVAL' || err.code === 'UNKNOWN') return fs.symlink(resolvedSrc, dest, cb)\n          return cb(err)\n        }\n        if (opts.dereference) {\n          resolvedDest = path.resolve(process.cwd(), resolvedDest)\n        }\n        if (stat.isSrcSubdir(resolvedSrc, resolvedDest)) {\n          return cb(new Error(`Cannot copy '${resolvedSrc}' to a subdirectory of itself, '${resolvedDest}'.`))\n        }\n\n        // do not copy if src is a subdir of dest since unlinking\n        // dest in this case would result in removing src contents\n        // and therefore a broken symlink would be created.\n        if (destStat.isDirectory() && stat.isSrcSubdir(resolvedDest, resolvedSrc)) {\n          return cb(new Error(`Cannot overwrite '${resolvedDest}' with '${resolvedSrc}'.`))\n        }\n        return copyLink(resolvedSrc, dest, cb)\n      })\n    }\n  })\n}\n\nfunction copyLink (resolvedSrc, dest, cb) {\n  fs.unlink(dest, err => {\n    if (err) return cb(err)\n    return fs.symlink(resolvedSrc, dest, cb)\n  })\n}\n\nmodule.exports = copy\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/copy/copy.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/copy/index.js":
/*!*************************************************!*\
  !*** ./node_modules/fs-extra/lib/copy/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nmodule.exports = {\n  copy: u(__webpack_require__(/*! ./copy */ \"./node_modules/fs-extra/lib/copy/copy.js\")),\n  copySync: __webpack_require__(/*! ./copy-sync */ \"./node_modules/fs-extra/lib/copy/copy-sync.js\")\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/copy/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/empty/index.js":
/*!**************************************************!*\
  !*** ./node_modules/fs-extra/lib/empty/index.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromPromise)\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/fs-extra/lib/fs/index.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\")\nconst remove = __webpack_require__(/*! ../remove */ \"./node_modules/fs-extra/lib/remove/index.js\")\n\nconst emptyDir = u(async function emptyDir (dir) {\n  let items\n  try {\n    items = await fs.readdir(dir)\n  } catch {\n    return mkdir.mkdirs(dir)\n  }\n\n  return Promise.all(items.map(item => remove.remove(path.join(dir, item))))\n})\n\nfunction emptyDirSync (dir) {\n  let items\n  try {\n    items = fs.readdirSync(dir)\n  } catch {\n    return mkdir.mkdirsSync(dir)\n  }\n\n  items.forEach(item => {\n    item = path.join(dir, item)\n    remove.removeSync(item)\n  })\n}\n\nmodule.exports = {\n  emptyDirSync,\n  emptydirSync: emptyDirSync,\n  emptyDir,\n  emptydir: emptyDir\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/empty/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/ensure/file.js":
/*!**************************************************!*\
  !*** ./node_modules/fs-extra/lib/ensure/file.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\")\n\nfunction createFile (file, callback) {\n  function makeFile () {\n    fs.writeFile(file, '', err => {\n      if (err) return callback(err)\n      callback()\n    })\n  }\n\n  fs.stat(file, (err, stats) => { // eslint-disable-line handle-callback-err\n    if (!err && stats.isFile()) return callback()\n    const dir = path.dirname(file)\n    fs.stat(dir, (err, stats) => {\n      if (err) {\n        // if the directory doesn't exist, make it\n        if (err.code === 'ENOENT') {\n          return mkdir.mkdirs(dir, err => {\n            if (err) return callback(err)\n            makeFile()\n          })\n        }\n        return callback(err)\n      }\n\n      if (stats.isDirectory()) makeFile()\n      else {\n        // parent is not a directory\n        // This is just to cause an internal ENOTDIR error to be thrown\n        fs.readdir(dir, err => {\n          if (err) return callback(err)\n        })\n      }\n    })\n  })\n}\n\nfunction createFileSync (file) {\n  let stats\n  try {\n    stats = fs.statSync(file)\n  } catch {}\n  if (stats && stats.isFile()) return\n\n  const dir = path.dirname(file)\n  try {\n    if (!fs.statSync(dir).isDirectory()) {\n      // parent is not a directory\n      // This is just to cause an internal ENOTDIR error to be thrown\n      fs.readdirSync(dir)\n    }\n  } catch (err) {\n    // If the stat call above failed because the directory doesn't exist, create it\n    if (err && err.code === 'ENOENT') mkdir.mkdirsSync(dir)\n    else throw err\n  }\n\n  fs.writeFileSync(file, '')\n}\n\nmodule.exports = {\n  createFile: u(createFile),\n  createFileSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/ensure/file.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/ensure/index.js":
/*!***************************************************!*\
  !*** ./node_modules/fs-extra/lib/ensure/index.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { createFile, createFileSync } = __webpack_require__(/*! ./file */ \"./node_modules/fs-extra/lib/ensure/file.js\")\nconst { createLink, createLinkSync } = __webpack_require__(/*! ./link */ \"./node_modules/fs-extra/lib/ensure/link.js\")\nconst { createSymlink, createSymlinkSync } = __webpack_require__(/*! ./symlink */ \"./node_modules/fs-extra/lib/ensure/symlink.js\")\n\nmodule.exports = {\n  // file\n  createFile,\n  createFileSync,\n  ensureFile: createFile,\n  ensureFileSync: createFileSync,\n  // link\n  createLink,\n  createLinkSync,\n  ensureLink: createLink,\n  ensureLinkSync: createLinkSync,\n  // symlink\n  createSymlink,\n  createSymlinkSync,\n  ensureSymlink: createSymlink,\n  ensureSymlinkSync: createSymlinkSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/ensure/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/ensure/link.js":
/*!**************************************************!*\
  !*** ./node_modules/fs-extra/lib/ensure/link.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\")\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\nconst { areIdentical } = __webpack_require__(/*! ../util/stat */ \"./node_modules/fs-extra/lib/util/stat.js\")\n\nfunction createLink (srcpath, dstpath, callback) {\n  function makeLink (srcpath, dstpath) {\n    fs.link(srcpath, dstpath, err => {\n      if (err) return callback(err)\n      callback(null)\n    })\n  }\n\n  fs.lstat(dstpath, (_, dstStat) => {\n    fs.lstat(srcpath, (err, srcStat) => {\n      if (err) {\n        err.message = err.message.replace('lstat', 'ensureLink')\n        return callback(err)\n      }\n      if (dstStat && areIdentical(srcStat, dstStat)) return callback(null)\n\n      const dir = path.dirname(dstpath)\n      pathExists(dir, (err, dirExists) => {\n        if (err) return callback(err)\n        if (dirExists) return makeLink(srcpath, dstpath)\n        mkdir.mkdirs(dir, err => {\n          if (err) return callback(err)\n          makeLink(srcpath, dstpath)\n        })\n      })\n    })\n  })\n}\n\nfunction createLinkSync (srcpath, dstpath) {\n  let dstStat\n  try {\n    dstStat = fs.lstatSync(dstpath)\n  } catch {}\n\n  try {\n    const srcStat = fs.lstatSync(srcpath)\n    if (dstStat && areIdentical(srcStat, dstStat)) return\n  } catch (err) {\n    err.message = err.message.replace('lstat', 'ensureLink')\n    throw err\n  }\n\n  const dir = path.dirname(dstpath)\n  const dirExists = fs.existsSync(dir)\n  if (dirExists) return fs.linkSync(srcpath, dstpath)\n  mkdir.mkdirsSync(dir)\n\n  return fs.linkSync(srcpath, dstpath)\n}\n\nmodule.exports = {\n  createLink: u(createLink),\n  createLinkSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/ensure/link.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/ensure/symlink-paths.js":
/*!***********************************************************!*\
  !*** ./node_modules/fs-extra/lib/ensure/symlink-paths.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\n\n/**\n * Function that returns two types of paths, one relative to symlink, and one\n * relative to the current working directory. Checks if path is absolute or\n * relative. If the path is relative, this function checks if the path is\n * relative to symlink or relative to current working directory. This is an\n * initiative to find a smarter `srcpath` to supply when building symlinks.\n * This allows you to determine which path to use out of one of three possible\n * types of source paths. The first is an absolute path. This is detected by\n * `path.isAbsolute()`. When an absolute path is provided, it is checked to\n * see if it exists. If it does it's used, if not an error is returned\n * (callback)/ thrown (sync). The other two options for `srcpath` are a\n * relative url. By default Node's `fs.symlink` works by creating a symlink\n * using `dstpath` and expects the `srcpath` to be relative to the newly\n * created symlink. If you provide a `srcpath` that does not exist on the file\n * system it results in a broken symlink. To minimize this, the function\n * checks to see if the 'relative to symlink' source file exists, and if it\n * does it will use it. If it does not, it checks if there's a file that\n * exists that is relative to the current working directory, if does its used.\n * This preserves the expectations of the original fs.symlink spec and adds\n * the ability to pass in `relative to current working direcotry` paths.\n */\n\nfunction symlinkPaths (srcpath, dstpath, callback) {\n  if (path.isAbsolute(srcpath)) {\n    return fs.lstat(srcpath, (err) => {\n      if (err) {\n        err.message = err.message.replace('lstat', 'ensureSymlink')\n        return callback(err)\n      }\n      return callback(null, {\n        toCwd: srcpath,\n        toDst: srcpath\n      })\n    })\n  } else {\n    const dstdir = path.dirname(dstpath)\n    const relativeToDst = path.join(dstdir, srcpath)\n    return pathExists(relativeToDst, (err, exists) => {\n      if (err) return callback(err)\n      if (exists) {\n        return callback(null, {\n          toCwd: relativeToDst,\n          toDst: srcpath\n        })\n      } else {\n        return fs.lstat(srcpath, (err) => {\n          if (err) {\n            err.message = err.message.replace('lstat', 'ensureSymlink')\n            return callback(err)\n          }\n          return callback(null, {\n            toCwd: srcpath,\n            toDst: path.relative(dstdir, srcpath)\n          })\n        })\n      }\n    })\n  }\n}\n\nfunction symlinkPathsSync (srcpath, dstpath) {\n  let exists\n  if (path.isAbsolute(srcpath)) {\n    exists = fs.existsSync(srcpath)\n    if (!exists) throw new Error('absolute srcpath does not exist')\n    return {\n      toCwd: srcpath,\n      toDst: srcpath\n    }\n  } else {\n    const dstdir = path.dirname(dstpath)\n    const relativeToDst = path.join(dstdir, srcpath)\n    exists = fs.existsSync(relativeToDst)\n    if (exists) {\n      return {\n        toCwd: relativeToDst,\n        toDst: srcpath\n      }\n    } else {\n      exists = fs.existsSync(srcpath)\n      if (!exists) throw new Error('relative srcpath does not exist')\n      return {\n        toCwd: srcpath,\n        toDst: path.relative(dstdir, srcpath)\n      }\n    }\n  }\n}\n\nmodule.exports = {\n  symlinkPaths,\n  symlinkPathsSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/ensure/symlink-paths.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/ensure/symlink-type.js":
/*!**********************************************************!*\
  !*** ./node_modules/fs-extra/lib/ensure/symlink-type.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\n\nfunction symlinkType (srcpath, type, callback) {\n  callback = (typeof type === 'function') ? type : callback\n  type = (typeof type === 'function') ? false : type\n  if (type) return callback(null, type)\n  fs.lstat(srcpath, (err, stats) => {\n    if (err) return callback(null, 'file')\n    type = (stats && stats.isDirectory()) ? 'dir' : 'file'\n    callback(null, type)\n  })\n}\n\nfunction symlinkTypeSync (srcpath, type) {\n  let stats\n\n  if (type) return type\n  try {\n    stats = fs.lstatSync(srcpath)\n  } catch {\n    return 'file'\n  }\n  return (stats && stats.isDirectory()) ? 'dir' : 'file'\n}\n\nmodule.exports = {\n  symlinkType,\n  symlinkTypeSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/ensure/symlink-type.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/ensure/symlink.js":
/*!*****************************************************!*\
  !*** ./node_modules/fs-extra/lib/ensure/symlink.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst path = __webpack_require__(/*! path */ \"path\")\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/fs-extra/lib/fs/index.js\")\nconst _mkdirs = __webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\")\nconst mkdirs = _mkdirs.mkdirs\nconst mkdirsSync = _mkdirs.mkdirsSync\n\nconst _symlinkPaths = __webpack_require__(/*! ./symlink-paths */ \"./node_modules/fs-extra/lib/ensure/symlink-paths.js\")\nconst symlinkPaths = _symlinkPaths.symlinkPaths\nconst symlinkPathsSync = _symlinkPaths.symlinkPathsSync\n\nconst _symlinkType = __webpack_require__(/*! ./symlink-type */ \"./node_modules/fs-extra/lib/ensure/symlink-type.js\")\nconst symlinkType = _symlinkType.symlinkType\nconst symlinkTypeSync = _symlinkType.symlinkTypeSync\n\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\n\nconst { areIdentical } = __webpack_require__(/*! ../util/stat */ \"./node_modules/fs-extra/lib/util/stat.js\")\n\nfunction createSymlink (srcpath, dstpath, type, callback) {\n  callback = (typeof type === 'function') ? type : callback\n  type = (typeof type === 'function') ? false : type\n\n  fs.lstat(dstpath, (err, stats) => {\n    if (!err && stats.isSymbolicLink()) {\n      Promise.all([\n        fs.stat(srcpath),\n        fs.stat(dstpath)\n      ]).then(([srcStat, dstStat]) => {\n        if (areIdentical(srcStat, dstStat)) return callback(null)\n        _createSymlink(srcpath, dstpath, type, callback)\n      })\n    } else _createSymlink(srcpath, dstpath, type, callback)\n  })\n}\n\nfunction _createSymlink (srcpath, dstpath, type, callback) {\n  symlinkPaths(srcpath, dstpath, (err, relative) => {\n    if (err) return callback(err)\n    srcpath = relative.toDst\n    symlinkType(relative.toCwd, type, (err, type) => {\n      if (err) return callback(err)\n      const dir = path.dirname(dstpath)\n      pathExists(dir, (err, dirExists) => {\n        if (err) return callback(err)\n        if (dirExists) return fs.symlink(srcpath, dstpath, type, callback)\n        mkdirs(dir, err => {\n          if (err) return callback(err)\n          fs.symlink(srcpath, dstpath, type, callback)\n        })\n      })\n    })\n  })\n}\n\nfunction createSymlinkSync (srcpath, dstpath, type) {\n  let stats\n  try {\n    stats = fs.lstatSync(dstpath)\n  } catch {}\n  if (stats && stats.isSymbolicLink()) {\n    const srcStat = fs.statSync(srcpath)\n    const dstStat = fs.statSync(dstpath)\n    if (areIdentical(srcStat, dstStat)) return\n  }\n\n  const relative = symlinkPathsSync(srcpath, dstpath)\n  srcpath = relative.toDst\n  type = symlinkTypeSync(relative.toCwd, type)\n  const dir = path.dirname(dstpath)\n  const exists = fs.existsSync(dir)\n  if (exists) return fs.symlinkSync(srcpath, dstpath, type)\n  mkdirsSync(dir)\n  return fs.symlinkSync(srcpath, dstpath, type)\n}\n\nmodule.exports = {\n  createSymlink: u(createSymlink),\n  createSymlinkSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/ensure/symlink.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/fs/index.js":
/*!***********************************************!*\
  !*** ./node_modules/fs-extra/lib/fs/index.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n// This is adapted from https://github.com/normalize/mz\n// Copyright (c) 2014-2016 Jonathan Ong me@jongleberry.com and Contributors\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\n\nconst api = [\n  'access',\n  'appendFile',\n  'chmod',\n  'chown',\n  'close',\n  'copyFile',\n  'fchmod',\n  'fchown',\n  'fdatasync',\n  'fstat',\n  'fsync',\n  'ftruncate',\n  'futimes',\n  'lchmod',\n  'lchown',\n  'link',\n  'lstat',\n  'mkdir',\n  'mkdtemp',\n  'open',\n  'opendir',\n  'readdir',\n  'readFile',\n  'readlink',\n  'realpath',\n  'rename',\n  'rm',\n  'rmdir',\n  'stat',\n  'symlink',\n  'truncate',\n  'unlink',\n  'utimes',\n  'writeFile'\n].filter(key => {\n  // Some commands are not available on some systems. Ex:\n  // fs.opendir was added in Node.js v12.12.0\n  // fs.rm was added in Node.js v14.14.0\n  // fs.lchown is not available on at least some Linux\n  return typeof fs[key] === 'function'\n})\n\n// Export cloned fs:\nObject.assign(exports, fs)\n\n// Universalify async methods:\napi.forEach(method => {\n  exports[method] = u(fs[method])\n})\n\n// We differ from mz/fs in that we still ship the old, broken, fs.exists()\n// since we are a drop-in replacement for the native module\nexports.exists = function (filename, callback) {\n  if (typeof callback === 'function') {\n    return fs.exists(filename, callback)\n  }\n  return new Promise(resolve => {\n    return fs.exists(filename, resolve)\n  })\n}\n\n// fs.read(), fs.write(), & fs.writev() need special treatment due to multiple callback args\n\nexports.read = function (fd, buffer, offset, length, position, callback) {\n  if (typeof callback === 'function') {\n    return fs.read(fd, buffer, offset, length, position, callback)\n  }\n  return new Promise((resolve, reject) => {\n    fs.read(fd, buffer, offset, length, position, (err, bytesRead, buffer) => {\n      if (err) return reject(err)\n      resolve({ bytesRead, buffer })\n    })\n  })\n}\n\n// Function signature can be\n// fs.write(fd, buffer[, offset[, length[, position]]], callback)\n// OR\n// fs.write(fd, string[, position[, encoding]], callback)\n// We need to handle both cases, so we use ...args\nexports.write = function (fd, buffer, ...args) {\n  if (typeof args[args.length - 1] === 'function') {\n    return fs.write(fd, buffer, ...args)\n  }\n\n  return new Promise((resolve, reject) => {\n    fs.write(fd, buffer, ...args, (err, bytesWritten, buffer) => {\n      if (err) return reject(err)\n      resolve({ bytesWritten, buffer })\n    })\n  })\n}\n\n// fs.writev only available in Node v12.9.0+\nif (typeof fs.writev === 'function') {\n  // Function signature is\n  // s.writev(fd, buffers[, position], callback)\n  // We need to handle the optional arg, so we use ...args\n  exports.writev = function (fd, buffers, ...args) {\n    if (typeof args[args.length - 1] === 'function') {\n      return fs.writev(fd, buffers, ...args)\n    }\n\n    return new Promise((resolve, reject) => {\n      fs.writev(fd, buffers, ...args, (err, bytesWritten, buffers) => {\n        if (err) return reject(err)\n        resolve({ bytesWritten, buffers })\n      })\n    })\n  }\n}\n\n// fs.realpath.native sometimes not available if fs is monkey-patched\nif (typeof fs.realpath.native === 'function') {\n  exports.realpath.native = u(fs.realpath.native)\n} else {\n  process.emitWarning(\n    'fs.realpath.native is not a function. Is fs being monkey-patched?',\n    'Warning', 'fs-extra-WARN0003'\n  )\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/fs/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/index.js":
/*!********************************************!*\
  !*** ./node_modules/fs-extra/lib/index.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = {\n  // Export promiseified graceful-fs:\n  ...__webpack_require__(/*! ./fs */ \"./node_modules/fs-extra/lib/fs/index.js\"),\n  // Export extra methods:\n  ...__webpack_require__(/*! ./copy */ \"./node_modules/fs-extra/lib/copy/index.js\"),\n  ...__webpack_require__(/*! ./empty */ \"./node_modules/fs-extra/lib/empty/index.js\"),\n  ...__webpack_require__(/*! ./ensure */ \"./node_modules/fs-extra/lib/ensure/index.js\"),\n  ...__webpack_require__(/*! ./json */ \"./node_modules/fs-extra/lib/json/index.js\"),\n  ...__webpack_require__(/*! ./mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\"),\n  ...__webpack_require__(/*! ./move */ \"./node_modules/fs-extra/lib/move/index.js\"),\n  ...__webpack_require__(/*! ./output-file */ \"./node_modules/fs-extra/lib/output-file/index.js\"),\n  ...__webpack_require__(/*! ./path-exists */ \"./node_modules/fs-extra/lib/path-exists/index.js\"),\n  ...__webpack_require__(/*! ./remove */ \"./node_modules/fs-extra/lib/remove/index.js\")\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/json/index.js":
/*!*************************************************!*\
  !*** ./node_modules/fs-extra/lib/json/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromPromise)\nconst jsonFile = __webpack_require__(/*! ./jsonfile */ \"./node_modules/fs-extra/lib/json/jsonfile.js\")\n\njsonFile.outputJson = u(__webpack_require__(/*! ./output-json */ \"./node_modules/fs-extra/lib/json/output-json.js\"))\njsonFile.outputJsonSync = __webpack_require__(/*! ./output-json-sync */ \"./node_modules/fs-extra/lib/json/output-json-sync.js\")\n// aliases\njsonFile.outputJSON = jsonFile.outputJson\njsonFile.outputJSONSync = jsonFile.outputJsonSync\njsonFile.writeJSON = jsonFile.writeJson\njsonFile.writeJSONSync = jsonFile.writeJsonSync\njsonFile.readJSON = jsonFile.readJson\njsonFile.readJSONSync = jsonFile.readJsonSync\n\nmodule.exports = jsonFile\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/json/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/json/jsonfile.js":
/*!****************************************************!*\
  !*** ./node_modules/fs-extra/lib/json/jsonfile.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst jsonFile = __webpack_require__(/*! jsonfile */ \"./node_modules/jsonfile/index.js\")\n\nmodule.exports = {\n  // jsonfile exports\n  readJson: jsonFile.readFile,\n  readJsonSync: jsonFile.readFileSync,\n  writeJson: jsonFile.writeFile,\n  writeJsonSync: jsonFile.writeFileSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/json/jsonfile.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/json/output-json-sync.js":
/*!************************************************************!*\
  !*** ./node_modules/fs-extra/lib/json/output-json-sync.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { stringify } = __webpack_require__(/*! jsonfile/utils */ \"./node_modules/jsonfile/utils.js\")\nconst { outputFileSync } = __webpack_require__(/*! ../output-file */ \"./node_modules/fs-extra/lib/output-file/index.js\")\n\nfunction outputJsonSync (file, data, options) {\n  const str = stringify(data, options)\n\n  outputFileSync(file, str, options)\n}\n\nmodule.exports = outputJsonSync\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/json/output-json-sync.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/json/output-json.js":
/*!*******************************************************!*\
  !*** ./node_modules/fs-extra/lib/json/output-json.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { stringify } = __webpack_require__(/*! jsonfile/utils */ \"./node_modules/jsonfile/utils.js\")\nconst { outputFile } = __webpack_require__(/*! ../output-file */ \"./node_modules/fs-extra/lib/output-file/index.js\")\n\nasync function outputJson (file, data, options = {}) {\n  const str = stringify(data, options)\n\n  await outputFile(file, str, options)\n}\n\nmodule.exports = outputJson\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/json/output-json.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/mkdirs/index.js":
/*!***************************************************!*\
  !*** ./node_modules/fs-extra/lib/mkdirs/index.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromPromise)\nconst { makeDir: _makeDir, makeDirSync } = __webpack_require__(/*! ./make-dir */ \"./node_modules/fs-extra/lib/mkdirs/make-dir.js\")\nconst makeDir = u(_makeDir)\n\nmodule.exports = {\n  mkdirs: makeDir,\n  mkdirsSync: makeDirSync,\n  // alias\n  mkdirp: makeDir,\n  mkdirpSync: makeDirSync,\n  ensureDir: makeDir,\n  ensureDirSync: makeDirSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/mkdirs/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/mkdirs/make-dir.js":
/*!******************************************************!*\
  !*** ./node_modules/fs-extra/lib/mkdirs/make-dir.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/fs-extra/lib/fs/index.js\")\nconst { checkPath } = __webpack_require__(/*! ./utils */ \"./node_modules/fs-extra/lib/mkdirs/utils.js\")\n\nconst getMode = options => {\n  const defaults = { mode: 0o777 }\n  if (typeof options === 'number') return options\n  return ({ ...defaults, ...options }).mode\n}\n\nmodule.exports.makeDir = async (dir, options) => {\n  checkPath(dir)\n\n  return fs.mkdir(dir, {\n    mode: getMode(options),\n    recursive: true\n  })\n}\n\nmodule.exports.makeDirSync = (dir, options) => {\n  checkPath(dir)\n\n  return fs.mkdirSync(dir, {\n    mode: getMode(options),\n    recursive: true\n  })\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/mkdirs/make-dir.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/mkdirs/utils.js":
/*!***************************************************!*\
  !*** ./node_modules/fs-extra/lib/mkdirs/utils.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Adapted from https://github.com/sindresorhus/make-dir\n// Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n// Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n// The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nconst path = __webpack_require__(/*! path */ \"path\")\n\n// https://github.com/nodejs/node/issues/8987\n// https://github.com/libuv/libuv/pull/1088\nmodule.exports.checkPath = function checkPath (pth) {\n  if (process.platform === 'win32') {\n    const pathHasInvalidWinCharacters = /[<>:\"|?*]/.test(pth.replace(path.parse(pth).root, ''))\n\n    if (pathHasInvalidWinCharacters) {\n      const error = new Error(`Path contains invalid characters: ${pth}`)\n      error.code = 'EINVAL'\n      throw error\n    }\n  }\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/mkdirs/utils.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/move/index.js":
/*!*************************************************!*\
  !*** ./node_modules/fs-extra/lib/move/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nmodule.exports = {\n  move: u(__webpack_require__(/*! ./move */ \"./node_modules/fs-extra/lib/move/move.js\")),\n  moveSync: __webpack_require__(/*! ./move-sync */ \"./node_modules/fs-extra/lib/move/move-sync.js\")\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/move/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/move/move-sync.js":
/*!*****************************************************!*\
  !*** ./node_modules/fs-extra/lib/move/move-sync.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst copySync = (__webpack_require__(/*! ../copy */ \"./node_modules/fs-extra/lib/copy/index.js\").copySync)\nconst removeSync = (__webpack_require__(/*! ../remove */ \"./node_modules/fs-extra/lib/remove/index.js\").removeSync)\nconst mkdirpSync = (__webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\").mkdirpSync)\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/fs-extra/lib/util/stat.js\")\n\nfunction moveSync (src, dest, opts) {\n  opts = opts || {}\n  const overwrite = opts.overwrite || opts.clobber || false\n\n  const { srcStat, isChangingCase = false } = stat.checkPathsSync(src, dest, 'move', opts)\n  stat.checkParentPathsSync(src, srcStat, dest, 'move')\n  if (!isParentRoot(dest)) mkdirpSync(path.dirname(dest))\n  return doRename(src, dest, overwrite, isChangingCase)\n}\n\nfunction isParentRoot (dest) {\n  const parent = path.dirname(dest)\n  const parsedPath = path.parse(parent)\n  return parsedPath.root === parent\n}\n\nfunction doRename (src, dest, overwrite, isChangingCase) {\n  if (isChangingCase) return rename(src, dest, overwrite)\n  if (overwrite) {\n    removeSync(dest)\n    return rename(src, dest, overwrite)\n  }\n  if (fs.existsSync(dest)) throw new Error('dest already exists.')\n  return rename(src, dest, overwrite)\n}\n\nfunction rename (src, dest, overwrite) {\n  try {\n    fs.renameSync(src, dest)\n  } catch (err) {\n    if (err.code !== 'EXDEV') throw err\n    return moveAcrossDevice(src, dest, overwrite)\n  }\n}\n\nfunction moveAcrossDevice (src, dest, overwrite) {\n  const opts = {\n    overwrite,\n    errorOnExist: true\n  }\n  copySync(src, dest, opts)\n  return removeSync(src)\n}\n\nmodule.exports = moveSync\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/move/move-sync.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/move/move.js":
/*!************************************************!*\
  !*** ./node_modules/fs-extra/lib/move/move.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst copy = (__webpack_require__(/*! ../copy */ \"./node_modules/fs-extra/lib/copy/index.js\").copy)\nconst remove = (__webpack_require__(/*! ../remove */ \"./node_modules/fs-extra/lib/remove/index.js\").remove)\nconst mkdirp = (__webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\").mkdirp)\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\nconst stat = __webpack_require__(/*! ../util/stat */ \"./node_modules/fs-extra/lib/util/stat.js\")\n\nfunction move (src, dest, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts\n    opts = {}\n  }\n\n  opts = opts || {}\n\n  const overwrite = opts.overwrite || opts.clobber || false\n\n  stat.checkPaths(src, dest, 'move', opts, (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat, isChangingCase = false } = stats\n    stat.checkParentPaths(src, srcStat, dest, 'move', err => {\n      if (err) return cb(err)\n      if (isParentRoot(dest)) return doRename(src, dest, overwrite, isChangingCase, cb)\n      mkdirp(path.dirname(dest), err => {\n        if (err) return cb(err)\n        return doRename(src, dest, overwrite, isChangingCase, cb)\n      })\n    })\n  })\n}\n\nfunction isParentRoot (dest) {\n  const parent = path.dirname(dest)\n  const parsedPath = path.parse(parent)\n  return parsedPath.root === parent\n}\n\nfunction doRename (src, dest, overwrite, isChangingCase, cb) {\n  if (isChangingCase) return rename(src, dest, overwrite, cb)\n  if (overwrite) {\n    return remove(dest, err => {\n      if (err) return cb(err)\n      return rename(src, dest, overwrite, cb)\n    })\n  }\n  pathExists(dest, (err, destExists) => {\n    if (err) return cb(err)\n    if (destExists) return cb(new Error('dest already exists.'))\n    return rename(src, dest, overwrite, cb)\n  })\n}\n\nfunction rename (src, dest, overwrite, cb) {\n  fs.rename(src, dest, err => {\n    if (!err) return cb()\n    if (err.code !== 'EXDEV') return cb(err)\n    return moveAcrossDevice(src, dest, overwrite, cb)\n  })\n}\n\nfunction moveAcrossDevice (src, dest, overwrite, cb) {\n  const opts = {\n    overwrite,\n    errorOnExist: true\n  }\n  copy(src, dest, opts, err => {\n    if (err) return cb(err)\n    return remove(src, cb)\n  })\n}\n\nmodule.exports = move\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/move/move.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/output-file/index.js":
/*!********************************************************!*\
  !*** ./node_modules/fs-extra/lib/output-file/index.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst mkdir = __webpack_require__(/*! ../mkdirs */ \"./node_modules/fs-extra/lib/mkdirs/index.js\")\nconst pathExists = (__webpack_require__(/*! ../path-exists */ \"./node_modules/fs-extra/lib/path-exists/index.js\").pathExists)\n\nfunction outputFile (file, data, encoding, callback) {\n  if (typeof encoding === 'function') {\n    callback = encoding\n    encoding = 'utf8'\n  }\n\n  const dir = path.dirname(file)\n  pathExists(dir, (err, itDoes) => {\n    if (err) return callback(err)\n    if (itDoes) return fs.writeFile(file, data, encoding, callback)\n\n    mkdir.mkdirs(dir, err => {\n      if (err) return callback(err)\n\n      fs.writeFile(file, data, encoding, callback)\n    })\n  })\n}\n\nfunction outputFileSync (file, ...args) {\n  const dir = path.dirname(file)\n  if (fs.existsSync(dir)) {\n    return fs.writeFileSync(file, ...args)\n  }\n  mkdir.mkdirsSync(dir)\n  fs.writeFileSync(file, ...args)\n}\n\nmodule.exports = {\n  outputFile: u(outputFile),\n  outputFileSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/output-file/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/path-exists/index.js":
/*!********************************************************!*\
  !*** ./node_modules/fs-extra/lib/path-exists/index.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromPromise)\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/fs-extra/lib/fs/index.js\")\n\nfunction pathExists (path) {\n  return fs.access(path).then(() => true).catch(() => false)\n}\n\nmodule.exports = {\n  pathExists: u(pathExists),\n  pathExistsSync: fs.existsSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/path-exists/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/remove/index.js":
/*!***************************************************!*\
  !*** ./node_modules/fs-extra/lib/remove/index.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst u = (__webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\").fromCallback)\nconst rimraf = __webpack_require__(/*! ./rimraf */ \"./node_modules/fs-extra/lib/remove/rimraf.js\")\n\nfunction remove (path, callback) {\n  // Node 14.14.0+\n  if (fs.rm) return fs.rm(path, { recursive: true, force: true }, callback)\n  rimraf(path, callback)\n}\n\nfunction removeSync (path) {\n  // Node 14.14.0+\n  if (fs.rmSync) return fs.rmSync(path, { recursive: true, force: true })\n  rimraf.sync(path)\n}\n\nmodule.exports = {\n  remove: u(remove),\n  removeSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/remove/index.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/remove/rimraf.js":
/*!****************************************************!*\
  !*** ./node_modules/fs-extra/lib/remove/rimraf.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst assert = __webpack_require__(/*! assert */ \"assert\")\n\nconst isWindows = (process.platform === 'win32')\n\nfunction defaults (options) {\n  const methods = [\n    'unlink',\n    'chmod',\n    'stat',\n    'lstat',\n    'rmdir',\n    'readdir'\n  ]\n  methods.forEach(m => {\n    options[m] = options[m] || fs[m]\n    m = m + 'Sync'\n    options[m] = options[m] || fs[m]\n  })\n\n  options.maxBusyTries = options.maxBusyTries || 3\n}\n\nfunction rimraf (p, options, cb) {\n  let busyTries = 0\n\n  if (typeof options === 'function') {\n    cb = options\n    options = {}\n  }\n\n  assert(p, 'rimraf: missing path')\n  assert.strictEqual(typeof p, 'string', 'rimraf: path should be a string')\n  assert.strictEqual(typeof cb, 'function', 'rimraf: callback function required')\n  assert(options, 'rimraf: invalid options argument provided')\n  assert.strictEqual(typeof options, 'object', 'rimraf: options should be object')\n\n  defaults(options)\n\n  rimraf_(p, options, function CB (er) {\n    if (er) {\n      if ((er.code === 'EBUSY' || er.code === 'ENOTEMPTY' || er.code === 'EPERM') &&\n          busyTries < options.maxBusyTries) {\n        busyTries++\n        const time = busyTries * 100\n        // try again, with the same exact callback as this one.\n        return setTimeout(() => rimraf_(p, options, CB), time)\n      }\n\n      // already gone\n      if (er.code === 'ENOENT') er = null\n    }\n\n    cb(er)\n  })\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nfunction rimraf_ (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // sunos lets the root user unlink directories, which is... weird.\n  // so we have to lstat here and make sure it's not a dir.\n  options.lstat(p, (er, st) => {\n    if (er && er.code === 'ENOENT') {\n      return cb(null)\n    }\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er && er.code === 'EPERM' && isWindows) {\n      return fixWinEPERM(p, options, er, cb)\n    }\n\n    if (st && st.isDirectory()) {\n      return rmdir(p, options, er, cb)\n    }\n\n    options.unlink(p, er => {\n      if (er) {\n        if (er.code === 'ENOENT') {\n          return cb(null)\n        }\n        if (er.code === 'EPERM') {\n          return (isWindows)\n            ? fixWinEPERM(p, options, er, cb)\n            : rmdir(p, options, er, cb)\n        }\n        if (er.code === 'EISDIR') {\n          return rmdir(p, options, er, cb)\n        }\n      }\n      return cb(er)\n    })\n  })\n}\n\nfunction fixWinEPERM (p, options, er, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.chmod(p, 0o666, er2 => {\n    if (er2) {\n      cb(er2.code === 'ENOENT' ? null : er)\n    } else {\n      options.stat(p, (er3, stats) => {\n        if (er3) {\n          cb(er3.code === 'ENOENT' ? null : er)\n        } else if (stats.isDirectory()) {\n          rmdir(p, options, er, cb)\n        } else {\n          options.unlink(p, cb)\n        }\n      })\n    }\n  })\n}\n\nfunction fixWinEPERMSync (p, options, er) {\n  let stats\n\n  assert(p)\n  assert(options)\n\n  try {\n    options.chmodSync(p, 0o666)\n  } catch (er2) {\n    if (er2.code === 'ENOENT') {\n      return\n    } else {\n      throw er\n    }\n  }\n\n  try {\n    stats = options.statSync(p)\n  } catch (er3) {\n    if (er3.code === 'ENOENT') {\n      return\n    } else {\n      throw er\n    }\n  }\n\n  if (stats.isDirectory()) {\n    rmdirSync(p, options, er)\n  } else {\n    options.unlinkSync(p)\n  }\n}\n\nfunction rmdir (p, options, originalEr, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  options.rmdir(p, er => {\n    if (er && (er.code === 'ENOTEMPTY' || er.code === 'EEXIST' || er.code === 'EPERM')) {\n      rmkids(p, options, cb)\n    } else if (er && er.code === 'ENOTDIR') {\n      cb(originalEr)\n    } else {\n      cb(er)\n    }\n  })\n}\n\nfunction rmkids (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.readdir(p, (er, files) => {\n    if (er) return cb(er)\n\n    let n = files.length\n    let errState\n\n    if (n === 0) return options.rmdir(p, cb)\n\n    files.forEach(f => {\n      rimraf(path.join(p, f), options, er => {\n        if (errState) {\n          return\n        }\n        if (er) return cb(errState = er)\n        if (--n === 0) {\n          options.rmdir(p, cb)\n        }\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nfunction rimrafSync (p, options) {\n  let st\n\n  options = options || {}\n  defaults(options)\n\n  assert(p, 'rimraf: missing path')\n  assert.strictEqual(typeof p, 'string', 'rimraf: path should be a string')\n  assert(options, 'rimraf: missing options')\n  assert.strictEqual(typeof options, 'object', 'rimraf: options should be object')\n\n  try {\n    st = options.lstatSync(p)\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      return\n    }\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er.code === 'EPERM' && isWindows) {\n      fixWinEPERMSync(p, options, er)\n    }\n  }\n\n  try {\n    // sunos lets the root user unlink directories, which is... weird.\n    if (st && st.isDirectory()) {\n      rmdirSync(p, options, null)\n    } else {\n      options.unlinkSync(p)\n    }\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      return\n    } else if (er.code === 'EPERM') {\n      return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)\n    } else if (er.code !== 'EISDIR') {\n      throw er\n    }\n    rmdirSync(p, options, er)\n  }\n}\n\nfunction rmdirSync (p, options, originalEr) {\n  assert(p)\n  assert(options)\n\n  try {\n    options.rmdirSync(p)\n  } catch (er) {\n    if (er.code === 'ENOTDIR') {\n      throw originalEr\n    } else if (er.code === 'ENOTEMPTY' || er.code === 'EEXIST' || er.code === 'EPERM') {\n      rmkidsSync(p, options)\n    } else if (er.code !== 'ENOENT') {\n      throw er\n    }\n  }\n}\n\nfunction rmkidsSync (p, options) {\n  assert(p)\n  assert(options)\n  options.readdirSync(p).forEach(f => rimrafSync(path.join(p, f), options))\n\n  if (isWindows) {\n    // We only end up here once we got ENOTEMPTY at least once, and\n    // at this point, we are guaranteed to have removed all the kids.\n    // So, we know that it won't be ENOENT or ENOTDIR or anything else.\n    // try really hard to delete stuff on windows, because it has a\n    // PROFOUNDLY annoying habit of not closing handles promptly when\n    // files are deleted, resulting in spurious ENOTEMPTY errors.\n    const startTime = Date.now()\n    do {\n      try {\n        const ret = options.rmdirSync(p, options)\n        return ret\n      } catch {}\n    } while (Date.now() - startTime < 500) // give up after 500ms\n  } else {\n    const ret = options.rmdirSync(p, options)\n    return ret\n  }\n}\n\nmodule.exports = rimraf\nrimraf.sync = rimrafSync\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/remove/rimraf.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/util/stat.js":
/*!************************************************!*\
  !*** ./node_modules/fs-extra/lib/util/stat.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! ../fs */ \"./node_modules/fs-extra/lib/fs/index.js\")\nconst path = __webpack_require__(/*! path */ \"path\")\nconst util = __webpack_require__(/*! util */ \"util\")\n\nfunction getStats (src, dest, opts) {\n  const statFunc = opts.dereference\n    ? (file) => fs.stat(file, { bigint: true })\n    : (file) => fs.lstat(file, { bigint: true })\n  return Promise.all([\n    statFunc(src),\n    statFunc(dest).catch(err => {\n      if (err.code === 'ENOENT') return null\n      throw err\n    })\n  ]).then(([srcStat, destStat]) => ({ srcStat, destStat }))\n}\n\nfunction getStatsSync (src, dest, opts) {\n  let destStat\n  const statFunc = opts.dereference\n    ? (file) => fs.statSync(file, { bigint: true })\n    : (file) => fs.lstatSync(file, { bigint: true })\n  const srcStat = statFunc(src)\n  try {\n    destStat = statFunc(dest)\n  } catch (err) {\n    if (err.code === 'ENOENT') return { srcStat, destStat: null }\n    throw err\n  }\n  return { srcStat, destStat }\n}\n\nfunction checkPaths (src, dest, funcName, opts, cb) {\n  util.callbackify(getStats)(src, dest, opts, (err, stats) => {\n    if (err) return cb(err)\n    const { srcStat, destStat } = stats\n\n    if (destStat) {\n      if (areIdentical(srcStat, destStat)) {\n        const srcBaseName = path.basename(src)\n        const destBaseName = path.basename(dest)\n        if (funcName === 'move' &&\n          srcBaseName !== destBaseName &&\n          srcBaseName.toLowerCase() === destBaseName.toLowerCase()) {\n          return cb(null, { srcStat, destStat, isChangingCase: true })\n        }\n        return cb(new Error('Source and destination must not be the same.'))\n      }\n      if (srcStat.isDirectory() && !destStat.isDirectory()) {\n        return cb(new Error(`Cannot overwrite non-directory '${dest}' with directory '${src}'.`))\n      }\n      if (!srcStat.isDirectory() && destStat.isDirectory()) {\n        return cb(new Error(`Cannot overwrite directory '${dest}' with non-directory '${src}'.`))\n      }\n    }\n\n    if (srcStat.isDirectory() && isSrcSubdir(src, dest)) {\n      return cb(new Error(errMsg(src, dest, funcName)))\n    }\n    return cb(null, { srcStat, destStat })\n  })\n}\n\nfunction checkPathsSync (src, dest, funcName, opts) {\n  const { srcStat, destStat } = getStatsSync(src, dest, opts)\n\n  if (destStat) {\n    if (areIdentical(srcStat, destStat)) {\n      const srcBaseName = path.basename(src)\n      const destBaseName = path.basename(dest)\n      if (funcName === 'move' &&\n        srcBaseName !== destBaseName &&\n        srcBaseName.toLowerCase() === destBaseName.toLowerCase()) {\n        return { srcStat, destStat, isChangingCase: true }\n      }\n      throw new Error('Source and destination must not be the same.')\n    }\n    if (srcStat.isDirectory() && !destStat.isDirectory()) {\n      throw new Error(`Cannot overwrite non-directory '${dest}' with directory '${src}'.`)\n    }\n    if (!srcStat.isDirectory() && destStat.isDirectory()) {\n      throw new Error(`Cannot overwrite directory '${dest}' with non-directory '${src}'.`)\n    }\n  }\n\n  if (srcStat.isDirectory() && isSrcSubdir(src, dest)) {\n    throw new Error(errMsg(src, dest, funcName))\n  }\n  return { srcStat, destStat }\n}\n\n// recursively check if dest parent is a subdirectory of src.\n// It works for all file types including symlinks since it\n// checks the src and dest inodes. It starts from the deepest\n// parent and stops once it reaches the src parent or the root path.\nfunction checkParentPaths (src, srcStat, dest, funcName, cb) {\n  const srcParent = path.resolve(path.dirname(src))\n  const destParent = path.resolve(path.dirname(dest))\n  if (destParent === srcParent || destParent === path.parse(destParent).root) return cb()\n  fs.stat(destParent, { bigint: true }, (err, destStat) => {\n    if (err) {\n      if (err.code === 'ENOENT') return cb()\n      return cb(err)\n    }\n    if (areIdentical(srcStat, destStat)) {\n      return cb(new Error(errMsg(src, dest, funcName)))\n    }\n    return checkParentPaths(src, srcStat, destParent, funcName, cb)\n  })\n}\n\nfunction checkParentPathsSync (src, srcStat, dest, funcName) {\n  const srcParent = path.resolve(path.dirname(src))\n  const destParent = path.resolve(path.dirname(dest))\n  if (destParent === srcParent || destParent === path.parse(destParent).root) return\n  let destStat\n  try {\n    destStat = fs.statSync(destParent, { bigint: true })\n  } catch (err) {\n    if (err.code === 'ENOENT') return\n    throw err\n  }\n  if (areIdentical(srcStat, destStat)) {\n    throw new Error(errMsg(src, dest, funcName))\n  }\n  return checkParentPathsSync(src, srcStat, destParent, funcName)\n}\n\nfunction areIdentical (srcStat, destStat) {\n  return destStat.ino && destStat.dev && destStat.ino === srcStat.ino && destStat.dev === srcStat.dev\n}\n\n// return true if dest is a subdir of src, otherwise false.\n// It only checks the path strings.\nfunction isSrcSubdir (src, dest) {\n  const srcArr = path.resolve(src).split(path.sep).filter(i => i)\n  const destArr = path.resolve(dest).split(path.sep).filter(i => i)\n  return srcArr.reduce((acc, cur, i) => acc && destArr[i] === cur, true)\n}\n\nfunction errMsg (src, dest, funcName) {\n  return `Cannot ${funcName} '${src}' to a subdirectory of itself, '${dest}'.`\n}\n\nmodule.exports = {\n  checkPaths,\n  checkPathsSync,\n  checkParentPaths,\n  checkParentPathsSync,\n  isSrcSubdir,\n  areIdentical\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/util/stat.js?");

/***/ }),

/***/ "./node_modules/fs-extra/lib/util/utimes.js":
/*!**************************************************!*\
  !*** ./node_modules/fs-extra/lib/util/utimes.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\n\nfunction utimesMillis (path, atime, mtime, callback) {\n  // if (!HAS_MILLIS_RES) return fs.utimes(path, atime, mtime, callback)\n  fs.open(path, 'r+', (err, fd) => {\n    if (err) return callback(err)\n    fs.futimes(fd, atime, mtime, futimesErr => {\n      fs.close(fd, closeErr => {\n        if (callback) callback(futimesErr || closeErr)\n      })\n    })\n  })\n}\n\nfunction utimesMillisSync (path, atime, mtime) {\n  const fd = fs.openSync(path, 'r+')\n  fs.futimesSync(fd, atime, mtime)\n  return fs.closeSync(fd)\n}\n\nmodule.exports = {\n  utimesMillis,\n  utimesMillisSync\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/fs-extra/lib/util/utimes.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/clone.js":
/*!*******************************************!*\
  !*** ./node_modules/graceful-fs/clone.js ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = clone\n\nvar getPrototypeOf = Object.getPrototypeOf || function (obj) {\n  return obj.__proto__\n}\n\nfunction clone (obj) {\n  if (obj === null || typeof obj !== 'object')\n    return obj\n\n  if (obj instanceof Object)\n    var copy = { __proto__: getPrototypeOf(obj) }\n  else\n    var copy = Object.create(null)\n\n  Object.getOwnPropertyNames(obj).forEach(function (key) {\n    Object.defineProperty(copy, key, Object.getOwnPropertyDescriptor(obj, key))\n  })\n\n  return copy\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/graceful-fs/clone.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/graceful-fs.js":
/*!*************************************************!*\
  !*** ./node_modules/graceful-fs/graceful-fs.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var fs = __webpack_require__(/*! fs */ \"fs\")\nvar polyfills = __webpack_require__(/*! ./polyfills.js */ \"./node_modules/graceful-fs/polyfills.js\")\nvar legacy = __webpack_require__(/*! ./legacy-streams.js */ \"./node_modules/graceful-fs/legacy-streams.js\")\nvar clone = __webpack_require__(/*! ./clone.js */ \"./node_modules/graceful-fs/clone.js\")\n\nvar util = __webpack_require__(/*! util */ \"util\")\n\n/* istanbul ignore next - node 0.x polyfill */\nvar gracefulQueue\nvar previousSymbol\n\n/* istanbul ignore else - node 0.x polyfill */\nif (typeof Symbol === 'function' && typeof Symbol.for === 'function') {\n  gracefulQueue = Symbol.for('graceful-fs.queue')\n  // This is used in testing by future versions\n  previousSymbol = Symbol.for('graceful-fs.previous')\n} else {\n  gracefulQueue = '___graceful-fs.queue'\n  previousSymbol = '___graceful-fs.previous'\n}\n\nfunction noop () {}\n\nfunction publishQueue(context, queue) {\n  Object.defineProperty(context, gracefulQueue, {\n    get: function() {\n      return queue\n    }\n  })\n}\n\nvar debug = noop\nif (util.debuglog)\n  debug = util.debuglog('gfs4')\nelse if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS4: ' + m.split(/\\n/).join('\\nGFS4: ')\n    console.error(m)\n  }\n\n// Once time initialization\nif (!fs[gracefulQueue]) {\n  // This queue can be shared by multiple loaded instances\n  var queue = global[gracefulQueue] || []\n  publishQueue(fs, queue)\n\n  // Patch fs.close/closeSync to shared queue version, because we need\n  // to retry() whenever a close happens *anywhere* in the program.\n  // This is essential when multiple graceful-fs instances are\n  // in play at the same time.\n  fs.close = (function (fs$close) {\n    function close (fd, cb) {\n      return fs$close.call(fs, fd, function (err) {\n        // This function uses the graceful-fs shared queue\n        if (!err) {\n          resetQueue()\n        }\n\n        if (typeof cb === 'function')\n          cb.apply(this, arguments)\n      })\n    }\n\n    Object.defineProperty(close, previousSymbol, {\n      value: fs$close\n    })\n    return close\n  })(fs.close)\n\n  fs.closeSync = (function (fs$closeSync) {\n    function closeSync (fd) {\n      // This function uses the graceful-fs shared queue\n      fs$closeSync.apply(fs, arguments)\n      resetQueue()\n    }\n\n    Object.defineProperty(closeSync, previousSymbol, {\n      value: fs$closeSync\n    })\n    return closeSync\n  })(fs.closeSync)\n\n  if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) {\n    process.on('exit', function() {\n      debug(fs[gracefulQueue])\n      __webpack_require__(/*! assert */ \"assert\").equal(fs[gracefulQueue].length, 0)\n    })\n  }\n}\n\nif (!global[gracefulQueue]) {\n  publishQueue(global, fs[gracefulQueue]);\n}\n\nmodule.exports = patch(clone(fs))\nif (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH && !fs.__patched) {\n    module.exports = patch(fs)\n    fs.__patched = true;\n}\n\nfunction patch (fs) {\n  // Everything that references the open() function needs to be in here\n  polyfills(fs)\n  fs.gracefulify = patch\n\n  fs.createReadStream = createReadStream\n  fs.createWriteStream = createWriteStream\n  var fs$readFile = fs.readFile\n  fs.readFile = readFile\n  function readFile (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$readFile(path, options, cb)\n\n    function go$readFile (path, options, cb, startTime) {\n      return fs$readFile(path, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$readFile, [path, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$writeFile = fs.writeFile\n  fs.writeFile = writeFile\n  function writeFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$writeFile(path, data, options, cb)\n\n    function go$writeFile (path, data, options, cb, startTime) {\n      return fs$writeFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$writeFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$appendFile = fs.appendFile\n  if (fs$appendFile)\n    fs.appendFile = appendFile\n  function appendFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$appendFile(path, data, options, cb)\n\n    function go$appendFile (path, data, options, cb, startTime) {\n      return fs$appendFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$appendFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$copyFile = fs.copyFile\n  if (fs$copyFile)\n    fs.copyFile = copyFile\n  function copyFile (src, dest, flags, cb) {\n    if (typeof flags === 'function') {\n      cb = flags\n      flags = 0\n    }\n    return go$copyFile(src, dest, flags, cb)\n\n    function go$copyFile (src, dest, flags, cb, startTime) {\n      return fs$copyFile(src, dest, flags, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$copyFile, [src, dest, flags, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$readdir = fs.readdir\n  fs.readdir = readdir\n  var noReaddirOptionVersions = /^v[0-5]\\./\n  function readdir (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    var go$readdir = noReaddirOptionVersions.test(process.version)\n      ? function go$readdir (path, options, cb, startTime) {\n        return fs$readdir(path, fs$readdirCallback(\n          path, options, cb, startTime\n        ))\n      }\n      : function go$readdir (path, options, cb, startTime) {\n        return fs$readdir(path, options, fs$readdirCallback(\n          path, options, cb, startTime\n        ))\n      }\n\n    return go$readdir(path, options, cb)\n\n    function fs$readdirCallback (path, options, cb, startTime) {\n      return function (err, files) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([\n            go$readdir,\n            [path, options, cb],\n            err,\n            startTime || Date.now(),\n            Date.now()\n          ])\n        else {\n          if (files && files.sort)\n            files.sort()\n\n          if (typeof cb === 'function')\n            cb.call(this, err, files)\n        }\n      }\n    }\n  }\n\n  if (process.version.substr(0, 4) === 'v0.8') {\n    var legStreams = legacy(fs)\n    ReadStream = legStreams.ReadStream\n    WriteStream = legStreams.WriteStream\n  }\n\n  var fs$ReadStream = fs.ReadStream\n  if (fs$ReadStream) {\n    ReadStream.prototype = Object.create(fs$ReadStream.prototype)\n    ReadStream.prototype.open = ReadStream$open\n  }\n\n  var fs$WriteStream = fs.WriteStream\n  if (fs$WriteStream) {\n    WriteStream.prototype = Object.create(fs$WriteStream.prototype)\n    WriteStream.prototype.open = WriteStream$open\n  }\n\n  Object.defineProperty(fs, 'ReadStream', {\n    get: function () {\n      return ReadStream\n    },\n    set: function (val) {\n      ReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  Object.defineProperty(fs, 'WriteStream', {\n    get: function () {\n      return WriteStream\n    },\n    set: function (val) {\n      WriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  // legacy names\n  var FileReadStream = ReadStream\n  Object.defineProperty(fs, 'FileReadStream', {\n    get: function () {\n      return FileReadStream\n    },\n    set: function (val) {\n      FileReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  var FileWriteStream = WriteStream\n  Object.defineProperty(fs, 'FileWriteStream', {\n    get: function () {\n      return FileWriteStream\n    },\n    set: function (val) {\n      FileWriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  function ReadStream (path, options) {\n    if (this instanceof ReadStream)\n      return fs$ReadStream.apply(this, arguments), this\n    else\n      return ReadStream.apply(Object.create(ReadStream.prototype), arguments)\n  }\n\n  function ReadStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        if (that.autoClose)\n          that.destroy()\n\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n        that.read()\n      }\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (this instanceof WriteStream)\n      return fs$WriteStream.apply(this, arguments), this\n    else\n      return WriteStream.apply(Object.create(WriteStream.prototype), arguments)\n  }\n\n  function WriteStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        that.destroy()\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n      }\n    })\n  }\n\n  function createReadStream (path, options) {\n    return new fs.ReadStream(path, options)\n  }\n\n  function createWriteStream (path, options) {\n    return new fs.WriteStream(path, options)\n  }\n\n  var fs$open = fs.open\n  fs.open = open\n  function open (path, flags, mode, cb) {\n    if (typeof mode === 'function')\n      cb = mode, mode = null\n\n    return go$open(path, flags, mode, cb)\n\n    function go$open (path, flags, mode, cb, startTime) {\n      return fs$open(path, flags, mode, function (err, fd) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$open, [path, flags, mode, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  return fs\n}\n\nfunction enqueue (elem) {\n  debug('ENQUEUE', elem[0].name, elem[1])\n  fs[gracefulQueue].push(elem)\n  retry()\n}\n\n// keep track of the timeout between retry() calls\nvar retryTimer\n\n// reset the startTime and lastTime to now\n// this resets the start of the 60 second overall timeout as well as the\n// delay between attempts so that we'll retry these jobs sooner\nfunction resetQueue () {\n  var now = Date.now()\n  for (var i = 0; i < fs[gracefulQueue].length; ++i) {\n    // entries that are only a length of 2 are from an older version, don't\n    // bother modifying those since they'll be retried anyway.\n    if (fs[gracefulQueue][i].length > 2) {\n      fs[gracefulQueue][i][3] = now // startTime\n      fs[gracefulQueue][i][4] = now // lastTime\n    }\n  }\n  // call retry to make sure we're actively processing the queue\n  retry()\n}\n\nfunction retry () {\n  // clear the timer and remove it to help prevent unintended concurrency\n  clearTimeout(retryTimer)\n  retryTimer = undefined\n\n  if (fs[gracefulQueue].length === 0)\n    return\n\n  var elem = fs[gracefulQueue].shift()\n  var fn = elem[0]\n  var args = elem[1]\n  // these items may be unset if they were added by an older graceful-fs\n  var err = elem[2]\n  var startTime = elem[3]\n  var lastTime = elem[4]\n\n  // if we don't have a startTime we have no way of knowing if we've waited\n  // long enough, so go ahead and retry this item now\n  if (startTime === undefined) {\n    debug('RETRY', fn.name, args)\n    fn.apply(null, args)\n  } else if (Date.now() - startTime >= 60000) {\n    // it's been more than 60 seconds total, bail now\n    debug('TIMEOUT', fn.name, args)\n    var cb = args.pop()\n    if (typeof cb === 'function')\n      cb.call(null, err)\n  } else {\n    // the amount of time between the last attempt and right now\n    var sinceAttempt = Date.now() - lastTime\n    // the amount of time between when we first tried, and when we last tried\n    // rounded up to at least 1\n    var sinceStart = Math.max(lastTime - startTime, 1)\n    // backoff. wait longer than the total time we've been retrying, but only\n    // up to a maximum of 100ms\n    var desiredDelay = Math.min(sinceStart * 1.2, 100)\n    // it's been long enough since the last retry, do it again\n    if (sinceAttempt >= desiredDelay) {\n      debug('RETRY', fn.name, args)\n      fn.apply(null, args.concat([startTime]))\n    } else {\n      // if we can't do this job yet, push it to the end of the queue\n      // and let the next iteration check again\n      fs[gracefulQueue].push(elem)\n    }\n  }\n\n  // schedule our next run if one isn't already scheduled\n  if (retryTimer === undefined) {\n    retryTimer = setTimeout(retry, 0)\n  }\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/graceful-fs/graceful-fs.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/legacy-streams.js":
/*!****************************************************!*\
  !*** ./node_modules/graceful-fs/legacy-streams.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Stream = (__webpack_require__(/*! stream */ \"stream\").Stream)\n\nmodule.exports = legacy\n\nfunction legacy (fs) {\n  return {\n    ReadStream: ReadStream,\n    WriteStream: WriteStream\n  }\n\n  function ReadStream (path, options) {\n    if (!(this instanceof ReadStream)) return new ReadStream(path, options);\n\n    Stream.call(this);\n\n    var self = this;\n\n    this.path = path;\n    this.fd = null;\n    this.readable = true;\n    this.paused = false;\n\n    this.flags = 'r';\n    this.mode = 438; /*=0666*/\n    this.bufferSize = 64 * 1024;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.encoding) this.setEncoding(this.encoding);\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.end === undefined) {\n        this.end = Infinity;\n      } else if ('number' !== typeof this.end) {\n        throw TypeError('end must be a Number');\n      }\n\n      if (this.start > this.end) {\n        throw new Error('start must be <= end');\n      }\n\n      this.pos = this.start;\n    }\n\n    if (this.fd !== null) {\n      process.nextTick(function() {\n        self._read();\n      });\n      return;\n    }\n\n    fs.open(this.path, this.flags, this.mode, function (err, fd) {\n      if (err) {\n        self.emit('error', err);\n        self.readable = false;\n        return;\n      }\n\n      self.fd = fd;\n      self.emit('open', fd);\n      self._read();\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (!(this instanceof WriteStream)) return new WriteStream(path, options);\n\n    Stream.call(this);\n\n    this.path = path;\n    this.fd = null;\n    this.writable = true;\n\n    this.flags = 'w';\n    this.encoding = 'binary';\n    this.mode = 438; /*=0666*/\n    this.bytesWritten = 0;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.start < 0) {\n        throw new Error('start must be >= zero');\n      }\n\n      this.pos = this.start;\n    }\n\n    this.busy = false;\n    this._queue = [];\n\n    if (this.fd === null) {\n      this._open = fs.open;\n      this._queue.push([this._open, this.path, this.flags, this.mode, undefined]);\n      this.flush();\n    }\n  }\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/graceful-fs/legacy-streams.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/polyfills.js":
/*!***********************************************!*\
  !*** ./node_modules/graceful-fs/polyfills.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var constants = __webpack_require__(/*! constants */ \"constants\")\n\nvar origCwd = process.cwd\nvar cwd = null\n\nvar platform = process.env.GRACEFUL_FS_PLATFORM || process.platform\n\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\ntry {\n  process.cwd()\n} catch (er) {}\n\n// This check is needed until node.js 12 is required\nif (typeof process.chdir === 'function') {\n  var chdir = process.chdir\n  process.chdir = function (d) {\n    cwd = null\n    chdir.call(process, d)\n  }\n  if (Object.setPrototypeOf) Object.setPrototypeOf(process.chdir, chdir)\n}\n\nmodule.exports = patch\n\nfunction patch (fs) {\n  // (re-)implement some things that are known busted or missing.\n\n  // lchmod, broken prior to 0.6.2\n  // back-port the fix here.\n  if (constants.hasOwnProperty('O_SYMLINK') &&\n      process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n    patchLchmod(fs)\n  }\n\n  // lutimes implementation, or no-op\n  if (!fs.lutimes) {\n    patchLutimes(fs)\n  }\n\n  // https://github.com/isaacs/node-graceful-fs/issues/4\n  // Chown should not fail on einval or eperm if non-root.\n  // It should not fail on enosys ever, as this just indicates\n  // that a fs doesn't support the intended operation.\n\n  fs.chown = chownFix(fs.chown)\n  fs.fchown = chownFix(fs.fchown)\n  fs.lchown = chownFix(fs.lchown)\n\n  fs.chmod = chmodFix(fs.chmod)\n  fs.fchmod = chmodFix(fs.fchmod)\n  fs.lchmod = chmodFix(fs.lchmod)\n\n  fs.chownSync = chownFixSync(fs.chownSync)\n  fs.fchownSync = chownFixSync(fs.fchownSync)\n  fs.lchownSync = chownFixSync(fs.lchownSync)\n\n  fs.chmodSync = chmodFixSync(fs.chmodSync)\n  fs.fchmodSync = chmodFixSync(fs.fchmodSync)\n  fs.lchmodSync = chmodFixSync(fs.lchmodSync)\n\n  fs.stat = statFix(fs.stat)\n  fs.fstat = statFix(fs.fstat)\n  fs.lstat = statFix(fs.lstat)\n\n  fs.statSync = statFixSync(fs.statSync)\n  fs.fstatSync = statFixSync(fs.fstatSync)\n  fs.lstatSync = statFixSync(fs.lstatSync)\n\n  // if lchmod/lchown do not exist, then make them no-ops\n  if (fs.chmod && !fs.lchmod) {\n    fs.lchmod = function (path, mode, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchmodSync = function () {}\n  }\n  if (fs.chown && !fs.lchown) {\n    fs.lchown = function (path, uid, gid, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchownSync = function () {}\n  }\n\n  // on Windows, A/V software can lock the directory, causing this\n  // to fail with an EACCES or EPERM if the directory contains newly\n  // created files.  Try again on failure, for up to 60 seconds.\n\n  // Set the timeout this long because some Windows Anti-Virus, such as Parity\n  // bit9, may lock files for up to a minute, causing npm package install\n  // failures. Also, take care to yield the scheduler. Windows scheduling gives\n  // CPU to a busy looping process, which can cause the program causing the lock\n  // contention to be starved of CPU by node, so the contention doesn't resolve.\n  if (platform === \"win32\") {\n    fs.rename = typeof fs.rename !== 'function' ? fs.rename\n    : (function (fs$rename) {\n      function rename (from, to, cb) {\n        var start = Date.now()\n        var backoff = 0;\n        fs$rename(from, to, function CB (er) {\n          if (er\n              && (er.code === \"EACCES\" || er.code === \"EPERM\")\n              && Date.now() - start < 60000) {\n            setTimeout(function() {\n              fs.stat(to, function (stater, st) {\n                if (stater && stater.code === \"ENOENT\")\n                  fs$rename(from, to, CB);\n                else\n                  cb(er)\n              })\n            }, backoff)\n            if (backoff < 100)\n              backoff += 10;\n            return;\n          }\n          if (cb) cb(er)\n        })\n      }\n      if (Object.setPrototypeOf) Object.setPrototypeOf(rename, fs$rename)\n      return rename\n    })(fs.rename)\n  }\n\n  // if read() returns EAGAIN, then just try it again.\n  fs.read = typeof fs.read !== 'function' ? fs.read\n  : (function (fs$read) {\n    function read (fd, buffer, offset, length, position, callback_) {\n      var callback\n      if (callback_ && typeof callback_ === 'function') {\n        var eagCounter = 0\n        callback = function (er, _, __) {\n          if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n            eagCounter ++\n            return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n          }\n          callback_.apply(this, arguments)\n        }\n      }\n      return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n    }\n\n    // This ensures `util.promisify` works as it does for native `fs.read`.\n    if (Object.setPrototypeOf) Object.setPrototypeOf(read, fs$read)\n    return read\n  })(fs.read)\n\n  fs.readSync = typeof fs.readSync !== 'function' ? fs.readSync\n  : (function (fs$readSync) { return function (fd, buffer, offset, length, position) {\n    var eagCounter = 0\n    while (true) {\n      try {\n        return fs$readSync.call(fs, fd, buffer, offset, length, position)\n      } catch (er) {\n        if (er.code === 'EAGAIN' && eagCounter < 10) {\n          eagCounter ++\n          continue\n        }\n        throw er\n      }\n    }\n  }})(fs.readSync)\n\n  function patchLchmod (fs) {\n    fs.lchmod = function (path, mode, callback) {\n      fs.open( path\n             , constants.O_WRONLY | constants.O_SYMLINK\n             , mode\n             , function (err, fd) {\n        if (err) {\n          if (callback) callback(err)\n          return\n        }\n        // prefer to return the chmod error, if one occurs,\n        // but still try to close, and report closing errors if they occur.\n        fs.fchmod(fd, mode, function (err) {\n          fs.close(fd, function(err2) {\n            if (callback) callback(err || err2)\n          })\n        })\n      })\n    }\n\n    fs.lchmodSync = function (path, mode) {\n      var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      var threw = true\n      var ret\n      try {\n        ret = fs.fchmodSync(fd, mode)\n        threw = false\n      } finally {\n        if (threw) {\n          try {\n            fs.closeSync(fd)\n          } catch (er) {}\n        } else {\n          fs.closeSync(fd)\n        }\n      }\n      return ret\n    }\n  }\n\n  function patchLutimes (fs) {\n    if (constants.hasOwnProperty(\"O_SYMLINK\") && fs.futimes) {\n      fs.lutimes = function (path, at, mt, cb) {\n        fs.open(path, constants.O_SYMLINK, function (er, fd) {\n          if (er) {\n            if (cb) cb(er)\n            return\n          }\n          fs.futimes(fd, at, mt, function (er) {\n            fs.close(fd, function (er2) {\n              if (cb) cb(er || er2)\n            })\n          })\n        })\n      }\n\n      fs.lutimesSync = function (path, at, mt) {\n        var fd = fs.openSync(path, constants.O_SYMLINK)\n        var ret\n        var threw = true\n        try {\n          ret = fs.futimesSync(fd, at, mt)\n          threw = false\n        } finally {\n          if (threw) {\n            try {\n              fs.closeSync(fd)\n            } catch (er) {}\n          } else {\n            fs.closeSync(fd)\n          }\n        }\n        return ret\n      }\n\n    } else if (fs.futimes) {\n      fs.lutimes = function (_a, _b, _c, cb) { if (cb) process.nextTick(cb) }\n      fs.lutimesSync = function () {}\n    }\n  }\n\n  function chmodFix (orig) {\n    if (!orig) return orig\n    return function (target, mode, cb) {\n      return orig.call(fs, target, mode, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chmodFixSync (orig) {\n    if (!orig) return orig\n    return function (target, mode) {\n      try {\n        return orig.call(fs, target, mode)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n\n  function chownFix (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid, cb) {\n      return orig.call(fs, target, uid, gid, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chownFixSync (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid) {\n      try {\n        return orig.call(fs, target, uid, gid)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n  function statFix (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options, cb) {\n      if (typeof options === 'function') {\n        cb = options\n        options = null\n      }\n      function callback (er, stats) {\n        if (stats) {\n          if (stats.uid < 0) stats.uid += 0x100000000\n          if (stats.gid < 0) stats.gid += 0x100000000\n        }\n        if (cb) cb.apply(this, arguments)\n      }\n      return options ? orig.call(fs, target, options, callback)\n        : orig.call(fs, target, callback)\n    }\n  }\n\n  function statFixSync (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options) {\n      var stats = options ? orig.call(fs, target, options)\n        : orig.call(fs, target)\n      if (stats) {\n        if (stats.uid < 0) stats.uid += 0x100000000\n        if (stats.gid < 0) stats.gid += 0x100000000\n      }\n      return stats;\n    }\n  }\n\n  // ENOSYS means that the fs doesn't support the op. Just ignore\n  // that, because it doesn't matter.\n  //\n  // if there's no getuid, or if getuid() is something other\n  // than 0, and the error is EINVAL or EPERM, then just ignore\n  // it.\n  //\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  //\n  // When running as root, or if other types of errors are\n  // encountered, then it's strict.\n  function chownErOk (er) {\n    if (!er)\n      return true\n\n    if (er.code === \"ENOSYS\")\n      return true\n\n    var nonroot = !process.getuid || process.getuid() !== 0\n    if (nonroot) {\n      if (er.code === \"EINVAL\" || er.code === \"EPERM\")\n        return true\n    }\n\n    return false\n  }\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/graceful-fs/polyfills.js?");

/***/ }),

/***/ "./node_modules/has-flag/index.js":
/*!****************************************!*\
  !*** ./node_modules/has-flag/index.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = (flag, argv = process.argv) => {\n\tconst prefix = flag.startsWith('-') ? '' : (flag.length === 1 ? '-' : '--');\n\tconst position = argv.indexOf(prefix + flag);\n\tconst terminatorPosition = argv.indexOf('--');\n\treturn position !== -1 && (terminatorPosition === -1 || position < terminatorPosition);\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/has-flag/index.js?");

/***/ }),

/***/ "./node_modules/jsonfile/index.js":
/*!****************************************!*\
  !*** ./node_modules/jsonfile/index.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("let _fs\ntry {\n  _fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\")\n} catch (_) {\n  _fs = __webpack_require__(/*! fs */ \"fs\")\n}\nconst universalify = __webpack_require__(/*! universalify */ \"./node_modules/universalify/index.js\")\nconst { stringify, stripBom } = __webpack_require__(/*! ./utils */ \"./node_modules/jsonfile/utils.js\")\n\nasync function _readFile (file, options = {}) {\n  if (typeof options === 'string') {\n    options = { encoding: options }\n  }\n\n  const fs = options.fs || _fs\n\n  const shouldThrow = 'throws' in options ? options.throws : true\n\n  let data = await universalify.fromCallback(fs.readFile)(file, options)\n\n  data = stripBom(data)\n\n  let obj\n  try {\n    obj = JSON.parse(data, options ? options.reviver : null)\n  } catch (err) {\n    if (shouldThrow) {\n      err.message = `${file}: ${err.message}`\n      throw err\n    } else {\n      return null\n    }\n  }\n\n  return obj\n}\n\nconst readFile = universalify.fromPromise(_readFile)\n\nfunction readFileSync (file, options = {}) {\n  if (typeof options === 'string') {\n    options = { encoding: options }\n  }\n\n  const fs = options.fs || _fs\n\n  const shouldThrow = 'throws' in options ? options.throws : true\n\n  try {\n    let content = fs.readFileSync(file, options)\n    content = stripBom(content)\n    return JSON.parse(content, options.reviver)\n  } catch (err) {\n    if (shouldThrow) {\n      err.message = `${file}: ${err.message}`\n      throw err\n    } else {\n      return null\n    }\n  }\n}\n\nasync function _writeFile (file, obj, options = {}) {\n  const fs = options.fs || _fs\n\n  const str = stringify(obj, options)\n\n  await universalify.fromCallback(fs.writeFile)(file, str, options)\n}\n\nconst writeFile = universalify.fromPromise(_writeFile)\n\nfunction writeFileSync (file, obj, options = {}) {\n  const fs = options.fs || _fs\n\n  const str = stringify(obj, options)\n  // not sure if fs.writeFileSync returns anything, but just in case\n  return fs.writeFileSync(file, str, options)\n}\n\nconst jsonfile = {\n  readFile,\n  readFileSync,\n  writeFile,\n  writeFileSync\n}\n\nmodule.exports = jsonfile\n\n\n//# sourceURL=webpack://udan-react/./node_modules/jsonfile/index.js?");

/***/ }),

/***/ "./node_modules/jsonfile/utils.js":
/*!****************************************!*\
  !*** ./node_modules/jsonfile/utils.js ***!
  \****************************************/
/***/ ((module) => {

eval("function stringify (obj, { EOL = '\\n', finalEOL = true, replacer = null, spaces } = {}) {\n  const EOF = finalEOL ? EOL : ''\n  const str = JSON.stringify(obj, replacer, spaces)\n\n  return str.replace(/\\n/g, EOL) + EOF\n}\n\nfunction stripBom (content) {\n  // we do this because JSON.parse would convert it to a utf8 string if encoding wasn't specified\n  if (Buffer.isBuffer(content)) content = content.toString('utf8')\n  return content.replace(/^\\uFEFF/, '')\n}\n\nmodule.exports = { stringify, stripBom }\n\n\n//# sourceURL=webpack://udan-react/./node_modules/jsonfile/utils.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/LoggingEvent.js":
/*!*************************************************!*\
  !*** ./node_modules/log4js/lib/LoggingEvent.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const flatted = __webpack_require__(/*! flatted */ \"./node_modules/flatted/cjs/index.js\");\nconst levels = __webpack_require__(/*! ./levels */ \"./node_modules/log4js/lib/levels.js\");\n\n/**\n * @name LoggingEvent\n * @namespace Log4js\n */\nclass LoggingEvent {\n  /**\n   * Models a logging event.\n   * @constructor\n   * @param {string} categoryName name of category\n   * @param {Log4js.Level} level level of message\n   * @param {Array} data objects to log\n   * @author Seth Chisamore\n   */\n  constructor(categoryName, level, data, context, location) {\n    this.startTime = new Date();\n    this.categoryName = categoryName;\n    this.data = data;\n    this.level = level;\n    this.context = Object.assign({}, context); // eslint-disable-line prefer-object-spread\n    this.pid = process.pid;\n\n    if (location) {\n      this.functionName = location.functionName;\n      this.fileName = location.fileName;\n      this.lineNumber = location.lineNumber;\n      this.columnNumber = location.columnNumber;\n      this.callStack = location.callStack;\n    }\n  }\n\n  serialise() {\n    return flatted.stringify(this, (key, value) => {\n      // JSON.stringify(new Error('test')) returns {}, which is not really useful for us.\n      // The following allows us to serialize errors correctly.\n      // duck-typing for Error object\n      if (value && value.message && value.stack) {\n        // eslint-disable-next-line prefer-object-spread\n        value = Object.assign(\n          { message: value.message, stack: value.stack },\n          value\n        );\n      }\n      // JSON.stringify({a: parseInt('abc'), b: 1/0, c: -1/0}) returns {a: null, b: null, c: null}.\n      // The following allows us to serialize to NaN, Infinity and -Infinity correctly.\n      else if (\n        typeof value === 'number' &&\n        (Number.isNaN(value) || !Number.isFinite(value))\n      ) {\n        value = value.toString();\n      }\n      // JSON.stringify([undefined]) returns [null].\n      // The following allows us to serialize to undefined correctly.\n      else if (typeof value === 'undefined') {\n        value = typeof value;\n      }\n      return value;\n    });\n  }\n\n  static deserialise(serialised) {\n    let event;\n    try {\n      const rehydratedEvent = flatted.parse(serialised, (key, value) => {\n        if (value && value.message && value.stack) {\n          const fakeError = new Error(value);\n          Object.keys(value).forEach((k) => {\n            fakeError[k] = value[k];\n          });\n          value = fakeError;\n        }\n        return value;\n      });\n      rehydratedEvent.location = {\n        functionName: rehydratedEvent.functionName,\n        fileName: rehydratedEvent.fileName,\n        lineNumber: rehydratedEvent.lineNumber,\n        columnNumber: rehydratedEvent.columnNumber,\n        callStack: rehydratedEvent.callStack,\n      };\n      event = new LoggingEvent(\n        rehydratedEvent.categoryName,\n        levels.getLevel(rehydratedEvent.level.levelStr),\n        rehydratedEvent.data,\n        rehydratedEvent.context,\n        rehydratedEvent.location\n      );\n      event.startTime = new Date(rehydratedEvent.startTime);\n      event.pid = rehydratedEvent.pid;\n      event.cluster = rehydratedEvent.cluster;\n    } catch (e) {\n      event = new LoggingEvent('log4js', levels.ERROR, [\n        'Unable to parse log:',\n        serialised,\n        'because: ',\n        e,\n      ]);\n    }\n\n    return event;\n  }\n}\n\nmodule.exports = LoggingEvent;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/LoggingEvent.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/adapters.js":
/*!*******************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/adapters.js ***!
  \*******************************************************/
/***/ ((module) => {

eval("function maxFileSizeUnitTransform(maxLogSize) {\n  if (typeof maxLogSize === 'number' && Number.isInteger(maxLogSize)) {\n    return maxLogSize;\n  }\n\n  const units = {\n    K: 1024,\n    M: 1024 * 1024,\n    G: 1024 * 1024 * 1024,\n  };\n  const validUnit = Object.keys(units);\n  const unit = maxLogSize.slice(-1).toLocaleUpperCase();\n  const value = maxLogSize.slice(0, -1).trim();\n\n  if (validUnit.indexOf(unit) < 0 || !Number.isInteger(Number(value))) {\n    throw Error(`maxLogSize: \"${maxLogSize}\" is invalid`);\n  } else {\n    return value * units[unit];\n  }\n}\n\nfunction adapter(configAdapter, config) {\n  const newConfig = Object.assign({}, config); // eslint-disable-line prefer-object-spread\n  Object.keys(configAdapter).forEach((key) => {\n    if (newConfig[key]) {\n      newConfig[key] = configAdapter[key](config[key]);\n    }\n  });\n  return newConfig;\n}\n\nfunction fileAppenderAdapter(config) {\n  const configAdapter = {\n    maxLogSize: maxFileSizeUnitTransform,\n  };\n  return adapter(configAdapter, config);\n}\n\nconst adapters = {\n  dateFile: fileAppenderAdapter,\n  file: fileAppenderAdapter,\n  fileSync: fileAppenderAdapter,\n};\n\nmodule.exports.modifyConfig = (config) =>\n  adapters[config.type] ? adapters[config.type](config) : config;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/adapters.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/categoryFilter.js":
/*!*************************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/categoryFilter.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:categoryFilter');\n\nfunction categoryFilter(excludes, appender) {\n  if (typeof excludes === 'string') excludes = [excludes];\n  return (logEvent) => {\n    debug(`Checking ${logEvent.categoryName} against ${excludes}`);\n    if (excludes.indexOf(logEvent.categoryName) === -1) {\n      debug('Not excluded, sending to appender');\n      appender(logEvent);\n    }\n  };\n}\n\nfunction configure(config, layouts, findAppender) {\n  const appender = findAppender(config.appender);\n  return categoryFilter(config.exclude, appender);\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/categoryFilter.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/console.js":
/*!******************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/console.js ***!
  \******************************************************/
/***/ ((module) => {

eval("// eslint-disable-next-line no-console\nconst consoleLog = console.log.bind(console);\n\nfunction consoleAppender(layout, timezoneOffset) {\n  return (loggingEvent) => {\n    consoleLog(layout(loggingEvent, timezoneOffset));\n  };\n}\n\nfunction configure(config, layouts) {\n  let layout = layouts.colouredLayout;\n  if (config.layout) {\n    layout = layouts.layout(config.layout.type, config.layout);\n  }\n  return consoleAppender(layout, config.timezoneOffset);\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/console.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/dateFile.js":
/*!*******************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/dateFile.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const streams = __webpack_require__(/*! streamroller */ \"./node_modules/streamroller/lib/index.js\");\nconst os = __webpack_require__(/*! os */ \"os\");\n\nconst eol = os.EOL;\n\nfunction openTheStream(filename, pattern, options) {\n  const stream = new streams.DateRollingFileStream(filename, pattern, options);\n  stream.on('error', (err) => {\n    // eslint-disable-next-line no-console\n    console.error(\n      'log4js.dateFileAppender - Writing to file %s, error happened ',\n      filename,\n      err\n    );\n  });\n  stream.on('drain', () => {\n    process.emit('log4js:pause', false);\n  });\n  return stream;\n}\n\n/**\n * File appender that rolls files according to a date pattern.\n * @param filename base filename.\n * @param pattern the format that will be added to the end of filename when rolling,\n *          also used to check when to roll files - defaults to '.yyyy-MM-dd'\n * @param layout layout function for log messages - defaults to basicLayout\n * @param options - options to be passed to the underlying stream\n * @param timezoneOffset - optional timezone offset in minutes (default system local)\n */\nfunction appender(filename, pattern, layout, options, timezoneOffset) {\n  // the options for file appender use maxLogSize, but the docs say any file appender\n  // options should work for dateFile as well.\n  options.maxSize = options.maxLogSize;\n\n  const writer = openTheStream(filename, pattern, options);\n\n  const app = function (logEvent) {\n    if (!writer.writable) {\n      return;\n    }\n    if (!writer.write(layout(logEvent, timezoneOffset) + eol, 'utf8')) {\n      process.emit('log4js:pause', true);\n    }\n  };\n\n  app.shutdown = function (complete) {\n    writer.end('', 'utf-8', complete);\n  };\n\n  return app;\n}\n\nfunction configure(config, layouts) {\n  let layout = layouts.basicLayout;\n  if (config.layout) {\n    layout = layouts.layout(config.layout.type, config.layout);\n  }\n\n  if (!config.alwaysIncludePattern) {\n    config.alwaysIncludePattern = false;\n  }\n\n  // security default (instead of relying on streamroller default)\n  config.mode = config.mode || 0o600;\n\n  return appender(\n    config.filename,\n    config.pattern,\n    layout,\n    config,\n    config.timezoneOffset\n  );\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/dateFile.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/file.js":
/*!***************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/file.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:file');\nconst path = __webpack_require__(/*! path */ \"path\");\nconst streams = __webpack_require__(/*! streamroller */ \"./node_modules/streamroller/lib/index.js\");\nconst os = __webpack_require__(/*! os */ \"os\");\n\nconst eol = os.EOL;\n\nlet mainSighupListenerStarted = false;\nconst sighupListeners = new Set();\nfunction mainSighupHandler() {\n  sighupListeners.forEach((app) => {\n    app.sighupHandler();\n  });\n}\n\n/**\n * File Appender writing the logs to a text file. Supports rolling of logs by size.\n *\n * @param file the file log messages will be written to\n * @param layout a function that takes a logEvent and returns a string\n *   (defaults to basicLayout).\n * @param logSize - the maximum size (in bytes) for a log file,\n *   if not provided then logs won't be rotated.\n * @param numBackups - the number of log files to keep after logSize\n *   has been reached (default 5)\n * @param options - options to be passed to the underlying stream\n * @param timezoneOffset - optional timezone offset in minutes (default system local)\n */\nfunction fileAppender(\n  file,\n  layout,\n  logSize,\n  numBackups,\n  options,\n  timezoneOffset\n) {\n  if (typeof file !== 'string' || file.length === 0) {\n    throw new Error(`Invalid filename: ${file}`);\n  } else if (file.endsWith(path.sep)) {\n    throw new Error(`Filename is a directory: ${file}`);\n  } else {\n    // handle ~ expansion: https://github.com/nodejs/node/issues/684\n    // exclude ~ and ~filename as these can be valid files\n    file = file.replace(new RegExp(`^~(?=${path.sep}.+)`), os.homedir());\n  }\n  file = path.normalize(file);\n  numBackups = !numBackups && numBackups !== 0 ? 5 : numBackups;\n\n  debug(\n    'Creating file appender (',\n    file,\n    ', ',\n    logSize,\n    ', ',\n    numBackups,\n    ', ',\n    options,\n    ', ',\n    timezoneOffset,\n    ')'\n  );\n\n  function openTheStream(filePath, fileSize, numFiles, opt) {\n    const stream = new streams.RollingFileStream(\n      filePath,\n      fileSize,\n      numFiles,\n      opt\n    );\n    stream.on('error', (err) => {\n      // eslint-disable-next-line no-console\n      console.error(\n        'log4js.fileAppender - Writing to file %s, error happened ',\n        filePath,\n        err\n      );\n    });\n    stream.on('drain', () => {\n      process.emit('log4js:pause', false);\n    });\n    return stream;\n  }\n\n  let writer = openTheStream(file, logSize, numBackups, options);\n\n  const app = function (loggingEvent) {\n    if (!writer.writable) {\n      return;\n    }\n    if (options.removeColor === true) {\n      // eslint-disable-next-line no-control-regex\n      const regex = /\\x1b[[0-9;]*m/g;\n      loggingEvent.data = loggingEvent.data.map((d) => {\n        if (typeof d === 'string') return d.replace(regex, '');\n        return d;\n      });\n    }\n    if (!writer.write(layout(loggingEvent, timezoneOffset) + eol, 'utf8')) {\n      process.emit('log4js:pause', true);\n    }\n  };\n\n  app.reopen = function () {\n    writer.end(() => {\n      writer = openTheStream(file, logSize, numBackups, options);\n    });\n  };\n\n  app.sighupHandler = function () {\n    debug('SIGHUP handler called.');\n    app.reopen();\n  };\n\n  app.shutdown = function (complete) {\n    sighupListeners.delete(app);\n    if (sighupListeners.size === 0 && mainSighupListenerStarted) {\n      process.removeListener('SIGHUP', mainSighupHandler);\n      mainSighupListenerStarted = false;\n    }\n    writer.end('', 'utf-8', complete);\n  };\n\n  // On SIGHUP, close and reopen all files. This allows this appender to work with\n  // logrotate. Note that if you are using logrotate, you should not set\n  // `logSize`.\n  sighupListeners.add(app);\n  if (!mainSighupListenerStarted) {\n    process.on('SIGHUP', mainSighupHandler);\n    mainSighupListenerStarted = true;\n  }\n\n  return app;\n}\n\nfunction configure(config, layouts) {\n  let layout = layouts.basicLayout;\n  if (config.layout) {\n    layout = layouts.layout(config.layout.type, config.layout);\n  }\n\n  // security default (instead of relying on streamroller default)\n  config.mode = config.mode || 0o600;\n\n  return fileAppender(\n    config.filename,\n    layout,\n    config.maxLogSize,\n    config.backups,\n    config,\n    config.timezoneOffset\n  );\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/file.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/fileSync.js":
/*!*******************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/fileSync.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:fileSync');\nconst path = __webpack_require__(/*! path */ \"path\");\nconst fs = __webpack_require__(/*! fs */ \"fs\");\nconst os = __webpack_require__(/*! os */ \"os\");\n\nconst eol = os.EOL;\n\nfunction touchFile(file, options) {\n  // attempt to create the directory\n  const mkdir = (dir) => {\n    try {\n      return fs.mkdirSync(dir, { recursive: true });\n    } catch (e) {\n      // backward-compatible fs.mkdirSync for nodejs pre-10.12.0 (without recursive option)\n      // recursive creation of parent first\n      if (e.code === 'ENOENT') {\n        mkdir(path.dirname(dir));\n        return mkdir(dir);\n      }\n\n      // throw error for all except EEXIST and EROFS (read-only filesystem)\n      if (e.code !== 'EEXIST' && e.code !== 'EROFS') {\n        throw e;\n      }\n\n      // EEXIST: throw if file and not directory\n      // EROFS : throw if directory not found\n      else {\n        try {\n          if (fs.statSync(dir).isDirectory()) {\n            return dir;\n          }\n          throw e;\n        } catch (err) {\n          throw e;\n        }\n      }\n    }\n  };\n  mkdir(path.dirname(file));\n\n  // try to throw EISDIR, EROFS, EACCES\n  fs.appendFileSync(file, '', { mode: options.mode, flag: options.flags });\n}\n\nclass RollingFileSync {\n  constructor(filename, maxLogSize, backups, options) {\n    debug('In RollingFileStream');\n\n    if (maxLogSize < 0) {\n      throw new Error(`maxLogSize (${maxLogSize}) should be > 0`);\n    }\n\n    this.filename = filename;\n    this.size = maxLogSize;\n    this.backups = backups;\n    this.options = options;\n    this.currentSize = 0;\n\n    function currentFileSize(file) {\n      let fileSize = 0;\n\n      try {\n        fileSize = fs.statSync(file).size;\n      } catch (e) {\n        // file does not exist\n        touchFile(file, options);\n      }\n      return fileSize;\n    }\n\n    this.currentSize = currentFileSize(this.filename);\n  }\n\n  shouldRoll() {\n    debug(\n      'should roll with current size %d, and max size %d',\n      this.currentSize,\n      this.size\n    );\n    return this.currentSize >= this.size;\n  }\n\n  roll(filename) {\n    const that = this;\n    const nameMatcher = new RegExp(`^${path.basename(filename)}`);\n\n    function justTheseFiles(item) {\n      return nameMatcher.test(item);\n    }\n\n    function index(filename_) {\n      return (\n        parseInt(filename_.slice(`${path.basename(filename)}.`.length), 10) || 0\n      );\n    }\n\n    function byIndex(a, b) {\n      return index(a) - index(b);\n    }\n\n    function increaseFileIndex(fileToRename) {\n      const idx = index(fileToRename);\n      debug(`Index of ${fileToRename} is ${idx}`);\n      if (that.backups === 0) {\n        fs.truncateSync(filename, 0);\n      } else if (idx < that.backups) {\n        // on windows, you can get a EEXIST error if you rename a file to an existing file\n        // so, we'll try to delete the file we're renaming to first\n        try {\n          fs.unlinkSync(`${filename}.${idx + 1}`);\n        } catch (e) {\n          // ignore err: if we could not delete, it's most likely that it doesn't exist\n        }\n\n        debug(`Renaming ${fileToRename} -> ${filename}.${idx + 1}`);\n        fs.renameSync(\n          path.join(path.dirname(filename), fileToRename),\n          `${filename}.${idx + 1}`\n        );\n      }\n    }\n\n    function renameTheFiles() {\n      // roll the backups (rename file.n to file.n+1, where n <= numBackups)\n      debug('Renaming the old files');\n\n      const files = fs.readdirSync(path.dirname(filename));\n      files\n        .filter(justTheseFiles)\n        .sort(byIndex)\n        .reverse()\n        .forEach(increaseFileIndex);\n    }\n\n    debug('Rolling, rolling, rolling');\n    renameTheFiles();\n  }\n\n  // eslint-disable-next-line no-unused-vars\n  write(chunk, encoding) {\n    const that = this;\n\n    function writeTheChunk() {\n      debug('writing the chunk to the file');\n      that.currentSize += chunk.length;\n      fs.appendFileSync(that.filename, chunk);\n    }\n\n    debug('in write');\n\n    if (this.shouldRoll()) {\n      this.currentSize = 0;\n      this.roll(this.filename);\n    }\n\n    writeTheChunk();\n  }\n}\n\n/**\n * File Appender writing the logs to a text file. Supports rolling of logs by size.\n *\n * @param file the file log messages will be written to\n * @param layout a function that takes a logevent and returns a string\n *   (defaults to basicLayout).\n * @param logSize - the maximum size (in bytes) for a log file,\n *   if not provided then logs won't be rotated.\n * @param numBackups - the number of log files to keep after logSize\n *   has been reached (default 5)\n * @param options - options to be passed to the underlying stream\n * @param timezoneOffset - optional timezone offset in minutes (default system local)\n */\nfunction fileAppender(\n  file,\n  layout,\n  logSize,\n  numBackups,\n  options,\n  timezoneOffset\n) {\n  if (typeof file !== 'string' || file.length === 0) {\n    throw new Error(`Invalid filename: ${file}`);\n  } else if (file.endsWith(path.sep)) {\n    throw new Error(`Filename is a directory: ${file}`);\n  } else {\n    // handle ~ expansion: https://github.com/nodejs/node/issues/684\n    // exclude ~ and ~filename as these can be valid files\n    file = file.replace(new RegExp(`^~(?=${path.sep}.+)`), os.homedir());\n  }\n  file = path.normalize(file);\n  numBackups = !numBackups && numBackups !== 0 ? 5 : numBackups;\n\n  debug(\n    'Creating fileSync appender (',\n    file,\n    ', ',\n    logSize,\n    ', ',\n    numBackups,\n    ', ',\n    options,\n    ', ',\n    timezoneOffset,\n    ')'\n  );\n\n  function openTheStream(filePath, fileSize, numFiles) {\n    let stream;\n\n    if (fileSize) {\n      stream = new RollingFileSync(filePath, fileSize, numFiles, options);\n    } else {\n      stream = ((f) => {\n        // touch the file to apply flags (like w to truncate the file)\n        touchFile(f, options);\n\n        return {\n          write(data) {\n            fs.appendFileSync(f, data);\n          },\n        };\n      })(filePath);\n    }\n\n    return stream;\n  }\n\n  const logFile = openTheStream(file, logSize, numBackups);\n\n  return (loggingEvent) => {\n    logFile.write(layout(loggingEvent, timezoneOffset) + eol);\n  };\n}\n\nfunction configure(config, layouts) {\n  let layout = layouts.basicLayout;\n  if (config.layout) {\n    layout = layouts.layout(config.layout.type, config.layout);\n  }\n\n  const options = {\n    flags: config.flags || 'a',\n    encoding: config.encoding || 'utf8',\n    mode: config.mode || 0o600,\n  };\n\n  return fileAppender(\n    config.filename,\n    layout,\n    config.maxLogSize,\n    config.backups,\n    options,\n    config.timezoneOffset\n  );\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/fileSync.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/index.js":
/*!****************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/index.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const path = __webpack_require__(/*! path */ \"path\");\nconst debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:appenders');\nconst configuration = __webpack_require__(/*! ../configuration */ \"./node_modules/log4js/lib/configuration.js\");\nconst clustering = __webpack_require__(/*! ../clustering */ \"./node_modules/log4js/lib/clustering.js\");\nconst levels = __webpack_require__(/*! ../levels */ \"./node_modules/log4js/lib/levels.js\");\nconst layouts = __webpack_require__(/*! ../layouts */ \"./node_modules/log4js/lib/layouts.js\");\nconst adapters = __webpack_require__(/*! ./adapters */ \"./node_modules/log4js/lib/appenders/adapters.js\");\n\n// pre-load the core appenders so that webpack can find them\nconst coreAppenders = new Map();\ncoreAppenders.set('console', __webpack_require__(/*! ./console */ \"./node_modules/log4js/lib/appenders/console.js\"));\ncoreAppenders.set('stdout', __webpack_require__(/*! ./stdout */ \"./node_modules/log4js/lib/appenders/stdout.js\"));\ncoreAppenders.set('stderr', __webpack_require__(/*! ./stderr */ \"./node_modules/log4js/lib/appenders/stderr.js\"));\ncoreAppenders.set('logLevelFilter', __webpack_require__(/*! ./logLevelFilter */ \"./node_modules/log4js/lib/appenders/logLevelFilter.js\"));\ncoreAppenders.set('categoryFilter', __webpack_require__(/*! ./categoryFilter */ \"./node_modules/log4js/lib/appenders/categoryFilter.js\"));\ncoreAppenders.set('noLogFilter', __webpack_require__(/*! ./noLogFilter */ \"./node_modules/log4js/lib/appenders/noLogFilter.js\"));\ncoreAppenders.set('file', __webpack_require__(/*! ./file */ \"./node_modules/log4js/lib/appenders/file.js\"));\ncoreAppenders.set('dateFile', __webpack_require__(/*! ./dateFile */ \"./node_modules/log4js/lib/appenders/dateFile.js\"));\ncoreAppenders.set('fileSync', __webpack_require__(/*! ./fileSync */ \"./node_modules/log4js/lib/appenders/fileSync.js\"));\ncoreAppenders.set('tcp', __webpack_require__(/*! ./tcp */ \"./node_modules/log4js/lib/appenders/tcp.js\"));\n\nconst appenders = new Map();\n\nconst tryLoading = (modulePath, config) => {\n  let resolvedPath;\n  try {\n    const modulePathCJS = `${modulePath}.cjs`;\n    resolvedPath = /*require.resolve*/(__webpack_require__(\"./node_modules/log4js/lib/appenders sync recursive\").resolve(modulePathCJS));\n    debug('Loading module from ', modulePathCJS);\n  } catch (e) {\n    resolvedPath = modulePath;\n    debug('Loading module from ', modulePath);\n  }\n  try {\n    // eslint-disable-next-line global-require, import/no-dynamic-require\n    return __webpack_require__(\"./node_modules/log4js/lib/appenders sync recursive\")(resolvedPath);\n  } catch (e) {\n    // if the module was found, and we still got an error, then raise it\n    configuration.throwExceptionIf(\n      config,\n      e.code !== 'MODULE_NOT_FOUND',\n      `appender \"${modulePath}\" could not be loaded (error was: ${e})`\n    );\n    return undefined;\n  }\n};\n\nconst loadAppenderModule = (type, config) =>\n  coreAppenders.get(type) ||\n  tryLoading(`./${type}`, config) ||\n  tryLoading(type, config) ||\n  (__webpack_require__.c[__webpack_require__.s] &&\n    __webpack_require__.c[__webpack_require__.s].filename &&\n    tryLoading(path.join(path.dirname(__webpack_require__.c[__webpack_require__.s].filename), type), config)) ||\n  tryLoading(path.join(process.cwd(), type), config);\n\nconst appendersLoading = new Set();\n\nconst getAppender = (name, config) => {\n  if (appenders.has(name)) return appenders.get(name);\n  if (!config.appenders[name]) return false;\n  if (appendersLoading.has(name))\n    throw new Error(`Dependency loop detected for appender ${name}.`);\n  appendersLoading.add(name);\n\n  debug(`Creating appender ${name}`);\n  // eslint-disable-next-line no-use-before-define\n  const appender = createAppender(name, config);\n  appendersLoading.delete(name);\n  appenders.set(name, appender);\n  return appender;\n};\n\nconst createAppender = (name, config) => {\n  const appenderConfig = config.appenders[name];\n  const appenderModule = appenderConfig.type.configure\n    ? appenderConfig.type\n    : loadAppenderModule(appenderConfig.type, config);\n  configuration.throwExceptionIf(\n    config,\n    configuration.not(appenderModule),\n    `appender \"${name}\" is not valid (type \"${appenderConfig.type}\" could not be found)`\n  );\n  if (appenderModule.appender) {\n    process.emitWarning(\n      `Appender ${appenderConfig.type} exports an appender function.`,\n      'DeprecationWarning',\n      'log4js-node-DEP0001'\n    );\n    debug(\n      '[log4js-node-DEP0001]',\n      `DEPRECATION: Appender ${appenderConfig.type} exports an appender function.`\n    );\n  }\n  if (appenderModule.shutdown) {\n    process.emitWarning(\n      `Appender ${appenderConfig.type} exports a shutdown function.`,\n      'DeprecationWarning',\n      'log4js-node-DEP0002'\n    );\n    debug(\n      '[log4js-node-DEP0002]',\n      `DEPRECATION: Appender ${appenderConfig.type} exports a shutdown function.`\n    );\n  }\n\n  debug(`${name}: clustering.isMaster ? ${clustering.isMaster()}`);\n  debug(\n    // eslint-disable-next-line global-require\n    `${name}: appenderModule is ${(__webpack_require__(/*! util */ \"util\").inspect)(appenderModule)}`\n  );\n  return clustering.onlyOnMaster(\n    () => {\n      debug(\n        `calling appenderModule.configure for ${name} / ${appenderConfig.type}`\n      );\n      return appenderModule.configure(\n        adapters.modifyConfig(appenderConfig),\n        layouts,\n        (appender) => getAppender(appender, config),\n        levels\n      );\n    },\n    /* istanbul ignore next: fn never gets called by non-master yet needed to pass config validation */ () => {}\n  );\n};\n\nconst setup = (config) => {\n  appenders.clear();\n  appendersLoading.clear();\n  if (!config) {\n    return;\n  }\n\n  const usedAppenders = [];\n  Object.values(config.categories).forEach((category) => {\n    usedAppenders.push(...category.appenders);\n  });\n  Object.keys(config.appenders).forEach((name) => {\n    // dodgy hard-coding of special case for tcp-server and multiprocess which may not have\n    // any categories associated with it, but needs to be started up anyway\n    if (\n      usedAppenders.includes(name) ||\n      config.appenders[name].type === 'tcp-server' ||\n      config.appenders[name].type === 'multiprocess'\n    ) {\n      getAppender(name, config);\n    }\n  });\n};\n\nconst init = () => {\n  setup();\n};\ninit();\n\nconfiguration.addListener((config) => {\n  configuration.throwExceptionIf(\n    config,\n    configuration.not(configuration.anObject(config.appenders)),\n    'must have a property \"appenders\" of type object.'\n  );\n  const appenderNames = Object.keys(config.appenders);\n  configuration.throwExceptionIf(\n    config,\n    configuration.not(appenderNames.length),\n    'must define at least one appender.'\n  );\n\n  appenderNames.forEach((name) => {\n    configuration.throwExceptionIf(\n      config,\n      configuration.not(config.appenders[name].type),\n      `appender \"${name}\" is not valid (must be an object with property \"type\")`\n    );\n  });\n});\n\nconfiguration.addListener(setup);\n\nmodule.exports = appenders;\nmodule.exports.init = init;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/index.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/logLevelFilter.js":
/*!*************************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/logLevelFilter.js ***!
  \*************************************************************/
/***/ ((module) => {

eval("function logLevelFilter(minLevelString, maxLevelString, appender, levels) {\n  const minLevel = levels.getLevel(minLevelString);\n  const maxLevel = levels.getLevel(maxLevelString, levels.FATAL);\n  return (logEvent) => {\n    const eventLevel = logEvent.level;\n    if (\n      minLevel.isLessThanOrEqualTo(eventLevel) &&\n      maxLevel.isGreaterThanOrEqualTo(eventLevel)\n    ) {\n      appender(logEvent);\n    }\n  };\n}\n\nfunction configure(config, layouts, findAppender, levels) {\n  const appender = findAppender(config.appender);\n  return logLevelFilter(config.level, config.maxLevel, appender, levels);\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/logLevelFilter.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/noLogFilter.js":
/*!**********************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/noLogFilter.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:noLogFilter');\n\n/**\n * The function removes empty or null regexp from the array\n * @param {string[]} regexp\n * @returns {string[]} a filtered string array with not empty or null regexp\n */\nfunction removeNullOrEmptyRegexp(regexp) {\n  const filtered = regexp.filter((el) => el != null && el !== '');\n  return filtered;\n}\n\n/**\n * Returns a function that will exclude the events in case they match\n * with the regular expressions provided\n * @param {(string|string[])} filters contains the regexp that will be used for the evaluation\n * @param {*} appender\n * @returns {function}\n */\nfunction noLogFilter(filters, appender) {\n  return (logEvent) => {\n    debug(`Checking data: ${logEvent.data} against filters: ${filters}`);\n    if (typeof filters === 'string') {\n      filters = [filters];\n    }\n    filters = removeNullOrEmptyRegexp(filters);\n    const regex = new RegExp(filters.join('|'), 'i');\n    if (\n      filters.length === 0 ||\n      logEvent.data.findIndex((value) => regex.test(value)) < 0\n    ) {\n      debug('Not excluded, sending to appender');\n      appender(logEvent);\n    }\n  };\n}\n\nfunction configure(config, layouts, findAppender) {\n  const appender = findAppender(config.appender);\n  return noLogFilter(config.exclude, appender);\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/noLogFilter.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/recording.js":
/*!********************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/recording.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:recording');\n\nconst recordedEvents = [];\n\nfunction configure() {\n  return function (logEvent) {\n    debug(\n      `received logEvent, number of events now ${recordedEvents.length + 1}`\n    );\n    debug('log event was ', logEvent);\n    recordedEvents.push(logEvent);\n  };\n}\n\nfunction replay() {\n  return recordedEvents.slice();\n}\n\nfunction reset() {\n  recordedEvents.length = 0;\n}\n\nmodule.exports = {\n  configure,\n  replay,\n  playback: replay,\n  reset,\n  erase: reset,\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/recording.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/stderr.js":
/*!*****************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/stderr.js ***!
  \*****************************************************/
/***/ ((module) => {

eval("function stderrAppender(layout, timezoneOffset) {\n  return (loggingEvent) => {\n    process.stderr.write(`${layout(loggingEvent, timezoneOffset)}\\n`);\n  };\n}\n\nfunction configure(config, layouts) {\n  let layout = layouts.colouredLayout;\n  if (config.layout) {\n    layout = layouts.layout(config.layout.type, config.layout);\n  }\n  return stderrAppender(layout, config.timezoneOffset);\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/stderr.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/stdout.js":
/*!*****************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/stdout.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {

eval("function stdoutAppender(layout, timezoneOffset) {\n  return (loggingEvent) => {\n    process.stdout.write(`${layout(loggingEvent, timezoneOffset)}\\n`);\n  };\n}\n\nfunction configure(config, layouts) {\n  let layout = layouts.colouredLayout;\n  if (config.layout) {\n    layout = layouts.layout(config.layout.type, config.layout);\n  }\n  return stdoutAppender(layout, config.timezoneOffset);\n}\n\nexports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/stdout.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders/tcp.js":
/*!**************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/tcp.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:tcp');\nconst net = __webpack_require__(/*! net */ \"net\");\n\nfunction appender(config, layout) {\n  let canWrite = false;\n  const buffer = [];\n  let socket;\n  let shutdownAttempts = 3;\n  let endMsg = '__LOG4JS__';\n\n  function write(loggingEvent) {\n    debug('Writing log event to socket');\n    canWrite = socket.write(`${layout(loggingEvent)}${endMsg}`, 'utf8');\n  }\n\n  function emptyBuffer() {\n    let evt;\n    debug('emptying buffer');\n    while ((evt = buffer.shift())) {\n      write(evt);\n    }\n  }\n\n  function createSocket() {\n    debug(\n      `appender creating socket to ${config.host || 'localhost'}:${\n        config.port || 5000\n      }`\n    );\n    endMsg = `${config.endMsg || '__LOG4JS__'}`;\n    socket = net.createConnection(\n      config.port || 5000,\n      config.host || 'localhost'\n    );\n    socket.on('connect', () => {\n      debug('socket connected');\n      emptyBuffer();\n      canWrite = true;\n    });\n    socket.on('drain', () => {\n      debug('drain event received, emptying buffer');\n      canWrite = true;\n      emptyBuffer();\n    });\n    socket.on('timeout', socket.end.bind(socket));\n    socket.on('error', (e) => {\n      debug('connection error', e);\n      canWrite = false;\n      emptyBuffer();\n    });\n    socket.on('close', createSocket);\n  }\n\n  createSocket();\n\n  function log(loggingEvent) {\n    if (canWrite) {\n      write(loggingEvent);\n    } else {\n      debug('buffering log event because it cannot write at the moment');\n      buffer.push(loggingEvent);\n    }\n  }\n\n  log.shutdown = function (cb) {\n    debug('shutdown called');\n    if (buffer.length && shutdownAttempts) {\n      debug('buffer has items, waiting 100ms to empty');\n      shutdownAttempts -= 1;\n      setTimeout(() => {\n        log.shutdown(cb);\n      }, 100);\n    } else {\n      socket.removeAllListeners('close');\n      socket.end(cb);\n    }\n  };\n  return log;\n}\n\nfunction configure(config, layouts) {\n  debug(`configure with config = ${config}`);\n  let layout = function (loggingEvent) {\n    return loggingEvent.serialise();\n  };\n  if (config.layout) {\n    layout = layouts.layout(config.layout.type, config.layout);\n  }\n  return appender(config, layout);\n}\n\nmodule.exports.configure = configure;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/tcp.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/appenders sync recursive":
/*!*************************************************!*\
  !*** ./node_modules/log4js/lib/appenders/ sync ***!
  \*************************************************/
/***/ ((module) => {

eval("function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = () => ([]);\nwebpackEmptyContext.resolve = webpackEmptyContext;\nwebpackEmptyContext.id = \"./node_modules/log4js/lib/appenders sync recursive\";\nmodule.exports = webpackEmptyContext;\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/appenders/_sync?");

/***/ }),

/***/ "./node_modules/log4js/lib/categories.js":
/*!***********************************************!*\
  !*** ./node_modules/log4js/lib/categories.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:categories');\nconst configuration = __webpack_require__(/*! ./configuration */ \"./node_modules/log4js/lib/configuration.js\");\nconst levels = __webpack_require__(/*! ./levels */ \"./node_modules/log4js/lib/levels.js\");\nconst appenders = __webpack_require__(/*! ./appenders */ \"./node_modules/log4js/lib/appenders/index.js\");\n\nconst categories = new Map();\n\n/**\n * Add inherited config to this category.  That includes extra appenders from parent,\n * and level, if none is set on this category.\n * This is recursive, so each parent also gets loaded with inherited appenders.\n * Inheritance is blocked if a category has inherit=false\n * @param  {*} config\n * @param  {*} category the child category\n * @param  {string} categoryName dotted path to category\n * @return {void}\n */\nfunction inheritFromParent(config, category, categoryName) {\n  if (category.inherit === false) return;\n  const lastDotIndex = categoryName.lastIndexOf('.');\n  if (lastDotIndex < 0) return; // category is not a child\n  const parentCategoryName = categoryName.slice(0, lastDotIndex);\n  let parentCategory = config.categories[parentCategoryName];\n\n  if (!parentCategory) {\n    // parent is missing, so implicitly create it, so that it can inherit from its parents\n    parentCategory = { inherit: true, appenders: [] };\n  }\n\n  // make sure parent has had its inheritance taken care of before pulling its properties to this child\n  inheritFromParent(config, parentCategory, parentCategoryName);\n\n  // if the parent is not in the config (because we just created it above),\n  // and it inherited a valid configuration, add it to config.categories\n  if (\n    !config.categories[parentCategoryName] &&\n    parentCategory.appenders &&\n    parentCategory.appenders.length &&\n    parentCategory.level\n  ) {\n    config.categories[parentCategoryName] = parentCategory;\n  }\n\n  category.appenders = category.appenders || [];\n  category.level = category.level || parentCategory.level;\n\n  // merge in appenders from parent (parent is already holding its inherited appenders)\n  parentCategory.appenders.forEach((ap) => {\n    if (!category.appenders.includes(ap)) {\n      category.appenders.push(ap);\n    }\n  });\n  category.parent = parentCategory;\n}\n\n/**\n * Walk all categories in the config, and pull down any configuration from parent to child.\n * This includes inherited appenders, and level, where level is not set.\n * Inheritance is skipped where a category has inherit=false.\n * @param  {*} config\n */\nfunction addCategoryInheritance(config) {\n  if (!config.categories) return;\n  const categoryNames = Object.keys(config.categories);\n  categoryNames.forEach((name) => {\n    const category = config.categories[name];\n    // add inherited appenders and level to this category\n    inheritFromParent(config, category, name);\n  });\n}\n\nconfiguration.addPreProcessingListener((config) =>\n  addCategoryInheritance(config)\n);\n\nconfiguration.addListener((config) => {\n  configuration.throwExceptionIf(\n    config,\n    configuration.not(configuration.anObject(config.categories)),\n    'must have a property \"categories\" of type object.'\n  );\n\n  const categoryNames = Object.keys(config.categories);\n  configuration.throwExceptionIf(\n    config,\n    configuration.not(categoryNames.length),\n    'must define at least one category.'\n  );\n\n  categoryNames.forEach((name) => {\n    const category = config.categories[name];\n    configuration.throwExceptionIf(\n      config,\n      [\n        configuration.not(category.appenders),\n        configuration.not(category.level),\n      ],\n      `category \"${name}\" is not valid (must be an object with properties \"appenders\" and \"level\")`\n    );\n\n    configuration.throwExceptionIf(\n      config,\n      configuration.not(Array.isArray(category.appenders)),\n      `category \"${name}\" is not valid (appenders must be an array of appender names)`\n    );\n\n    configuration.throwExceptionIf(\n      config,\n      configuration.not(category.appenders.length),\n      `category \"${name}\" is not valid (appenders must contain at least one appender name)`\n    );\n\n    if (Object.prototype.hasOwnProperty.call(category, 'enableCallStack')) {\n      configuration.throwExceptionIf(\n        config,\n        typeof category.enableCallStack !== 'boolean',\n        `category \"${name}\" is not valid (enableCallStack must be boolean type)`\n      );\n    }\n\n    category.appenders.forEach((appender) => {\n      configuration.throwExceptionIf(\n        config,\n        configuration.not(appenders.get(appender)),\n        `category \"${name}\" is not valid (appender \"${appender}\" is not defined)`\n      );\n    });\n\n    configuration.throwExceptionIf(\n      config,\n      configuration.not(levels.getLevel(category.level)),\n      `category \"${name}\" is not valid (level \"${category.level}\" not recognised;` +\n        ` valid levels are ${levels.levels.join(', ')})`\n    );\n  });\n\n  configuration.throwExceptionIf(\n    config,\n    configuration.not(config.categories.default),\n    'must define a \"default\" category.'\n  );\n});\n\nconst setup = (config) => {\n  categories.clear();\n  if (!config) {\n    return;\n  }\n\n  const categoryNames = Object.keys(config.categories);\n  categoryNames.forEach((name) => {\n    const category = config.categories[name];\n    const categoryAppenders = [];\n    category.appenders.forEach((appender) => {\n      categoryAppenders.push(appenders.get(appender));\n      debug(`Creating category ${name}`);\n      categories.set(name, {\n        appenders: categoryAppenders,\n        level: levels.getLevel(category.level),\n        enableCallStack: category.enableCallStack || false,\n      });\n    });\n  });\n};\n\nconst init = () => {\n  setup();\n};\ninit();\n\nconfiguration.addListener(setup);\n\nconst configForCategory = (category) => {\n  debug(`configForCategory: searching for config for ${category}`);\n  if (categories.has(category)) {\n    debug(`configForCategory: ${category} exists in config, returning it`);\n    return categories.get(category);\n  }\n\n  let sourceCategoryConfig;\n  if (category.indexOf('.') > 0) {\n    debug(`configForCategory: ${category} has hierarchy, cloning from parents`);\n    sourceCategoryConfig = {\n      ...configForCategory(category.slice(0, category.lastIndexOf('.'))),\n    };\n  } else {\n    if (!categories.has('default')) {\n      setup({ categories: { default: { appenders: ['out'], level: 'OFF' } } });\n    }\n    debug('configForCategory: cloning default category');\n    sourceCategoryConfig = { ...categories.get('default') };\n  }\n  categories.set(category, sourceCategoryConfig);\n  return sourceCategoryConfig;\n};\n\nconst appendersForCategory = (category) =>\n  configForCategory(category).appenders;\n\nconst getLevelForCategory = (category) => configForCategory(category).level;\nconst setLevelForCategory = (category, level) => {\n  configForCategory(category).level = level;\n};\n\nconst getEnableCallStackForCategory = (category) =>\n  configForCategory(category).enableCallStack === true;\nconst setEnableCallStackForCategory = (category, useCallStack) => {\n  configForCategory(category).enableCallStack = useCallStack;\n};\n\nmodule.exports = categories;\nmodule.exports = Object.assign(module.exports, {\n  appendersForCategory,\n  getLevelForCategory,\n  setLevelForCategory,\n  getEnableCallStackForCategory,\n  setEnableCallStackForCategory,\n  init,\n});\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/categories.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/clustering.js":
/*!***********************************************!*\
  !*** ./node_modules/log4js/lib/clustering.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:clustering');\nconst LoggingEvent = __webpack_require__(/*! ./LoggingEvent */ \"./node_modules/log4js/lib/LoggingEvent.js\");\nconst configuration = __webpack_require__(/*! ./configuration */ \"./node_modules/log4js/lib/configuration.js\");\n\nlet disabled = false;\nlet cluster = null;\ntry {\n  // eslint-disable-next-line global-require\n  cluster = __webpack_require__(/*! cluster */ \"cluster\");\n} catch (e) {\n  debug('cluster module not present');\n  disabled = true;\n}\n\nconst listeners = [];\n\nlet pm2 = false;\nlet pm2InstanceVar = 'NODE_APP_INSTANCE';\n\nconst isPM2Master = () => pm2 && process.env[pm2InstanceVar] === '0';\nconst isMaster = () =>\n  disabled || (cluster && cluster.isMaster) || isPM2Master();\n\nconst sendToListeners = (logEvent) => {\n  listeners.forEach((l) => l(logEvent));\n};\n\n// in a multi-process node environment, worker loggers will use\n// process.send\nconst receiver = (worker, message) => {\n  // prior to node v6, the worker parameter was not passed (args were message, handle)\n  debug('cluster message received from worker ', worker, ': ', message);\n  if (worker.topic && worker.data) {\n    message = worker;\n    worker = undefined;\n  }\n  if (message && message.topic && message.topic === 'log4js:message') {\n    debug('received message: ', message.data);\n    const logEvent = LoggingEvent.deserialise(message.data);\n    sendToListeners(logEvent);\n  }\n};\n\nif (!disabled) {\n  configuration.addListener((config) => {\n    // clear out the listeners, because configure has been called.\n    listeners.length = 0;\n\n    ({\n      pm2,\n      disableClustering: disabled,\n      pm2InstanceVar = 'NODE_APP_INSTANCE',\n    } = config);\n\n    debug(`clustering disabled ? ${disabled}`);\n    debug(`cluster.isMaster ? ${cluster && cluster.isMaster}`);\n    debug(`pm2 enabled ? ${pm2}`);\n    debug(`pm2InstanceVar = ${pm2InstanceVar}`);\n    debug(`process.env[${pm2InstanceVar}] = ${process.env[pm2InstanceVar]}`);\n\n    // just in case configure is called after shutdown\n    if (pm2) {\n      process.removeListener('message', receiver);\n    }\n    if (cluster && cluster.removeListener) {\n      cluster.removeListener('message', receiver);\n    }\n\n    if (disabled || config.disableClustering) {\n      debug('Not listening for cluster messages, because clustering disabled.');\n    } else if (isPM2Master()) {\n      // PM2 cluster support\n      // PM2 runs everything as workers - install pm2-intercom for this to work.\n      // we only want one of the app instances to write logs\n      debug('listening for PM2 broadcast messages');\n      process.on('message', receiver);\n    } else if (cluster && cluster.isMaster) {\n      debug('listening for cluster messages');\n      cluster.on('message', receiver);\n    } else {\n      debug('not listening for messages, because we are not a master process');\n    }\n  });\n}\n\nmodule.exports = {\n  onlyOnMaster: (fn, notMaster) => (isMaster() ? fn() : notMaster),\n  isMaster,\n  send: (msg) => {\n    if (isMaster()) {\n      sendToListeners(msg);\n    } else {\n      if (!pm2) {\n        msg.cluster = {\n          workerId: cluster.worker.id,\n          worker: process.pid,\n        };\n      }\n      process.send({ topic: 'log4js:message', data: msg.serialise() });\n    }\n  },\n  onMessage: (listener) => {\n    listeners.push(listener);\n  },\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/clustering.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/configuration.js":
/*!**************************************************!*\
  !*** ./node_modules/log4js/lib/configuration.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const util = __webpack_require__(/*! util */ \"util\");\nconst debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:configuration');\n\nconst preProcessingListeners = [];\nconst listeners = [];\n\nconst not = (thing) => !thing;\n\nconst anObject = (thing) =>\n  thing && typeof thing === 'object' && !Array.isArray(thing);\n\nconst validIdentifier = (thing) => /^[A-Za-z][A-Za-z0-9_]*$/g.test(thing);\n\nconst anInteger = (thing) =>\n  thing && typeof thing === 'number' && Number.isInteger(thing);\n\nconst addListener = (fn) => {\n  listeners.push(fn);\n  debug(`Added listener, now ${listeners.length} listeners`);\n};\n\nconst addPreProcessingListener = (fn) => {\n  preProcessingListeners.push(fn);\n  debug(\n    `Added pre-processing listener, now ${preProcessingListeners.length} listeners`\n  );\n};\n\nconst throwExceptionIf = (config, checks, message) => {\n  const tests = Array.isArray(checks) ? checks : [checks];\n  tests.forEach((test) => {\n    if (test) {\n      throw new Error(\n        `Problem with log4js configuration: (${util.inspect(config, {\n          depth: 5,\n        })}) - ${message}`\n      );\n    }\n  });\n};\n\nconst configure = (candidate) => {\n  debug('New configuration to be validated: ', candidate);\n  throwExceptionIf(candidate, not(anObject(candidate)), 'must be an object.');\n\n  debug(`Calling pre-processing listeners (${preProcessingListeners.length})`);\n  preProcessingListeners.forEach((listener) => listener(candidate));\n  debug('Configuration pre-processing finished.');\n\n  debug(`Calling configuration listeners (${listeners.length})`);\n  listeners.forEach((listener) => listener(candidate));\n  debug('Configuration finished.');\n};\n\nmodule.exports = {\n  configure,\n  addListener,\n  addPreProcessingListener,\n  throwExceptionIf,\n  anObject,\n  anInteger,\n  validIdentifier,\n  not,\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/configuration.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/connect-logger.js":
/*!***************************************************!*\
  !*** ./node_modules/log4js/lib/connect-logger.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* eslint no-underscore-dangle: [\"error\", { \"allow\": [\"__statusCode\", \"_remoteAddress\", \"__headers\", \"_logging\"] }] */\n\nconst levels = __webpack_require__(/*! ./levels */ \"./node_modules/log4js/lib/levels.js\");\n\nconst DEFAULT_FORMAT =\n  ':remote-addr - -' +\n  ' \":method :url HTTP/:http-version\"' +\n  ' :status :content-length \":referrer\"' +\n  ' \":user-agent\"';\n\n/**\n * Return request url path,\n * adding this function prevents the Cyclomatic Complexity,\n * for the assemble_tokens function at low, to pass the tests.\n *\n * @param  {IncomingMessage} req\n * @return {string}\n * @api private\n */\nfunction getUrl(req) {\n  return req.originalUrl || req.url;\n}\n\n/**\n * Adds custom {token, replacement} objects to defaults,\n * overwriting the defaults if any tokens clash\n *\n * @param  {IncomingMessage} req\n * @param  {ServerResponse} res\n * @param  {Array} customTokens\n *    [{ token: string-or-regexp, replacement: string-or-replace-function }]\n * @return {Array}\n */\nfunction assembleTokens(req, res, customTokens) {\n  const arrayUniqueTokens = (array) => {\n    const a = array.concat();\n    for (let i = 0; i < a.length; ++i) {\n      for (let j = i + 1; j < a.length; ++j) {\n        // not === because token can be regexp object\n        // eslint-disable-next-line eqeqeq\n        if (a[i].token == a[j].token) {\n          a.splice(j--, 1); // eslint-disable-line no-plusplus\n        }\n      }\n    }\n    return a;\n  };\n\n  const defaultTokens = [];\n  defaultTokens.push({ token: ':url', replacement: getUrl(req) });\n  defaultTokens.push({ token: ':protocol', replacement: req.protocol });\n  defaultTokens.push({ token: ':hostname', replacement: req.hostname });\n  defaultTokens.push({ token: ':method', replacement: req.method });\n  defaultTokens.push({\n    token: ':status',\n    replacement: res.__statusCode || res.statusCode,\n  });\n  defaultTokens.push({\n    token: ':response-time',\n    replacement: res.responseTime,\n  });\n  defaultTokens.push({ token: ':date', replacement: new Date().toUTCString() });\n  defaultTokens.push({\n    token: ':referrer',\n    replacement: req.headers.referer || req.headers.referrer || '',\n  });\n  defaultTokens.push({\n    token: ':http-version',\n    replacement: `${req.httpVersionMajor}.${req.httpVersionMinor}`,\n  });\n  defaultTokens.push({\n    token: ':remote-addr',\n    replacement:\n      req.headers['x-forwarded-for'] ||\n      req.ip ||\n      req._remoteAddress ||\n      (req.socket &&\n        (req.socket.remoteAddress ||\n          (req.socket.socket && req.socket.socket.remoteAddress))),\n  });\n  defaultTokens.push({\n    token: ':user-agent',\n    replacement: req.headers['user-agent'],\n  });\n  defaultTokens.push({\n    token: ':content-length',\n    replacement:\n      res.getHeader('content-length') ||\n      (res.__headers && res.__headers['Content-Length']) ||\n      '-',\n  });\n  defaultTokens.push({\n    token: /:req\\[([^\\]]+)]/g,\n    replacement(_, field) {\n      return req.headers[field.toLowerCase()];\n    },\n  });\n  defaultTokens.push({\n    token: /:res\\[([^\\]]+)]/g,\n    replacement(_, field) {\n      return (\n        res.getHeader(field.toLowerCase()) ||\n        (res.__headers && res.__headers[field])\n      );\n    },\n  });\n\n  return arrayUniqueTokens(customTokens.concat(defaultTokens));\n}\n\n/**\n * Return formatted log line.\n *\n * @param  {string} str\n * @param {Array} tokens\n * @return {string}\n * @api private\n */\nfunction format(str, tokens) {\n  for (let i = 0; i < tokens.length; i++) {\n    str = str.replace(tokens[i].token, tokens[i].replacement);\n  }\n  return str;\n}\n\n/**\n * Return RegExp Object about nolog\n *\n * @param  {(string|Array)} nolog\n * @return {RegExp}\n * @api private\n *\n * syntax\n *  1. String\n *   1.1 \"\\\\.gif\"\n *         NOT LOGGING http://example.com/hoge.gif and http://example.com/hoge.gif?fuga\n *         LOGGING http://example.com/hoge.agif\n *   1.2 in \"\\\\.gif|\\\\.jpg$\"\n *         NOT LOGGING http://example.com/hoge.gif and\n *           http://example.com/hoge.gif?fuga and http://example.com/hoge.jpg?fuga\n *         LOGGING http://example.com/hoge.agif,\n *           http://example.com/hoge.ajpg and http://example.com/hoge.jpg?hoge\n *   1.3 in \"\\\\.(gif|jpe?g|png)$\"\n *         NOT LOGGING http://example.com/hoge.gif and http://example.com/hoge.jpeg\n *         LOGGING http://example.com/hoge.gif?uid=2 and http://example.com/hoge.jpg?pid=3\n *  2. RegExp\n *   2.1 in /\\.(gif|jpe?g|png)$/\n *         SAME AS 1.3\n *  3. Array\n *   3.1 [\"\\\\.jpg$\", \"\\\\.png\", \"\\\\.gif\"]\n *         SAME AS \"\\\\.jpg|\\\\.png|\\\\.gif\"\n */\nfunction createNoLogCondition(nolog) {\n  let regexp = null;\n\n  if (nolog instanceof RegExp) {\n    regexp = nolog;\n  }\n\n  if (typeof nolog === 'string') {\n    regexp = new RegExp(nolog);\n  }\n\n  if (Array.isArray(nolog)) {\n    // convert to strings\n    const regexpsAsStrings = nolog.map((reg) =>\n      reg.source ? reg.source : reg\n    );\n    regexp = new RegExp(regexpsAsStrings.join('|'));\n  }\n\n  return regexp;\n}\n\n/**\n * Allows users to define rules around status codes to assign them to a specific\n * logging level.\n * There are two types of rules:\n *   - RANGE: matches a code within a certain range\n *     E.g. { 'from': 200, 'to': 299, 'level': 'info' }\n *   - CONTAINS: matches a code to a set of expected codes\n *     E.g. { 'codes': [200, 203], 'level': 'debug' }\n * Note*: Rules are respected only in order of prescendence.\n *\n * @param {Number} statusCode\n * @param {Level} currentLevel\n * @param {Object} ruleSet\n * @return {Level}\n * @api private\n */\nfunction matchRules(statusCode, currentLevel, ruleSet) {\n  let level = currentLevel;\n\n  if (ruleSet) {\n    const matchedRule = ruleSet.find((rule) => {\n      let ruleMatched = false;\n      if (rule.from && rule.to) {\n        ruleMatched = statusCode >= rule.from && statusCode <= rule.to;\n      } else {\n        ruleMatched = rule.codes.indexOf(statusCode) !== -1;\n      }\n      return ruleMatched;\n    });\n    if (matchedRule) {\n      level = levels.getLevel(matchedRule.level, level);\n    }\n  }\n  return level;\n}\n\n/**\n * Log requests with the given `options` or a `format` string.\n *\n * Options:\n *\n *   - `format`        Format string, see below for tokens\n *   - `level`         A log4js levels instance. Supports also 'auto'\n *   - `nolog`         A string or RegExp to exclude target logs or function(req, res): boolean\n *   - `statusRules`   A array of rules for setting specific logging levels base on status codes\n *   - `context`       Whether to add a response of express to the context\n *\n * Tokens:\n *\n *   - `:req[header]` ex: `:req[Accept]`\n *   - `:res[header]` ex: `:res[Content-Length]`\n *   - `:http-version`\n *   - `:response-time`\n *   - `:remote-addr`\n *   - `:date`\n *   - `:method`\n *   - `:url`\n *   - `:referrer`\n *   - `:user-agent`\n *   - `:status`\n *\n * @return {Function}\n * @param logger4js\n * @param options\n * @api public\n */\nmodule.exports = function getLogger(logger4js, options) {\n  if (typeof options === 'string' || typeof options === 'function') {\n    options = { format: options };\n  } else {\n    options = options || {};\n  }\n\n  const thisLogger = logger4js;\n  let level = levels.getLevel(options.level, levels.INFO);\n  const fmt = options.format || DEFAULT_FORMAT;\n\n  return (req, res, next) => {\n    // mount safety\n    if (req._logging) return next();\n\n    // nologs\n    if (typeof options.nolog === 'function') {\n      if (options.nolog(req, res) === true) return next();\n    } else {\n      const nolog = createNoLogCondition(options.nolog);\n      if (nolog && nolog.test(req.originalUrl)) return next();\n    }\n\n    if (thisLogger.isLevelEnabled(level) || options.level === 'auto') {\n      const start = new Date();\n      const { writeHead } = res;\n\n      // flag as logging\n      req._logging = true;\n\n      // proxy for statusCode.\n      res.writeHead = (code, headers) => {\n        res.writeHead = writeHead;\n        res.writeHead(code, headers);\n\n        res.__statusCode = code;\n        res.__headers = headers || {};\n      };\n\n      // hook on end request to emit the log entry of the HTTP request.\n      let finished = false;\n      const handler = () => {\n        if (finished) {\n          return;\n        }\n        finished = true;\n        res.responseTime = new Date() - start;\n        // status code response level handling\n        if (res.statusCode && options.level === 'auto') {\n          level = levels.INFO;\n          if (res.statusCode >= 300) level = levels.WARN;\n          if (res.statusCode >= 400) level = levels.ERROR;\n        }\n        level = matchRules(res.statusCode, level, options.statusRules);\n\n        const combinedTokens = assembleTokens(req, res, options.tokens || []);\n\n        if (options.context) thisLogger.addContext('res', res);\n        if (typeof fmt === 'function') {\n          const line = fmt(req, res, (str) => format(str, combinedTokens));\n          if (line) thisLogger.log(level, line);\n        } else {\n          thisLogger.log(level, format(fmt, combinedTokens));\n        }\n        if (options.context) thisLogger.removeContext('res');\n      };\n      res.on('end', handler);\n      res.on('finish', handler);\n      res.on('error', handler);\n      res.on('close', handler);\n    }\n\n    // ensure next gets always called\n    return next();\n  };\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/connect-logger.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/layouts.js":
/*!********************************************!*\
  !*** ./node_modules/log4js/lib/layouts.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const dateFormat = __webpack_require__(/*! date-format */ \"./node_modules/date-format/lib/index.js\");\nconst os = __webpack_require__(/*! os */ \"os\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst url = __webpack_require__(/*! url */ \"url\");\nconst debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:layouts');\n\nconst styles = {\n  // styles\n  bold: [1, 22],\n  italic: [3, 23],\n  underline: [4, 24],\n  inverse: [7, 27],\n  // grayscale\n  white: [37, 39],\n  grey: [90, 39],\n  black: [90, 39],\n  // colors\n  blue: [34, 39],\n  cyan: [36, 39],\n  green: [32, 39],\n  magenta: [35, 39],\n  red: [91, 39],\n  yellow: [33, 39],\n};\n\nfunction colorizeStart(style) {\n  return style ? `\\x1B[${styles[style][0]}m` : '';\n}\n\nfunction colorizeEnd(style) {\n  return style ? `\\x1B[${styles[style][1]}m` : '';\n}\n\n/**\n * Taken from masylum's fork (https://github.com/masylum/log4js-node)\n */\nfunction colorize(str, style) {\n  return colorizeStart(style) + str + colorizeEnd(style);\n}\n\nfunction timestampLevelAndCategory(loggingEvent, colour) {\n  return colorize(\n    util.format(\n      '[%s] [%s] %s - ',\n      dateFormat.asString(loggingEvent.startTime),\n      loggingEvent.level.toString(),\n      loggingEvent.categoryName\n    ),\n    colour\n  );\n}\n\n/**\n * BasicLayout is a simple layout for storing the logs. The logs are stored\n * in following format:\n * <pre>\n * [startTime] [logLevel] categoryName - message\\n\n * </pre>\n *\n * @author Stephan Strittmatter\n */\nfunction basicLayout(loggingEvent) {\n  return (\n    timestampLevelAndCategory(loggingEvent) + util.format(...loggingEvent.data)\n  );\n}\n\n/**\n * colouredLayout - taken from masylum's fork.\n * same as basicLayout, but with colours.\n */\nfunction colouredLayout(loggingEvent) {\n  return (\n    timestampLevelAndCategory(loggingEvent, loggingEvent.level.colour) +\n    util.format(...loggingEvent.data)\n  );\n}\n\nfunction messagePassThroughLayout(loggingEvent) {\n  return util.format(...loggingEvent.data);\n}\n\nfunction dummyLayout(loggingEvent) {\n  return loggingEvent.data[0];\n}\n\n/**\n * PatternLayout\n * Format for specifiers is %[padding].[truncation][field]{[format]}\n * e.g. %5.10p - left pad the log level by 5 characters, up to a max of 10\n * both padding and truncation can be negative.\n * Negative truncation = trunc from end of string\n * Positive truncation = trunc from start of string\n * Negative padding = pad right\n * Positive padding = pad left\n *\n * Fields can be any of:\n *  - %r time in toLocaleTimeString format\n *  - %p log level\n *  - %c log category\n *  - %h hostname\n *  - %m log data\n *  - %d date in constious formats\n *  - %% %\n *  - %n newline\n *  - %z pid\n *  - %f filename\n *  - %l line number\n *  - %o column postion\n *  - %s call stack\n *  - %x{<tokenname>} add dynamic tokens to your log. Tokens are specified in the tokens parameter\n *  - %X{<tokenname>} add dynamic tokens to your log. Tokens are specified in logger context\n * You can use %[ and %] to define a colored block.\n *\n * Tokens are specified as simple key:value objects.\n * The key represents the token name whereas the value can be a string or function\n * which is called to extract the value to put in the log message. If token is not\n * found, it doesn't replace the field.\n *\n * A sample token would be: { 'pid' : function() { return process.pid; } }\n *\n * Takes a pattern string, array of tokens and returns a layout function.\n * @return {Function}\n * @param pattern\n * @param tokens\n * @param timezoneOffset\n *\n * @authors ['Stephan Strittmatter', 'Jan Schmidle']\n */\nfunction patternLayout(pattern, tokens) {\n  const TTCC_CONVERSION_PATTERN = '%r %p %c - %m%n';\n  const regex =\n    /%(-?[0-9]+)?(\\.?-?[0-9]+)?([[\\]cdhmnprzxXyflos%])(\\{([^}]+)\\})?|([^%]+)/;\n\n  pattern = pattern || TTCC_CONVERSION_PATTERN;\n\n  function categoryName(loggingEvent, specifier) {\n    let loggerName = loggingEvent.categoryName;\n    if (specifier) {\n      const precision = parseInt(specifier, 10);\n      const loggerNameBits = loggerName.split('.');\n      if (precision < loggerNameBits.length) {\n        loggerName = loggerNameBits\n          .slice(loggerNameBits.length - precision)\n          .join('.');\n      }\n    }\n    return loggerName;\n  }\n\n  function formatAsDate(loggingEvent, specifier) {\n    let format = dateFormat.ISO8601_FORMAT;\n    if (specifier) {\n      format = specifier;\n      // Pick up special cases\n      switch (format) {\n        case 'ISO8601':\n        case 'ISO8601_FORMAT':\n          format = dateFormat.ISO8601_FORMAT;\n          break;\n        case 'ISO8601_WITH_TZ_OFFSET':\n        case 'ISO8601_WITH_TZ_OFFSET_FORMAT':\n          format = dateFormat.ISO8601_WITH_TZ_OFFSET_FORMAT;\n          break;\n        case 'ABSOLUTE':\n          process.emitWarning(\n            'Pattern %d{ABSOLUTE} is deprecated in favor of %d{ABSOLUTETIME}. ' +\n              'Please use %d{ABSOLUTETIME} instead.',\n            'DeprecationWarning',\n            'log4js-node-DEP0003'\n          );\n          debug(\n            '[log4js-node-DEP0003]',\n            'DEPRECATION: Pattern %d{ABSOLUTE} is deprecated and replaced by %d{ABSOLUTETIME}.'\n          );\n        // falls through\n        case 'ABSOLUTETIME':\n        case 'ABSOLUTETIME_FORMAT':\n          format = dateFormat.ABSOLUTETIME_FORMAT;\n          break;\n        case 'DATE':\n          process.emitWarning(\n            'Pattern %d{DATE} is deprecated due to the confusion it causes when used. ' +\n              'Please use %d{DATETIME} instead.',\n            'DeprecationWarning',\n            'log4js-node-DEP0004'\n          );\n          debug(\n            '[log4js-node-DEP0004]',\n            'DEPRECATION: Pattern %d{DATE} is deprecated and replaced by %d{DATETIME}.'\n          );\n        // falls through\n        case 'DATETIME':\n        case 'DATETIME_FORMAT':\n          format = dateFormat.DATETIME_FORMAT;\n          break;\n        // no default\n      }\n    }\n    // Format the date\n    return dateFormat.asString(format, loggingEvent.startTime);\n  }\n\n  function hostname() {\n    return os.hostname().toString();\n  }\n\n  function formatMessage(loggingEvent) {\n    return util.format(...loggingEvent.data);\n  }\n\n  function endOfLine() {\n    return os.EOL;\n  }\n\n  function logLevel(loggingEvent) {\n    return loggingEvent.level.toString();\n  }\n\n  function startTime(loggingEvent) {\n    return dateFormat.asString('hh:mm:ss', loggingEvent.startTime);\n  }\n\n  function startColour(loggingEvent) {\n    return colorizeStart(loggingEvent.level.colour);\n  }\n\n  function endColour(loggingEvent) {\n    return colorizeEnd(loggingEvent.level.colour);\n  }\n\n  function percent() {\n    return '%';\n  }\n\n  function pid(loggingEvent) {\n    return loggingEvent && loggingEvent.pid\n      ? loggingEvent.pid.toString()\n      : process.pid.toString();\n  }\n\n  function clusterInfo() {\n    // this used to try to return the master and worker pids,\n    // but it would never have worked because master pid is not available to workers\n    // leaving this here to maintain compatibility for patterns\n    return pid();\n  }\n\n  function userDefined(loggingEvent, specifier) {\n    if (typeof tokens[specifier] !== 'undefined') {\n      return typeof tokens[specifier] === 'function'\n        ? tokens[specifier](loggingEvent)\n        : tokens[specifier];\n    }\n\n    return null;\n  }\n\n  function contextDefined(loggingEvent, specifier) {\n    const resolver = loggingEvent.context[specifier];\n\n    if (typeof resolver !== 'undefined') {\n      return typeof resolver === 'function' ? resolver(loggingEvent) : resolver;\n    }\n\n    return null;\n  }\n\n  function fileName(loggingEvent, specifier) {\n    let filename = loggingEvent.fileName || '';\n\n    // support for ESM as it uses url instead of path for file\n    /* istanbul ignore next: unsure how to simulate ESM for test coverage */\n    const convertFileURLToPath = function (filepath) {\n      const urlPrefix = 'file://';\n      if (filepath.startsWith(urlPrefix)) {\n        // https://nodejs.org/api/url.html#urlfileurltopathurl\n        if (typeof url.fileURLToPath === 'function') {\n          filepath = url.fileURLToPath(filepath);\n        }\n        // backward-compatible for nodejs pre-10.12.0 (without url.fileURLToPath method)\n        else {\n          // posix: file:///hello/world/foo.txt -> /hello/world/foo.txt -> /hello/world/foo.txt\n          // win32: file:///C:/path/foo.txt     -> /C:/path/foo.txt     -> \\C:\\path\\foo.txt     -> C:\\path\\foo.txt\n          // win32: file://nas/foo.txt          -> //nas/foo.txt        -> nas\\foo.txt          -> \\\\nas\\foo.txt\n          filepath = path.normalize(\n            filepath.replace(new RegExp(`^${urlPrefix}`), '')\n          );\n          if (process.platform === 'win32') {\n            if (filepath.startsWith('\\\\')) {\n              filepath = filepath.slice(1);\n            } else {\n              filepath = path.sep + path.sep + filepath;\n            }\n          }\n        }\n      }\n      return filepath;\n    };\n    filename = convertFileURLToPath(filename);\n\n    if (specifier) {\n      const fileDepth = parseInt(specifier, 10);\n      const fileList = filename.split(path.sep);\n      if (fileList.length > fileDepth) {\n        filename = fileList.slice(-fileDepth).join(path.sep);\n      }\n    }\n\n    return filename;\n  }\n\n  function lineNumber(loggingEvent) {\n    return loggingEvent.lineNumber ? `${loggingEvent.lineNumber}` : '';\n  }\n\n  function columnNumber(loggingEvent) {\n    return loggingEvent.columnNumber ? `${loggingEvent.columnNumber}` : '';\n  }\n\n  function callStack(loggingEvent) {\n    return loggingEvent.callStack || '';\n  }\n\n  const replacers = {\n    c: categoryName,\n    d: formatAsDate,\n    h: hostname,\n    m: formatMessage,\n    n: endOfLine,\n    p: logLevel,\n    r: startTime,\n    '[': startColour,\n    ']': endColour,\n    y: clusterInfo,\n    z: pid,\n    '%': percent,\n    x: userDefined,\n    X: contextDefined,\n    f: fileName,\n    l: lineNumber,\n    o: columnNumber,\n    s: callStack,\n  };\n\n  function replaceToken(conversionCharacter, loggingEvent, specifier) {\n    return replacers[conversionCharacter](loggingEvent, specifier);\n  }\n\n  function truncate(truncation, toTruncate) {\n    let len;\n    if (truncation) {\n      len = parseInt(truncation.slice(1), 10);\n      // negative truncate length means truncate from end of string\n      return len > 0 ? toTruncate.slice(0, len) : toTruncate.slice(len);\n    }\n\n    return toTruncate;\n  }\n\n  function pad(padding, toPad) {\n    let len;\n    if (padding) {\n      if (padding.charAt(0) === '-') {\n        len = parseInt(padding.slice(1), 10);\n        // Right pad with spaces\n        while (toPad.length < len) {\n          toPad += ' ';\n        }\n      } else {\n        len = parseInt(padding, 10);\n        // Left pad with spaces\n        while (toPad.length < len) {\n          toPad = ` ${toPad}`;\n        }\n      }\n    }\n    return toPad;\n  }\n\n  function truncateAndPad(toTruncAndPad, truncation, padding) {\n    let replacement = toTruncAndPad;\n    replacement = truncate(truncation, replacement);\n    replacement = pad(padding, replacement);\n    return replacement;\n  }\n\n  return function (loggingEvent) {\n    let formattedString = '';\n    let result;\n    let searchString = pattern;\n\n    while ((result = regex.exec(searchString)) !== null) {\n      // const matchedString = result[0];\n      const padding = result[1];\n      const truncation = result[2];\n      const conversionCharacter = result[3];\n      const specifier = result[5];\n      const text = result[6];\n\n      // Check if the pattern matched was just normal text\n      if (text) {\n        formattedString += text.toString();\n      } else {\n        // Create a raw replacement string based on the conversion\n        // character and specifier\n        const replacement = replaceToken(\n          conversionCharacter,\n          loggingEvent,\n          specifier\n        );\n        formattedString += truncateAndPad(replacement, truncation, padding);\n      }\n      searchString = searchString.slice(result.index + result[0].length);\n    }\n    return formattedString;\n  };\n}\n\nconst layoutMakers = {\n  messagePassThrough() {\n    return messagePassThroughLayout;\n  },\n  basic() {\n    return basicLayout;\n  },\n  colored() {\n    return colouredLayout;\n  },\n  coloured() {\n    return colouredLayout;\n  },\n  pattern(config) {\n    return patternLayout(config && config.pattern, config && config.tokens);\n  },\n  dummy() {\n    return dummyLayout;\n  },\n};\n\nmodule.exports = {\n  basicLayout,\n  messagePassThroughLayout,\n  patternLayout,\n  colouredLayout,\n  coloredLayout: colouredLayout,\n  dummyLayout,\n  addLayout(name, serializerGenerator) {\n    layoutMakers[name] = serializerGenerator;\n  },\n  layout(name, config) {\n    return layoutMakers[name] && layoutMakers[name](config);\n  },\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/layouts.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/levels.js":
/*!*******************************************!*\
  !*** ./node_modules/log4js/lib/levels.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const configuration = __webpack_require__(/*! ./configuration */ \"./node_modules/log4js/lib/configuration.js\");\n\nconst validColours = [\n  'white',\n  'grey',\n  'black',\n  'blue',\n  'cyan',\n  'green',\n  'magenta',\n  'red',\n  'yellow',\n];\n\nclass Level {\n  constructor(level, levelStr, colour) {\n    this.level = level;\n    this.levelStr = levelStr;\n    this.colour = colour;\n  }\n\n  toString() {\n    return this.levelStr;\n  }\n\n  /**\n   * converts given String to corresponding Level\n   * @param {(Level|string)} sArg -- String value of Level OR Log4js.Level\n   * @param {Level} [defaultLevel] -- default Level, if no String representation\n   * @return {Level}\n   */\n  static getLevel(sArg, defaultLevel) {\n    if (!sArg) {\n      return defaultLevel;\n    }\n\n    if (sArg instanceof Level) {\n      return sArg;\n    }\n\n    // a json-serialised level won't be an instance of Level (see issue #768)\n    if (sArg instanceof Object && sArg.levelStr) {\n      sArg = sArg.levelStr;\n    }\n\n    return Level[sArg.toString().toUpperCase()] || defaultLevel;\n  }\n\n  static addLevels(customLevels) {\n    if (customLevels) {\n      const levels = Object.keys(customLevels);\n      levels.forEach((l) => {\n        const levelStr = l.toUpperCase();\n        Level[levelStr] = new Level(\n          customLevels[l].value,\n          levelStr,\n          customLevels[l].colour\n        );\n        const existingLevelIndex = Level.levels.findIndex(\n          (lvl) => lvl.levelStr === levelStr\n        );\n        if (existingLevelIndex > -1) {\n          Level.levels[existingLevelIndex] = Level[levelStr];\n        } else {\n          Level.levels.push(Level[levelStr]);\n        }\n      });\n      Level.levels.sort((a, b) => a.level - b.level);\n    }\n  }\n\n  isLessThanOrEqualTo(otherLevel) {\n    if (typeof otherLevel === 'string') {\n      otherLevel = Level.getLevel(otherLevel);\n    }\n    return this.level <= otherLevel.level;\n  }\n\n  isGreaterThanOrEqualTo(otherLevel) {\n    if (typeof otherLevel === 'string') {\n      otherLevel = Level.getLevel(otherLevel);\n    }\n    return this.level >= otherLevel.level;\n  }\n\n  isEqualTo(otherLevel) {\n    if (typeof otherLevel === 'string') {\n      otherLevel = Level.getLevel(otherLevel);\n    }\n    return this.level === otherLevel.level;\n  }\n}\n\nLevel.levels = [];\nLevel.addLevels({\n  ALL: { value: Number.MIN_VALUE, colour: 'grey' },\n  TRACE: { value: 5000, colour: 'blue' },\n  DEBUG: { value: 10000, colour: 'cyan' },\n  INFO: { value: 20000, colour: 'green' },\n  WARN: { value: 30000, colour: 'yellow' },\n  ERROR: { value: 40000, colour: 'red' },\n  FATAL: { value: 50000, colour: 'magenta' },\n  MARK: { value: 9007199254740992, colour: 'grey' }, // 2^53\n  OFF: { value: Number.MAX_VALUE, colour: 'grey' },\n});\n\nconfiguration.addListener((config) => {\n  const levelConfig = config.levels;\n  if (levelConfig) {\n    configuration.throwExceptionIf(\n      config,\n      configuration.not(configuration.anObject(levelConfig)),\n      'levels must be an object'\n    );\n    const newLevels = Object.keys(levelConfig);\n    newLevels.forEach((l) => {\n      configuration.throwExceptionIf(\n        config,\n        configuration.not(configuration.validIdentifier(l)),\n        `level name \"${l}\" is not a valid identifier (must start with a letter, only contain A-Z,a-z,0-9,_)`\n      );\n      configuration.throwExceptionIf(\n        config,\n        configuration.not(configuration.anObject(levelConfig[l])),\n        `level \"${l}\" must be an object`\n      );\n      configuration.throwExceptionIf(\n        config,\n        configuration.not(levelConfig[l].value),\n        `level \"${l}\" must have a 'value' property`\n      );\n      configuration.throwExceptionIf(\n        config,\n        configuration.not(configuration.anInteger(levelConfig[l].value)),\n        `level \"${l}\".value must have an integer value`\n      );\n      configuration.throwExceptionIf(\n        config,\n        configuration.not(levelConfig[l].colour),\n        `level \"${l}\" must have a 'colour' property`\n      );\n      configuration.throwExceptionIf(\n        config,\n        configuration.not(validColours.indexOf(levelConfig[l].colour) > -1),\n        `level \"${l}\".colour must be one of ${validColours.join(', ')}`\n      );\n    });\n  }\n});\n\nconfiguration.addListener((config) => {\n  Level.addLevels(config.levels);\n});\n\nmodule.exports = Level;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/levels.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/log4js.js":
/*!*******************************************!*\
  !*** ./node_modules/log4js/lib/log4js.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/**\n * @fileoverview log4js is a library to log in JavaScript in similar manner\n * than in log4j for Java (but not really).\n *\n * <h3>Example:</h3>\n * <pre>\n *  const logging = require('log4js');\n *  const log = logging.getLogger('some-category');\n *\n *  //call the log\n *  log.trace('trace me' );\n * </pre>\n *\n * NOTE: the authors below are the original browser-based log4js authors\n * don't try to contact them about bugs in this version :)\n * @author Stephan Strittmatter - http://jroller.com/page/stritti\n * @author Seth Chisamore - http://www.chisamore.com\n * @since 2005-05-20\n * Website: http://log4js.berlios.de\n */\nconst debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:main');\nconst fs = __webpack_require__(/*! fs */ \"fs\");\nconst deepClone = __webpack_require__(/*! rfdc */ \"./node_modules/rfdc/index.js\")({ proto: true });\nconst configuration = __webpack_require__(/*! ./configuration */ \"./node_modules/log4js/lib/configuration.js\");\nconst layouts = __webpack_require__(/*! ./layouts */ \"./node_modules/log4js/lib/layouts.js\");\nconst levels = __webpack_require__(/*! ./levels */ \"./node_modules/log4js/lib/levels.js\");\nconst appenders = __webpack_require__(/*! ./appenders */ \"./node_modules/log4js/lib/appenders/index.js\");\nconst categories = __webpack_require__(/*! ./categories */ \"./node_modules/log4js/lib/categories.js\");\nconst Logger = __webpack_require__(/*! ./logger */ \"./node_modules/log4js/lib/logger.js\");\nconst clustering = __webpack_require__(/*! ./clustering */ \"./node_modules/log4js/lib/clustering.js\");\nconst connectLogger = __webpack_require__(/*! ./connect-logger */ \"./node_modules/log4js/lib/connect-logger.js\");\nconst recordingModule = __webpack_require__(/*! ./appenders/recording */ \"./node_modules/log4js/lib/appenders/recording.js\");\n\nlet enabled = false;\n\nfunction sendLogEventToAppender(logEvent) {\n  if (!enabled) return;\n  debug('Received log event ', logEvent);\n  const categoryAppenders = categories.appendersForCategory(\n    logEvent.categoryName\n  );\n  categoryAppenders.forEach((appender) => {\n    appender(logEvent);\n  });\n}\n\nfunction loadConfigurationFile(filename) {\n  debug(`Loading configuration from ${filename}`);\n  try {\n    return JSON.parse(fs.readFileSync(filename, 'utf8'));\n  } catch (e) {\n    throw new Error(\n      `Problem reading config from file \"${filename}\". Error was ${e.message}`,\n      e\n    );\n  }\n}\n\nfunction configure(configurationFileOrObject) {\n  if (enabled) {\n    // eslint-disable-next-line no-use-before-define\n    shutdown();\n  }\n\n  let configObject = configurationFileOrObject;\n\n  if (typeof configObject === 'string') {\n    configObject = loadConfigurationFile(configurationFileOrObject);\n  }\n  debug(`Configuration is ${configObject}`);\n\n  configuration.configure(deepClone(configObject));\n\n  clustering.onMessage(sendLogEventToAppender);\n\n  enabled = true;\n\n  // eslint-disable-next-line no-use-before-define\n  return log4js;\n}\n\nfunction recording() {\n  return recordingModule;\n}\n\n/**\n * Shutdown all log appenders. This will first disable all writing to appenders\n * and then call the shutdown function each appender.\n *\n * @params {Function} cb - The callback to be invoked once all appenders have\n *  shutdown. If an error occurs, the callback will be given the error object\n *  as the first argument.\n */\nfunction shutdown(cb) {\n  debug('Shutdown called. Disabling all log writing.');\n  // First, disable all writing to appenders. This prevents appenders from\n  // not being able to be drained because of run-away log writes.\n  enabled = false;\n\n  // Clone out to maintain a reference\n  const appendersToCheck = Array.from(appenders.values());\n\n  // Reset immediately to prevent leaks\n  appenders.init();\n  categories.init();\n\n  // Call each of the shutdown functions in parallel\n  const shutdownFunctions = appendersToCheck.reduceRight(\n    (accum, next) => (next.shutdown ? accum + 1 : accum),\n    0\n  );\n  if (shutdownFunctions === 0) {\n    debug('No appenders with shutdown functions found.');\n    return cb !== undefined && cb();\n  }\n\n  let completed = 0;\n  let error;\n  debug(`Found ${shutdownFunctions} appenders with shutdown functions.`);\n  function complete(err) {\n    error = error || err;\n    completed += 1;\n    debug(`Appender shutdowns complete: ${completed} / ${shutdownFunctions}`);\n    if (completed >= shutdownFunctions) {\n      debug('All shutdown functions completed.');\n      if (cb) {\n        cb(error);\n      }\n    }\n  }\n  appendersToCheck\n    .filter((a) => a.shutdown)\n    .forEach((a) => a.shutdown(complete));\n\n  return null;\n}\n\n/**\n * Get a logger instance.\n * @static\n * @param loggerCategoryName\n * @return {Logger} instance of logger for the category\n */\nfunction getLogger(category) {\n  if (!enabled) {\n    configure(\n      process.env.LOG4JS_CONFIG || {\n        appenders: { out: { type: 'stdout' } },\n        categories: { default: { appenders: ['out'], level: 'OFF' } },\n      }\n    );\n  }\n  return new Logger(category || 'default');\n}\n\n/**\n * @name log4js\n * @namespace Log4js\n * @property getLogger\n * @property configure\n * @property shutdown\n */\nconst log4js = {\n  getLogger,\n  configure,\n  shutdown,\n  connectLogger,\n  levels,\n  addLayout: layouts.addLayout,\n  recording,\n};\n\nmodule.exports = log4js;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/log4js.js?");

/***/ }),

/***/ "./node_modules/log4js/lib/logger.js":
/*!*******************************************!*\
  !*** ./node_modules/log4js/lib/logger.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* eslint no-underscore-dangle: [\"error\", { \"allow\": [\"_log\"] }] */\n\nconst debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('log4js:logger');\nconst LoggingEvent = __webpack_require__(/*! ./LoggingEvent */ \"./node_modules/log4js/lib/LoggingEvent.js\");\nconst levels = __webpack_require__(/*! ./levels */ \"./node_modules/log4js/lib/levels.js\");\nconst clustering = __webpack_require__(/*! ./clustering */ \"./node_modules/log4js/lib/clustering.js\");\nconst categories = __webpack_require__(/*! ./categories */ \"./node_modules/log4js/lib/categories.js\");\nconst configuration = __webpack_require__(/*! ./configuration */ \"./node_modules/log4js/lib/configuration.js\");\n\nconst stackReg = /at (?:(.+)\\s+\\()?(?:(.+?):(\\d+)(?::(\\d+))?|([^)]+))\\)?/;\n\nfunction defaultParseCallStack(data, skipIdx = 4) {\n  try {\n    const stacklines = data.stack.split('\\n').slice(skipIdx);\n    const lineMatch = stackReg.exec(stacklines[0]);\n    /* istanbul ignore else: failsafe */\n    if (lineMatch && lineMatch.length === 6) {\n      return {\n        functionName: lineMatch[1],\n        fileName: lineMatch[2],\n        lineNumber: parseInt(lineMatch[3], 10),\n        columnNumber: parseInt(lineMatch[4], 10),\n        callStack: stacklines.join('\\n'),\n      };\n      // eslint-disable-next-line no-else-return\n    } else {\n      // will never get here unless nodejs has changes to Error\n      console.error('log4js.logger - defaultParseCallStack error'); // eslint-disable-line no-console\n    }\n  } catch (err) {\n    // will never get error unless nodejs has breaking changes to Error\n    console.error('log4js.logger - defaultParseCallStack error', err); // eslint-disable-line no-console\n  }\n  return null;\n}\n\n/**\n * Logger to log messages.\n * use {@see log4js#getLogger(String)} to get an instance.\n *\n * @name Logger\n * @namespace Log4js\n * @param name name of category to log to\n * @param level - the loglevel for the category\n * @param dispatch - the function which will receive the logevents\n *\n * @author Stephan Strittmatter\n */\nclass Logger {\n  constructor(name) {\n    if (!name) {\n      throw new Error('No category provided.');\n    }\n    this.category = name;\n    this.context = {};\n    this.parseCallStack = defaultParseCallStack;\n    debug(`Logger created (${this.category}, ${this.level})`);\n  }\n\n  get level() {\n    return levels.getLevel(\n      categories.getLevelForCategory(this.category),\n      levels.OFF\n    );\n  }\n\n  set level(level) {\n    categories.setLevelForCategory(\n      this.category,\n      levels.getLevel(level, this.level)\n    );\n  }\n\n  get useCallStack() {\n    return categories.getEnableCallStackForCategory(this.category);\n  }\n\n  set useCallStack(bool) {\n    categories.setEnableCallStackForCategory(this.category, bool === true);\n  }\n\n  log(level, ...args) {\n    const logLevel = levels.getLevel(level);\n    if (!logLevel) {\n      if (configuration.validIdentifier(level) && args.length > 0) {\n        // logLevel not found but of valid signature, WARN before fallback to INFO\n        this.log(\n          levels.WARN,\n          'log4js:logger.log: valid log-level not found as first parameter given:',\n          level\n        );\n        this.log(levels.INFO, `[${level}]`, ...args);\n      } else {\n        // apart from fallback, allow .log(...args) to be synonym with .log(\"INFO\", ...args)\n        this.log(levels.INFO, level, ...args);\n      }\n    } else if (this.isLevelEnabled(logLevel)) {\n      this._log(logLevel, args);\n    }\n  }\n\n  isLevelEnabled(otherLevel) {\n    return this.level.isLessThanOrEqualTo(otherLevel);\n  }\n\n  _log(level, data) {\n    debug(`sending log data (${level}) to appenders`);\n    const loggingEvent = new LoggingEvent(\n      this.category,\n      level,\n      data,\n      this.context,\n      this.useCallStack && this.parseCallStack(new Error())\n    );\n    clustering.send(loggingEvent);\n  }\n\n  addContext(key, value) {\n    this.context[key] = value;\n  }\n\n  removeContext(key) {\n    delete this.context[key];\n  }\n\n  clearContext() {\n    this.context = {};\n  }\n\n  setParseCallStackFunction(parseFunction) {\n    this.parseCallStack = parseFunction;\n  }\n}\n\nfunction addLevelMethods(target) {\n  const level = levels.getLevel(target);\n\n  const levelStrLower = level.toString().toLowerCase();\n  const levelMethod = levelStrLower.replace(/_([a-z])/g, (g) =>\n    g[1].toUpperCase()\n  );\n  const isLevelMethod = levelMethod[0].toUpperCase() + levelMethod.slice(1);\n\n  Logger.prototype[`is${isLevelMethod}Enabled`] = function () {\n    return this.isLevelEnabled(level);\n  };\n\n  Logger.prototype[levelMethod] = function (...args) {\n    this.log(level, ...args);\n  };\n}\n\nlevels.levels.forEach(addLevelMethods);\n\nconfiguration.addListener(() => {\n  levels.levels.forEach(addLevelMethods);\n});\n\nmodule.exports = Logger;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/log4js/lib/logger.js?");

/***/ }),

/***/ "./node_modules/ms/index.js":
/*!**********************************!*\
  !*** ./node_modules/ms/index.js ***!
  \**********************************/
/***/ ((module) => {

eval("/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/ms/index.js?");

/***/ }),

/***/ "./node_modules/rfdc/index.js":
/*!************************************!*\
  !*** ./node_modules/rfdc/index.js ***!
  \************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = rfdc\n\nfunction copyBuffer (cur) {\n  if (cur instanceof Buffer) {\n    return Buffer.from(cur)\n  }\n\n  return new cur.constructor(cur.buffer.slice(), cur.byteOffset, cur.length)\n}\n\nfunction rfdc (opts) {\n  opts = opts || {}\n\n  if (opts.circles) return rfdcCircles(opts)\n  return opts.proto ? cloneProto : clone\n\n  function cloneArray (a, fn) {\n    var keys = Object.keys(a)\n    var a2 = new Array(keys.length)\n    for (var i = 0; i < keys.length; i++) {\n      var k = keys[i]\n      var cur = a[k]\n      if (typeof cur !== 'object' || cur === null) {\n        a2[k] = cur\n      } else if (cur instanceof Date) {\n        a2[k] = new Date(cur)\n      } else if (ArrayBuffer.isView(cur)) {\n        a2[k] = copyBuffer(cur)\n      } else {\n        a2[k] = fn(cur)\n      }\n    }\n    return a2\n  }\n\n  function clone (o) {\n    if (typeof o !== 'object' || o === null) return o\n    if (o instanceof Date) return new Date(o)\n    if (Array.isArray(o)) return cloneArray(o, clone)\n    if (o instanceof Map) return new Map(cloneArray(Array.from(o), clone))\n    if (o instanceof Set) return new Set(cloneArray(Array.from(o), clone))\n    var o2 = {}\n    for (var k in o) {\n      if (Object.hasOwnProperty.call(o, k) === false) continue\n      var cur = o[k]\n      if (typeof cur !== 'object' || cur === null) {\n        o2[k] = cur\n      } else if (cur instanceof Date) {\n        o2[k] = new Date(cur)\n      } else if (cur instanceof Map) {\n        o2[k] = new Map(cloneArray(Array.from(cur), clone))\n      } else if (cur instanceof Set) {\n        o2[k] = new Set(cloneArray(Array.from(cur), clone))\n      } else if (ArrayBuffer.isView(cur)) {\n        o2[k] = copyBuffer(cur)\n      } else {\n        o2[k] = clone(cur)\n      }\n    }\n    return o2\n  }\n\n  function cloneProto (o) {\n    if (typeof o !== 'object' || o === null) return o\n    if (o instanceof Date) return new Date(o)\n    if (Array.isArray(o)) return cloneArray(o, cloneProto)\n    if (o instanceof Map) return new Map(cloneArray(Array.from(o), cloneProto))\n    if (o instanceof Set) return new Set(cloneArray(Array.from(o), cloneProto))\n    var o2 = {}\n    for (var k in o) {\n      var cur = o[k]\n      if (typeof cur !== 'object' || cur === null) {\n        o2[k] = cur\n      } else if (cur instanceof Date) {\n        o2[k] = new Date(cur)\n      } else if (cur instanceof Map) {\n        o2[k] = new Map(cloneArray(Array.from(cur), cloneProto))\n      } else if (cur instanceof Set) {\n        o2[k] = new Set(cloneArray(Array.from(cur), cloneProto))\n      } else if (ArrayBuffer.isView(cur)) {\n        o2[k] = copyBuffer(cur)\n      } else {\n        o2[k] = cloneProto(cur)\n      }\n    }\n    return o2\n  }\n}\n\nfunction rfdcCircles (opts) {\n  var refs = []\n  var refsNew = []\n\n  return opts.proto ? cloneProto : clone\n\n  function cloneArray (a, fn) {\n    var keys = Object.keys(a)\n    var a2 = new Array(keys.length)\n    for (var i = 0; i < keys.length; i++) {\n      var k = keys[i]\n      var cur = a[k]\n      if (typeof cur !== 'object' || cur === null) {\n        a2[k] = cur\n      } else if (cur instanceof Date) {\n        a2[k] = new Date(cur)\n      } else if (ArrayBuffer.isView(cur)) {\n        a2[k] = copyBuffer(cur)\n      } else {\n        var index = refs.indexOf(cur)\n        if (index !== -1) {\n          a2[k] = refsNew[index]\n        } else {\n          a2[k] = fn(cur)\n        }\n      }\n    }\n    return a2\n  }\n\n  function clone (o) {\n    if (typeof o !== 'object' || o === null) return o\n    if (o instanceof Date) return new Date(o)\n    if (Array.isArray(o)) return cloneArray(o, clone)\n    if (o instanceof Map) return new Map(cloneArray(Array.from(o), clone))\n    if (o instanceof Set) return new Set(cloneArray(Array.from(o), clone))\n    var o2 = {}\n    refs.push(o)\n    refsNew.push(o2)\n    for (var k in o) {\n      if (Object.hasOwnProperty.call(o, k) === false) continue\n      var cur = o[k]\n      if (typeof cur !== 'object' || cur === null) {\n        o2[k] = cur\n      } else if (cur instanceof Date) {\n        o2[k] = new Date(cur)\n      } else if (cur instanceof Map) {\n        o2[k] = new Map(cloneArray(Array.from(cur), clone))\n      } else if (cur instanceof Set) {\n        o2[k] = new Set(cloneArray(Array.from(cur), clone))\n      } else if (ArrayBuffer.isView(cur)) {\n        o2[k] = copyBuffer(cur)\n      } else {\n        var i = refs.indexOf(cur)\n        if (i !== -1) {\n          o2[k] = refsNew[i]\n        } else {\n          o2[k] = clone(cur)\n        }\n      }\n    }\n    refs.pop()\n    refsNew.pop()\n    return o2\n  }\n\n  function cloneProto (o) {\n    if (typeof o !== 'object' || o === null) return o\n    if (o instanceof Date) return new Date(o)\n    if (Array.isArray(o)) return cloneArray(o, cloneProto)\n    if (o instanceof Map) return new Map(cloneArray(Array.from(o), cloneProto))\n    if (o instanceof Set) return new Set(cloneArray(Array.from(o), cloneProto))\n    var o2 = {}\n    refs.push(o)\n    refsNew.push(o2)\n    for (var k in o) {\n      var cur = o[k]\n      if (typeof cur !== 'object' || cur === null) {\n        o2[k] = cur\n      } else if (cur instanceof Date) {\n        o2[k] = new Date(cur)\n      } else if (cur instanceof Map) {\n        o2[k] = new Map(cloneArray(Array.from(cur), cloneProto))\n      } else if (cur instanceof Set) {\n        o2[k] = new Set(cloneArray(Array.from(cur), cloneProto))\n      } else if (ArrayBuffer.isView(cur)) {\n        o2[k] = copyBuffer(cur)\n      } else {\n        var i = refs.indexOf(cur)\n        if (i !== -1) {\n          o2[k] = refsNew[i]\n        } else {\n          o2[k] = cloneProto(cur)\n        }\n      }\n    }\n    refs.pop()\n    refsNew.pop()\n    return o2\n  }\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/rfdc/index.js?");

/***/ }),

/***/ "./node_modules/streamroller/lib/DateRollingFileStream.js":
/*!****************************************************************!*\
  !*** ./node_modules/streamroller/lib/DateRollingFileStream.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const RollingFileWriteStream = __webpack_require__(/*! ./RollingFileWriteStream */ \"./node_modules/streamroller/lib/RollingFileWriteStream.js\");\n\n// just to adapt the previous version\nclass DateRollingFileStream extends RollingFileWriteStream {\n  constructor(filename, pattern, options) {\n    if (pattern && typeof(pattern) === 'object') {\n      options = pattern;\n      pattern = null;\n    }\n    if (!options) {\n      options = {};\n    }\n    if (!pattern) {\n      pattern = 'yyyy-MM-dd';\n    }\n    options.pattern = pattern;\n    if (!options.numBackups && options.numBackups !== 0) {\n      if (!options.daysToKeep && options.daysToKeep !== 0) {\n        options.daysToKeep = 1;\n      } else {\n        process.emitWarning(\n          \"options.daysToKeep is deprecated due to the confusion it causes when used \" + \n          \"together with file size rolling. Please use options.numBackups instead.\",\n          \"DeprecationWarning\", \"streamroller-DEP0001\"\n        );\n      }\n      options.numBackups = options.daysToKeep;\n    } else {\n      options.daysToKeep = options.numBackups;\n    }\n    super(filename, options);\n    this.mode = this.options.mode;\n  }\n\n  get theStream() {\n    return this.currentFileStream;\n  }\n\n}\n\nmodule.exports = DateRollingFileStream;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/streamroller/lib/DateRollingFileStream.js?");

/***/ }),

/***/ "./node_modules/streamroller/lib/RollingFileStream.js":
/*!************************************************************!*\
  !*** ./node_modules/streamroller/lib/RollingFileStream.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const RollingFileWriteStream = __webpack_require__(/*! ./RollingFileWriteStream */ \"./node_modules/streamroller/lib/RollingFileWriteStream.js\");\n\n// just to adapt the previous version\nclass RollingFileStream extends RollingFileWriteStream {\n  constructor(filename, size, backups, options) {\n    if (!options) {\n      options = {};\n    }\n    if (size) {\n      options.maxSize = size;\n    }\n    if (!options.numBackups && options.numBackups !== 0) {\n      if (!backups && backups !== 0) {\n        backups = 1;\n      }\n      options.numBackups = backups;\n    }\n    super(filename, options);\n    this.backups = options.numBackups;\n    this.size = this.options.maxSize;\n  }\n\n  get theStream() {\n    return this.currentFileStream;\n  }\n\n}\n\nmodule.exports = RollingFileStream;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/streamroller/lib/RollingFileStream.js?");

/***/ }),

/***/ "./node_modules/streamroller/lib/RollingFileWriteStream.js":
/*!*****************************************************************!*\
  !*** ./node_modules/streamroller/lib/RollingFileWriteStream.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")(\"streamroller:RollingFileWriteStream\");\nconst fs = __webpack_require__(/*! fs-extra */ \"./node_modules/fs-extra/lib/index.js\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst os = __webpack_require__(/*! os */ \"os\");\nconst newNow = __webpack_require__(/*! ./now */ \"./node_modules/streamroller/lib/now.js\");\nconst format = __webpack_require__(/*! date-format */ \"./node_modules/date-format/lib/index.js\");\nconst { Writable } = __webpack_require__(/*! stream */ \"stream\");\nconst fileNameFormatter = __webpack_require__(/*! ./fileNameFormatter */ \"./node_modules/streamroller/lib/fileNameFormatter.js\");\nconst fileNameParser = __webpack_require__(/*! ./fileNameParser */ \"./node_modules/streamroller/lib/fileNameParser.js\");\nconst moveAndMaybeCompressFile = __webpack_require__(/*! ./moveAndMaybeCompressFile */ \"./node_modules/streamroller/lib/moveAndMaybeCompressFile.js\");\n\nconst deleteFiles = fileNames => {\n  debug(`deleteFiles: files to delete: ${fileNames}`);\n  return Promise.all(fileNames.map(f => fs.unlink(f).catch((e) => {\n    debug(`deleteFiles: error when unlinking ${f}, ignoring. Error was ${e}`);\n  })));\n};\n\n/**\n * RollingFileWriteStream is mainly used when writing to a file rolling by date or size.\n * RollingFileWriteStream inherits from stream.Writable\n */\nclass RollingFileWriteStream extends Writable {\n  /**\n   * Create a RollingFileWriteStream\n   * @constructor\n   * @param {string} filePath - The file path to write.\n   * @param {object} options - The extra options\n   * @param {number} options.numToKeep - The max numbers of files to keep.\n   * @param {number} options.maxSize - The maxSize one file can reach. Unit is Byte.\n   *                                   This should be more than 1024. The default is 0.\n   *                                   If not specified or 0, then no log rolling will happen.\n   * @param {string} options.mode - The mode of the files. The default is '0600'. Refer to stream.writable for more.\n   * @param {string} options.flags - The default is 'a'. Refer to stream.flags for more.\n   * @param {boolean} options.compress - Whether to compress backup files.\n   * @param {boolean} options.keepFileExt - Whether to keep the file extension.\n   * @param {string} options.pattern - The date string pattern in the file name.\n   * @param {boolean} options.alwaysIncludePattern - Whether to add date to the name of the first file.\n   */\n  constructor(filePath, options) {\n    debug(`constructor: creating RollingFileWriteStream. path=${filePath}`);\n    if (typeof filePath !== \"string\" || filePath.length === 0) {\n      throw new Error(`Invalid filename: ${filePath}`);\n    } else if (filePath.endsWith(path.sep)) {\n      throw new Error(`Filename is a directory: ${filePath}`);\n    } else {\n      // handle ~ expansion: https://github.com/nodejs/node/issues/684\n      // exclude ~ and ~filename as these can be valid files\n      filePath = filePath.replace(new RegExp(`^~(?=${path.sep}.+)`), os.homedir());\n    }\n    super(options);\n    this.options = this._parseOption(options);\n    this.fileObject = path.parse(filePath);\n    if (this.fileObject.dir === \"\") {\n      this.fileObject = path.parse(path.join(process.cwd(), filePath));\n    }\n    this.fileFormatter = fileNameFormatter({\n      file: this.fileObject,\n      alwaysIncludeDate: this.options.alwaysIncludePattern,\n      needsIndex: this.options.maxSize < Number.MAX_SAFE_INTEGER,\n      compress: this.options.compress,\n      keepFileExt: this.options.keepFileExt,\n      fileNameSep: this.options.fileNameSep\n    });\n\n    this.fileNameParser = fileNameParser({\n      file: this.fileObject,\n      keepFileExt: this.options.keepFileExt,\n      pattern: this.options.pattern,\n      fileNameSep: this.options.fileNameSep\n    });\n\n    this.state = {\n      currentSize: 0\n    };\n\n    if (this.options.pattern) {\n      this.state.currentDate = format(this.options.pattern, newNow());\n    }\n\n    this.filename = this.fileFormatter({\n      index: 0,\n      date: this.state.currentDate\n    });\n    if ([\"a\", \"a+\", \"as\", \"as+\"].includes(this.options.flags)) {\n      this._setExistingSizeAndDate();\n    }\n\n    debug(\n      `constructor: create new file ${this.filename}, state=${JSON.stringify(\n        this.state\n      )}`\n    );\n    this._renewWriteStream();\n  }\n\n  _setExistingSizeAndDate() {\n    try {\n      const stats = fs.statSync(this.filename);\n      this.state.currentSize = stats.size;\n      if (this.options.pattern) {\n        this.state.currentDate = format(this.options.pattern, stats.mtime);\n      }\n    } catch (e) {\n      //file does not exist, that's fine - move along\n      return;\n    }\n  }\n\n  _parseOption(rawOptions) {\n    const defaultOptions = {\n      maxSize: 0,\n      numToKeep: Number.MAX_SAFE_INTEGER,\n      encoding: \"utf8\",\n      mode: parseInt(\"0600\", 8),\n      flags: \"a\",\n      compress: false,\n      keepFileExt: false,\n      alwaysIncludePattern: false\n    };\n    const options = Object.assign({}, defaultOptions, rawOptions);\n    if (!options.maxSize) {\n      delete options.maxSize;\n    } else if (options.maxSize <= 0) {\n      throw new Error(`options.maxSize (${options.maxSize}) should be > 0`);\n    }\n    // options.numBackups will supercede options.numToKeep\n    if (options.numBackups || options.numBackups === 0) {\n      if (options.numBackups < 0) {\n        throw new Error(`options.numBackups (${options.numBackups}) should be >= 0`);\n      } else if (options.numBackups >= Number.MAX_SAFE_INTEGER) {\n        // to cater for numToKeep (include the hot file) at Number.MAX_SAFE_INTEGER\n        throw new Error(`options.numBackups (${options.numBackups}) should be < Number.MAX_SAFE_INTEGER`);\n      } else {\n        options.numToKeep = options.numBackups + 1;\n      }\n    } else if (options.numToKeep <= 0) {\n      throw new Error(`options.numToKeep (${options.numToKeep}) should be > 0`);\n    }\n    debug(\n      `_parseOption: creating stream with option=${JSON.stringify(options)}`\n    );\n    return options;\n  }\n\n  _final(callback) {\n    this.currentFileStream.end(\"\", this.options.encoding, callback);\n  }\n\n  _write(chunk, encoding, callback) {\n    this._shouldRoll().then(() => {\n      debug(\n        `_write: writing chunk. ` +\n          `file=${this.currentFileStream.path} ` +\n          `state=${JSON.stringify(this.state)} ` +\n          `chunk=${chunk}`\n      );\n      this.currentFileStream.write(chunk, encoding, e => {\n        this.state.currentSize += chunk.length;\n        callback(e);\n      });\n    });\n  }\n\n  async _shouldRoll() {\n    if (this._dateChanged() || this._tooBig()) {\n      debug(\n        `_shouldRoll: rolling because dateChanged? ${this._dateChanged()} or tooBig? ${this._tooBig()}`\n      );\n      await this._roll();\n    }\n  }\n\n  _dateChanged() {\n    return (\n      this.state.currentDate &&\n      this.state.currentDate !== format(this.options.pattern, newNow())\n    );\n  }\n\n  _tooBig() {\n    return this.state.currentSize >= this.options.maxSize;\n  }\n\n  _roll() {\n    debug(`_roll: closing the current stream`);\n    return new Promise((resolve, reject) => {\n      this.currentFileStream.end(\"\", this.options.encoding, () => {\n        this._moveOldFiles()\n          .then(resolve)\n          .catch(reject);\n      });\n    });\n  }\n\n  async _moveOldFiles() {\n    const files = await this._getExistingFiles();\n    const todaysFiles = this.state.currentDate\n      ? files.filter(f => f.date === this.state.currentDate)\n      : files;\n    for (let i = todaysFiles.length; i >= 0; i--) {\n      debug(`_moveOldFiles: i = ${i}`);\n      const sourceFilePath = this.fileFormatter({\n        date: this.state.currentDate,\n        index: i\n      });\n      const targetFilePath = this.fileFormatter({\n        date: this.state.currentDate,\n        index: i + 1\n      });\n\n      const moveAndCompressOptions = {\n        compress: this.options.compress && i === 0,\n        mode: this.options.mode\n      };\n      await moveAndMaybeCompressFile(\n        sourceFilePath,\n        targetFilePath,\n        moveAndCompressOptions\n      );\n    }\n\n    this.state.currentSize = 0;\n    this.state.currentDate = this.state.currentDate\n      ? format(this.options.pattern, newNow())\n      : null;\n    debug(\n      `_moveOldFiles: finished rolling files. state=${JSON.stringify(\n        this.state\n      )}`\n    );\n    this._renewWriteStream();\n    // wait for the file to be open before cleaning up old ones,\n    // otherwise the daysToKeep calculations can be off\n    await new Promise((resolve, reject) => {\n      this.currentFileStream.write(\"\", \"utf8\", () => {\n        this._clean()\n          .then(resolve)\n          .catch(reject);\n      });\n    });\n  }\n\n  // Sorted from the oldest to the latest\n  async _getExistingFiles() {\n    const files = await fs.readdir(this.fileObject.dir)\n      .catch( /* istanbul ignore next: will not happen on windows */ () => []);\n\n    debug(`_getExistingFiles: files=${files}`);\n    const existingFileDetails = files\n      .map(n => this.fileNameParser(n))\n      .filter(n => n);\n\n    const getKey = n =>\n      (n.timestamp ? n.timestamp : newNow().getTime()) - n.index;\n    existingFileDetails.sort((a, b) => getKey(a) - getKey(b));\n\n    return existingFileDetails;\n  }\n\n  _renewWriteStream() {\n    const filePath = this.fileFormatter({\n      date: this.state.currentDate,\n      index: 0\n    });\n\n    // attempt to create the directory\n    const mkdir = (dir) => {\n      try {\n        return fs.mkdirSync(dir, { recursive: true });\n      }\n      // backward-compatible fs.mkdirSync for nodejs pre-10.12.0 (without recursive option)\n      catch (e) {\n        // recursive creation of parent first\n        if (e.code === \"ENOENT\") {\n          mkdir(path.dirname(dir));\n          return mkdir(dir);\n        }\n\n        // throw error for all except EEXIST and EROFS (read-only filesystem)\n        if (e.code !== \"EEXIST\" && e.code !== \"EROFS\") {\n          throw e;\n        }\n\n        // EEXIST: throw if file and not directory\n        // EROFS : throw if directory not found\n        else {\n          try {\n            if (fs.statSync(dir).isDirectory()) {\n              return dir;\n            }\n            throw e;\n          } catch (err) {\n            throw e;\n          }\n        }\n      }\n    };\n    mkdir(this.fileObject.dir);\n\n    const ops = {\n      flags: this.options.flags,\n      encoding: this.options.encoding,\n      mode: this.options.mode\n    };\n    const renameKey = function(obj, oldKey, newKey) {\n      obj[newKey] = obj[oldKey];\n      delete obj[oldKey];\n      return obj;\n    };\n    // try to throw EISDIR, EROFS, EACCES\n    fs.appendFileSync(filePath, \"\", renameKey({ ...ops }, \"flags\", \"flag\"));\n    this.currentFileStream = fs.createWriteStream(filePath, ops);\n    this.currentFileStream.on(\"error\", e => {\n      this.emit(\"error\", e);\n    });\n  }\n\n  async _clean() {\n    const existingFileDetails = await this._getExistingFiles();\n    debug(\n      `_clean: numToKeep = ${this.options.numToKeep}, existingFiles = ${existingFileDetails.length}`\n    );\n    debug(\"_clean: existing files are: \", existingFileDetails);\n    if (this._tooManyFiles(existingFileDetails.length)) {\n      const fileNamesToRemove = existingFileDetails\n        .slice(0, existingFileDetails.length - this.options.numToKeep)\n        .map(f => path.format({ dir: this.fileObject.dir, base: f.filename }));\n      await deleteFiles(fileNamesToRemove);\n    }\n  }\n\n  _tooManyFiles(numFiles) {\n    return this.options.numToKeep > 0 && numFiles > this.options.numToKeep;\n  }\n}\n\nmodule.exports = RollingFileWriteStream;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/streamroller/lib/RollingFileWriteStream.js?");

/***/ }),

/***/ "./node_modules/streamroller/lib/fileNameFormatter.js":
/*!************************************************************!*\
  !*** ./node_modules/streamroller/lib/fileNameFormatter.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")(\"streamroller:fileNameFormatter\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst ZIP_EXT = \".gz\";\nconst DEFAULT_FILENAME_SEP = \".\";\n\nmodule.exports = ({\n  file,\n  keepFileExt,\n  needsIndex,\n  alwaysIncludeDate,\n  compress,\n  fileNameSep\n}) => {\n  let FILENAME_SEP = fileNameSep || DEFAULT_FILENAME_SEP;\n  const dirAndName = path.join(file.dir, file.name);\n\n  const ext = f => f + file.ext;\n\n  const index = (f, i, d) =>\n    (needsIndex || !d) && i ? f + FILENAME_SEP + i : f;\n\n  const date = (f, i, d) => {\n    return (i > 0 || alwaysIncludeDate) && d ? f + FILENAME_SEP + d : f;\n  };\n\n  const gzip = (f, i) => (i && compress ? f + ZIP_EXT : f);\n\n  const parts = keepFileExt\n    ? [date, index, ext, gzip]\n    : [ext, date, index, gzip];\n\n  return ({ date, index }) => {\n    debug(`_formatFileName: date=${date}, index=${index}`);\n    return parts.reduce(\n      (filename, part) => part(filename, index, date),\n      dirAndName\n    );\n  };\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/streamroller/lib/fileNameFormatter.js?");

/***/ }),

/***/ "./node_modules/streamroller/lib/fileNameParser.js":
/*!*********************************************************!*\
  !*** ./node_modules/streamroller/lib/fileNameParser.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")(\"streamroller:fileNameParser\");\nconst ZIP_EXT = \".gz\";\nconst format = __webpack_require__(/*! date-format */ \"./node_modules/date-format/lib/index.js\");\nconst DEFAULT_FILENAME_SEP = \".\";\n\nmodule.exports = ({ file, keepFileExt, pattern, fileNameSep }) => {\n  let FILENAME_SEP = fileNameSep || DEFAULT_FILENAME_SEP;\n  // All these functions take two arguments: f, the filename, and p, the result placeholder\n  // They return the filename with any matching parts removed.\n  // The \"zip\" function, for instance, removes the \".gz\" part of the filename (if present)\n  const zip = (f, p) => {\n    if (f.endsWith(ZIP_EXT)) {\n      debug(\"it is gzipped\");\n      p.isCompressed = true;\n      return f.slice(0, -1 * ZIP_EXT.length);\n    }\n    return f;\n  };\n\n  const __NOT_MATCHING__ = \"__NOT_MATCHING__\";\n\n  const extAtEnd = f => {\n    if (f.startsWith(file.name) && f.endsWith(file.ext)) {\n      debug(\"it starts and ends with the right things\");\n      return f.slice(file.name.length + 1, -1 * file.ext.length);\n    }\n    return __NOT_MATCHING__;\n  };\n\n  const extInMiddle = f => {\n    if (f.startsWith(file.base)) {\n      debug(\"it starts with the right things\");\n      return f.slice(file.base.length + 1);\n    }\n    return __NOT_MATCHING__;\n  };\n\n  const dateAndIndex = (f, p) => {\n    const items = f.split(FILENAME_SEP);\n    let indexStr = items[items.length - 1];\n    debug(\"items: \", items, \", indexStr: \", indexStr);\n    let dateStr = f;\n    if (indexStr !== undefined && indexStr.match(/^\\d+$/)) {\n      dateStr = f.slice(0, -1 * (indexStr.length + 1));\n      debug(`dateStr is ${dateStr}`);\n      if (pattern && !dateStr) {\n        dateStr = indexStr;\n        indexStr = \"0\";\n      }\n    } else {\n      indexStr = \"0\";\n    }\n\n    try {\n      // Two arguments for new Date() are intentional. This will set other date\n      // components to minimal values in the current timezone instead of UTC,\n      // as new Date(0) will do.\n      const date = format.parse(pattern, dateStr, new Date(0, 0));\n      if (format.asString(pattern, date) !== dateStr) return f;\n      p.index = parseInt(indexStr, 10);\n      p.date = dateStr;\n      p.timestamp = date.getTime();\n      return \"\";\n    } catch (e) {\n      //not a valid date, don't panic.\n      debug(`Problem parsing ${dateStr} as ${pattern}, error was: `, e);\n      return f;\n    }\n  };\n\n  const index = (f, p) => {\n    if (f.match(/^\\d+$/)) {\n      debug(\"it has an index\");\n      p.index = parseInt(f, 10);\n      return \"\";\n    }\n    return f;\n  };\n\n  let parts = [\n    zip,\n    keepFileExt ? extAtEnd : extInMiddle,\n    pattern ? dateAndIndex : index\n  ];\n\n  return filename => {\n    let result = { filename, index: 0, isCompressed: false };\n    // pass the filename through each of the file part parsers\n    let whatsLeftOver = parts.reduce(\n      (remains, part) => part(remains, result),\n      filename\n    );\n    // if there's anything left after parsing, then it wasn't a valid filename\n    return whatsLeftOver ? null : result;\n  };\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/streamroller/lib/fileNameParser.js?");

/***/ }),

/***/ "./node_modules/streamroller/lib/index.js":
/*!************************************************!*\
  !*** ./node_modules/streamroller/lib/index.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = {\n  RollingFileWriteStream: __webpack_require__(/*! ./RollingFileWriteStream */ \"./node_modules/streamroller/lib/RollingFileWriteStream.js\"),\n  RollingFileStream: __webpack_require__(/*! ./RollingFileStream */ \"./node_modules/streamroller/lib/RollingFileStream.js\"),\n  DateRollingFileStream: __webpack_require__(/*! ./DateRollingFileStream */ \"./node_modules/streamroller/lib/DateRollingFileStream.js\")\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/streamroller/lib/index.js?");

/***/ }),

/***/ "./node_modules/streamroller/lib/moveAndMaybeCompressFile.js":
/*!*******************************************************************!*\
  !*** ./node_modules/streamroller/lib/moveAndMaybeCompressFile.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! debug */ \"./node_modules/debug/src/index.js\")('streamroller:moveAndMaybeCompressFile');\nconst fs = __webpack_require__(/*! fs-extra */ \"./node_modules/fs-extra/lib/index.js\");\nconst zlib = __webpack_require__(/*! zlib */ \"zlib\");\n\nconst _parseOption = function(rawOptions){\n  const defaultOptions = {\n    mode: parseInt(\"0600\", 8),\n    compress: false,\n  };\n  const options = Object.assign({}, defaultOptions, rawOptions);\n  debug(`_parseOption: moveAndMaybeCompressFile called with option=${JSON.stringify(options)}`);\n  return options;\n};\n\nconst moveAndMaybeCompressFile = async (\n  sourceFilePath,\n  targetFilePath,\n  options\n) => {\n  options = _parseOption(options);\n\n  if (sourceFilePath === targetFilePath) {\n    debug(`moveAndMaybeCompressFile: source and target are the same, not doing anything`);\n    return;\n  }\n\n  if (await fs.pathExists(sourceFilePath)) {\n    debug(\n      `moveAndMaybeCompressFile: moving file from ${sourceFilePath} to ${targetFilePath} ${\n        options.compress ? \"with\" : \"without\"\n      } compress`\n    );\n    if (options.compress) {\n      await new Promise((resolve, reject) => {\n        let isCreated = false;\n        // to avoid concurrency, the forked process which can create the file will proceed (using flags wx)\n        const writeStream = fs.createWriteStream(targetFilePath, { mode: options.mode, flags: \"wx\" })\n          // wait until writable stream is valid before proceeding to read\n          .on(\"open\", () => {\n            isCreated = true;\n            const readStream = fs.createReadStream(sourceFilePath)\n              // wait until readable stream is valid before piping\n              .on(\"open\", () => {\n                readStream.pipe(zlib.createGzip()).pipe(writeStream);\n              })\n              .on(\"error\", (e) => {\n                debug(`moveAndMaybeCompressFile: error reading ${sourceFilePath}`, e);\n                // manually close writable: https://nodejs.org/api/stream.html#readablepipedestination-options\n                writeStream.destroy(e);\n              });\n          })\n          .on(\"finish\", () => {\n            debug(`moveAndMaybeCompressFile: finished compressing ${targetFilePath}, deleting ${sourceFilePath}`);\n            // delete sourceFilePath\n            fs.unlink(sourceFilePath)\n              .then(resolve)\n              .catch((e) => {\n                debug(`moveAndMaybeCompressFile: error deleting ${sourceFilePath}, truncating instead`, e);\n                // fallback to truncate\n                fs.truncate(sourceFilePath)\n                  .then(resolve)\n                  .catch((e) => {\n                    debug(`moveAndMaybeCompressFile: error truncating ${sourceFilePath}`, e);\n                    reject(e);\n                  });\n              });\n          })\n          .on(\"error\", (e) => {\n            if (!isCreated) {\n              debug(`moveAndMaybeCompressFile: error creating ${targetFilePath}`, e);\n              // do not do anything if handled by another forked process\n              reject(e);\n            } else {\n              debug(`moveAndMaybeCompressFile: error writing ${targetFilePath}, deleting`, e);\n              // delete targetFilePath (taking as nothing happened)\n              fs.unlink(targetFilePath)\n                .then(() => { reject(e); })\n                .catch((e) => {\n                  debug(`moveAndMaybeCompressFile: error deleting ${targetFilePath}`, e);\n                  reject(e);\n                });\n            }\n          });\n      }).catch(() => {});\n    } else {\n      debug(`moveAndMaybeCompressFile: renaming ${sourceFilePath} to ${targetFilePath}`);\n      try {\n        await fs.move(sourceFilePath, targetFilePath, { overwrite: true });\n      } catch (e) {\n        debug(`moveAndMaybeCompressFile: error renaming ${sourceFilePath} to ${targetFilePath}`, e);\n        debug(`moveAndMaybeCompressFile: trying copy+truncate instead`);\n        await fs.copy(sourceFilePath, targetFilePath, { overwrite: true });\n        await fs.truncate(sourceFilePath);\n      }\n    }\n  }\n};\n\nmodule.exports = moveAndMaybeCompressFile;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/streamroller/lib/moveAndMaybeCompressFile.js?");

/***/ }),

/***/ "./node_modules/streamroller/lib/now.js":
/*!**********************************************!*\
  !*** ./node_modules/streamroller/lib/now.js ***!
  \**********************************************/
/***/ ((module) => {

eval("// allows us to inject a mock date in tests\nmodule.exports = () => new Date();\n\n\n//# sourceURL=webpack://udan-react/./node_modules/streamroller/lib/now.js?");

/***/ }),

/***/ "./node_modules/supports-color/index.js":
/*!**********************************************!*\
  !*** ./node_modules/supports-color/index.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst os = __webpack_require__(/*! os */ \"os\");\nconst tty = __webpack_require__(/*! tty */ \"tty\");\nconst hasFlag = __webpack_require__(/*! has-flag */ \"./node_modules/has-flag/index.js\");\n\nconst {env} = process;\n\nlet forceColor;\nif (hasFlag('no-color') ||\n\thasFlag('no-colors') ||\n\thasFlag('color=false') ||\n\thasFlag('color=never')) {\n\tforceColor = 0;\n} else if (hasFlag('color') ||\n\thasFlag('colors') ||\n\thasFlag('color=true') ||\n\thasFlag('color=always')) {\n\tforceColor = 1;\n}\n\nif ('FORCE_COLOR' in env) {\n\tif (env.FORCE_COLOR === 'true') {\n\t\tforceColor = 1;\n\t} else if (env.FORCE_COLOR === 'false') {\n\t\tforceColor = 0;\n\t} else {\n\t\tforceColor = env.FORCE_COLOR.length === 0 ? 1 : Math.min(parseInt(env.FORCE_COLOR, 10), 3);\n\t}\n}\n\nfunction translateLevel(level) {\n\tif (level === 0) {\n\t\treturn false;\n\t}\n\n\treturn {\n\t\tlevel,\n\t\thasBasic: true,\n\t\thas256: level >= 2,\n\t\thas16m: level >= 3\n\t};\n}\n\nfunction supportsColor(haveStream, streamIsTTY) {\n\tif (forceColor === 0) {\n\t\treturn 0;\n\t}\n\n\tif (hasFlag('color=16m') ||\n\t\thasFlag('color=full') ||\n\t\thasFlag('color=truecolor')) {\n\t\treturn 3;\n\t}\n\n\tif (hasFlag('color=256')) {\n\t\treturn 2;\n\t}\n\n\tif (haveStream && !streamIsTTY && forceColor === undefined) {\n\t\treturn 0;\n\t}\n\n\tconst min = forceColor || 0;\n\n\tif (env.TERM === 'dumb') {\n\t\treturn min;\n\t}\n\n\tif (process.platform === 'win32') {\n\t\t// Windows 10 build 10586 is the first Windows release that supports 256 colors.\n\t\t// Windows 10 build 14931 is the first release that supports 16m/TrueColor.\n\t\tconst osRelease = os.release().split('.');\n\t\tif (\n\t\t\tNumber(osRelease[0]) >= 10 &&\n\t\t\tNumber(osRelease[2]) >= 10586\n\t\t) {\n\t\t\treturn Number(osRelease[2]) >= 14931 ? 3 : 2;\n\t\t}\n\n\t\treturn 1;\n\t}\n\n\tif ('CI' in env) {\n\t\tif (['TRAVIS', 'CIRCLECI', 'APPVEYOR', 'GITLAB_CI', 'GITHUB_ACTIONS', 'BUILDKITE'].some(sign => sign in env) || env.CI_NAME === 'codeship') {\n\t\t\treturn 1;\n\t\t}\n\n\t\treturn min;\n\t}\n\n\tif ('TEAMCITY_VERSION' in env) {\n\t\treturn /^(9\\.(0*[1-9]\\d*)\\.|\\d{2,}\\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0;\n\t}\n\n\tif (env.COLORTERM === 'truecolor') {\n\t\treturn 3;\n\t}\n\n\tif ('TERM_PROGRAM' in env) {\n\t\tconst version = parseInt((env.TERM_PROGRAM_VERSION || '').split('.')[0], 10);\n\n\t\tswitch (env.TERM_PROGRAM) {\n\t\t\tcase 'iTerm.app':\n\t\t\t\treturn version >= 3 ? 3 : 2;\n\t\t\tcase 'Apple_Terminal':\n\t\t\t\treturn 2;\n\t\t\t// No default\n\t\t}\n\t}\n\n\tif (/-256(color)?$/i.test(env.TERM)) {\n\t\treturn 2;\n\t}\n\n\tif (/^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(env.TERM)) {\n\t\treturn 1;\n\t}\n\n\tif ('COLORTERM' in env) {\n\t\treturn 1;\n\t}\n\n\treturn min;\n}\n\nfunction getSupportLevel(stream) {\n\tconst level = supportsColor(stream, stream && stream.isTTY);\n\treturn translateLevel(level);\n}\n\nmodule.exports = {\n\tsupportsColor: getSupportLevel,\n\tstdout: translateLevel(supportsColor(true, tty.isatty(1))),\n\tstderr: translateLevel(supportsColor(true, tty.isatty(2)))\n};\n\n\n//# sourceURL=webpack://udan-react/./node_modules/supports-color/index.js?");

/***/ }),

/***/ "./src/config/error-log.ts":
/*!*********************************!*\
  !*** ./src/config/error-log.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"UDAConsoleLogger\": () => (/* binding */ UDAConsoleLogger),\n/* harmony export */   \"UDAErrorLogger\": () => (/* binding */ UDAErrorLogger),\n/* harmony export */   \"UDALog4jsLogger\": () => (/* binding */ UDALog4jsLogger),\n/* harmony export */   \"UDALogLevel\": () => (/* binding */ UDALogLevel)\n/* harmony export */ });\n/* harmony import */ var _modules_authData__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../modules/authData */ \"./src/modules/authData.ts\");\nvar log4js = __webpack_require__(/*! log4js */ \"./node_modules/log4js/lib/log4js.js\");\r\n// import { CONFIG } from './index';\r\n\r\nvar UDALog4jsLogger = log4js.getLogger();\r\nUDALog4jsLogger.level = 'debug'; // log4js.Level.OFF; // do not change this loglevel for performance reasons\r\n// let UDAAjaxAppender = new log4js.AjaxAppender(CONFIG.UDA_DOMAIN+'/logging/error');\r\n// UDAAjaxAppender.setLayout(new Log4js.JSONLayout());\r\n// UDALog4jsLogger.addAppender(UDAAjaxAppender);\r\nvar UDALogLevel = 0;\r\nvar UDAConsoleLogger = {\r\n    info: function (mes, level) {\r\n        if (level === void 0) { level = 1; }\r\n        if (UDALogLevel === level) {\r\n            console.log(mes);\r\n        }\r\n    },\r\n};\r\nvar UDAErrorLogger = {\r\n    error: function (message, exception) {\r\n        message = 'UserID: ' + _modules_authData__WEBPACK_IMPORTED_MODULE_0__.UDAUserAuthData.id + ' Error: ' + message;\r\n        UDALog4jsLogger.error(message, exception);\r\n    },\r\n};\r\n\n\n//# sourceURL=webpack://udan-react/./src/config/error-log.ts?");

/***/ }),

/***/ "./src/header.ts":
/*!***********************!*\
  !*** ./src/header.ts ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _config_error_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./config/error-log */ \"./src/config/error-log.ts\");\n/* harmony import */ var _util_index__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./util/index */ \"./src/util/index.ts\");\n/* harmony import */ var _modules_browserCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./modules/browserCheck */ \"./src/modules/browserCheck.ts\");\nvar _a;\r\n\r\n\r\n// import { UDAUserAuthData } from './modules/authData'\r\n\r\nvar UDABrowserName = _modules_browserCheck__WEBPACK_IMPORTED_MODULE_2__.UDABrowserCheck.detectBrowserNameAndVersion(navigator);\r\nvar UDAAllowedBrowsers = ['chrome', 'edge'];\r\nvar isUDAAllowed = UDAAllowedBrowsers.indexOf((_a = UDABrowserName === null || UDABrowserName === void 0 ? void 0 : UDABrowserName.name) === null || _a === void 0 ? void 0 : _a.toLowerCase());\r\nif (isUDAAllowed < 0) {\r\n    _config_error_log__WEBPACK_IMPORTED_MODULE_0__.UDAConsoleLogger.info('UDA links script not loaded');\r\n}\r\nelse {\r\n    // adding the click object that is registered via javascript\r\n    EventTarget.prototype.addEventListener = (function (addEventListener) {\r\n        var element = this;\r\n        return function () {\r\n            if (arguments[0] === 'click') {\r\n                (0,_util_index__WEBPACK_IMPORTED_MODULE_1__.UDAAddNewElement)(element);\r\n            }\r\n            addEventListener.call(element, arguments[0], arguments[1], arguments[2]);\r\n        };\r\n    })(EventTarget.prototype.addEventListener);\r\n    // starting the mutation observer\r\n    _util_index__WEBPACK_IMPORTED_MODULE_1__.DSA_OBSERVER.observe(document, {\r\n        childList: true,\r\n        subtree: true,\r\n    });\r\n}\r\n\n\n//# sourceURL=webpack://udan-react/./src/header.ts?");

/***/ }),

/***/ "./src/modules/authData.ts":
/*!*********************************!*\
  !*** ./src/modules/authData.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"UDAUserAuthData\": () => (/* binding */ UDAUserAuthData),\n/* harmony export */   \"udaauthdata\": () => (/* binding */ udaauthdata)\n/* harmony export */ });\n/* harmony import */ var _util__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util */ \"./src/util/index.ts\");\n\r\nvar UDAUserAuthData = { id: '', email: '', restrict_add_delete: false, role: 'default', permissions: '' };\r\nvar udaauthdata = {\r\n    set id(val) {\r\n        if (!val)\r\n            return;\r\n        (0,_util__WEBPACK_IMPORTED_MODULE_0__.UDAdigestMessage)(val, \"SHA-512\").then(function (encrypted) {\r\n            UDAUserAuthData.id = encrypted;\r\n            var sessionEvent = new CustomEvent(\"UDAClearSessionData\", { detail: { data: \"clearsession\" }, bubbles: false, cancelable: false });\r\n            document.dispatchEvent(sessionEvent);\r\n        });\r\n    },\r\n    get id() {\r\n        return UDAUserAuthData.id;\r\n    },\r\n    set email(val) {\r\n        (0,_util__WEBPACK_IMPORTED_MODULE_0__.UDAdigestMessage)(val, \"SHA-512\").then(function (encrypted) {\r\n            UDAUserAuthData.email = encrypted;\r\n            var sessionEvent = new CustomEvent(\"UDAClearSessionData\", { detail: { data: \"clearsession\" }, bubbles: false, cancelable: false });\r\n            document.dispatchEvent(sessionEvent);\r\n        });\r\n    },\r\n    get email() {\r\n        return UDAUserAuthData.email;\r\n    },\r\n    set userRole(val) {\r\n        UDAUserAuthData.role = val;\r\n        var sessionEvent = new CustomEvent(\"UDAClearSessionData\", { detail: { data: \"clearsession\" }, bubbles: false, cancelable: false });\r\n        document.dispatchEvent(sessionEvent);\r\n    },\r\n    get userRole() {\r\n        return UDAUserAuthData.role;\r\n    },\r\n    set restrict_add_delete(val) {\r\n        UDAUserAuthData.restrict_add_delete = val;\r\n        var sessionEvent = new CustomEvent(\"UDADisableButton\", { detail: { data: \"UDADisableButton\" }, bubbles: false, cancelable: false });\r\n        document.dispatchEvent(sessionEvent);\r\n    },\r\n    get restrict_add_delete() {\r\n        return UDAUserAuthData.restrict_add_delete;\r\n    },\r\n    set permissions(val) {\r\n        UDAUserAuthData.permissions = val;\r\n    },\r\n    get permissions() {\r\n        return UDAUserAuthData.permissions;\r\n    }\r\n};\r\n\n\n//# sourceURL=webpack://udan-react/./src/modules/authData.ts?");

/***/ }),

/***/ "./src/modules/browserCheck.ts":
/*!*************************************!*\
  !*** ./src/modules/browserCheck.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"UDABrowserCheck\": () => (/* binding */ UDABrowserCheck)\n/* harmony export */ });\nvar UDABrowserCheck = {\r\n    /**\r\n       * Detects Chrome browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isChrome: function (userAgent) {\r\n        return (userAgent.includes('Chrome') &&\r\n            !userAgent.includes('Chromium') &&\r\n            !userAgent.includes('OPR') &&\r\n            !userAgent.includes('Edge') &&\r\n            !userAgent.includes('Edg') &&\r\n            !userAgent.includes('SamsungBrowser'));\r\n    },\r\n    /**\r\n       * Detects Safari browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isSafari: function (userAgent) {\r\n        return (userAgent.includes('Safari') &&\r\n            !userAgent.includes('Chrome') &&\r\n            !userAgent.includes('Chromium') &&\r\n            !userAgent.includes('Edg') &&\r\n            !userAgent.includes('Android'));\r\n    },\r\n    /**\r\n       * Detects UC browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isUCBrowser: function (userAgent) {\r\n        return userAgent.includes('UCBrowser');\r\n    },\r\n    /**\r\n       * Detects Firefox browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isFirefox: function (userAgent) {\r\n        return userAgent.includes('Firefox') && !userAgent.includes('Seamonkey');\r\n    },\r\n    /**\r\n       * Detects IE browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isIE: function (userAgent) {\r\n        return /trident/i.test(userAgent);\r\n    },\r\n    /**\r\n       * Detects Opera browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isOpera: function (userAgent) {\r\n        return userAgent.includes('OPR');\r\n    },\r\n    /**\r\n       * Detects Samsung browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isSamsungInternet: function (userAgent) {\r\n        return userAgent.includes('SamsungBrowser');\r\n    },\r\n    /**\r\n       * Detects Android browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isAndroidBrowser: function (userAgent) {\r\n        return (userAgent.includes('Android') &&\r\n            !userAgent.includes('Chrome') &&\r\n            userAgent.includes('AppleWebKit'));\r\n    },\r\n    /**\r\n       * Detects Edge browser\r\n       * @param {string} userAgent\r\n       * @return {boolean}\r\n       */\r\n    isEdge: function (userAgent) {\r\n        return userAgent.match(/\\b(Edge|Edgios|Edga|Edg)\\/(\\d+)/);\r\n        // return ((userAgent.includes('Edge') || userAgent.includes('Edgeios') || userAgent.includes('Edga') || userAgent.includes('Edg')) && userAgent.includes('Chrome'));\r\n    },\r\n    /**\r\n       * Detects browser name\r\n       * @param {string} userAgent - window.navigator\r\n       * @return {string} browser name\r\n       */\r\n    detectBrowserName: function (userAgent) {\r\n        if (this.isChrome(userAgent))\r\n            return 'Chrome';\r\n        if (this.isSafari(userAgent))\r\n            return 'Safari';\r\n        if (this.isUCBrowser(userAgent))\r\n            return 'UC Browser';\r\n        if (this.isFirefox(userAgent))\r\n            return 'Firefox';\r\n        if (this.isIE(userAgent))\r\n            return 'IE';\r\n        if (this.isOpera(userAgent))\r\n            return 'Opera';\r\n        if (this.isSamsungInternet(userAgent))\r\n            return 'Samsung Internet';\r\n        if (this.isAndroidBrowser(userAgent))\r\n            return 'Android Browser';\r\n        if (this.isEdge(userAgent))\r\n            return 'Edge';\r\n    },\r\n    /**\r\n       * Retrieve browser version\r\n       * @param {string} name\r\n       * @param {string} str\r\n       * @return {number} browser version\r\n       */\r\n    retrieveVersion: function (name, str) {\r\n        name = name + '/';\r\n        var start = str.indexOf(name);\r\n        var preNum = str.substring(start + name.length);\r\n        var index = preNum.indexOf(' ');\r\n        if (index > 0)\r\n            preNum = preNum.substring(0, index);\r\n        var end;\r\n        if (preNum.indexOf('.', 2) > 0) {\r\n            end = preNum.indexOf('.', 2);\r\n        }\r\n        else {\r\n            end = preNum.indexOf('.', 1);\r\n        }\r\n        var num = preNum.substring(0, end);\r\n        return Number(num);\r\n    },\r\n    /**\r\n       * Returns Association\r\n       * @param {string} name\r\n       * @return {string} browser name\r\n       */\r\n    getBeautifulName: function (name) {\r\n        var browserName;\r\n        switch (name) {\r\n            case 'Opera':\r\n                browserName = 'OPR';\r\n                break;\r\n            case 'UC Browser':\r\n                browserName = 'UCBrowser';\r\n                break;\r\n            case 'Samsung Internet':\r\n                browserName = 'SamsungBrowser';\r\n                break;\r\n        }\r\n        return browserName;\r\n    },\r\n    /**\r\n       * Detects browser version\r\n       * @param {object} nav\r\n       * @param {string} name\r\n       * @return {number} browser version\r\n       */\r\n    detectBrowserVersion: function (nav, name) {\r\n        var userAgent = nav.userAgent;\r\n        switch (name) {\r\n            case 'IE': {\r\n                var _temp1 = /\\brv[ :]+(\\d+)/g.exec(userAgent) || [];\r\n                return Number(_temp1[1]) || null;\r\n            }\r\n            case 'Edge': {\r\n                var _temp2 = userAgent.match(/\\b(Edge|Edgios|Edga|Edg)\\/(\\d+)/);\r\n                return Number(_temp2[2]);\r\n            }\r\n        }\r\n        var browserName = this.getBeautifulName(name);\r\n        if (browserName)\r\n            return this.retrieveVersion(browserName, userAgent);\r\n        var found = userAgent.match(/(opera|chrome|safari|firefox|msie|trident(?=\\/))\\/?\\s*(\\d+)/i) || [];\r\n        found = found[2] ?\r\n            [found[1], found[2]] :\r\n            [nav.appName, nav.appVersion, '-?'];\r\n        var temp;\r\n        if ((temp = userAgent.match(/version\\/(\\d+)/i)) !== null) {\r\n            found.splice(1, 1, temp[1]);\r\n        }\r\n        return Number(found[1]);\r\n    },\r\n    /**\r\n       * Detects browser name & version\r\n       * @param {object} nav\r\n       * @return {object} browser name & version\r\n       */\r\n    detectBrowserNameAndVersion: function (nav) {\r\n        var name = this.detectBrowserName(nav.userAgent);\r\n        if (!name)\r\n            return { name: 'unknown', version: 'unknown' };\r\n        return {\r\n            name: name,\r\n            version: this.detectBrowserVersion(nav, name),\r\n        };\r\n    },\r\n};\r\n\n\n//# sourceURL=webpack://udan-react/./src/modules/browserCheck.ts?");

/***/ }),

/***/ "./src/util/index.ts":
/*!***************************!*\
  !*** ./src/util/index.ts ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DSA_OBSERVER\": () => (/* binding */ DSA_OBSERVER),\n/* harmony export */   \"UDAAddNewElement\": () => (/* binding */ UDAAddNewElement),\n/* harmony export */   \"UDAProcessNode\": () => (/* binding */ UDAProcessNode),\n/* harmony export */   \"UDAProcessRemovedNode\": () => (/* binding */ UDAProcessRemovedNode),\n/* harmony export */   \"UDAdigestMessage\": () => (/* binding */ UDAdigestMessage)\n/* harmony export */ });\n/* harmony import */ var _config_error_log__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../config/error-log */ \"./src/config/error-log.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\nvar __generator = (undefined && undefined.__generator) || function (thisArg, body) {\r\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n    function verb(n) { return function (v) { return step([n, v]); }; }\r\n    function step(op) {\r\n        if (f) throw new TypeError(\"Generator is already executing.\");\r\n        while (_) try {\r\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n            if (y = 0, t) op = [op[0] & 2, t.value];\r\n            switch (op[0]) {\r\n                case 0: case 1: t = op; break;\r\n                case 4: _.label++; return { value: op[1], done: false };\r\n                case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                default:\r\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                    if (t[2]) _.ops.pop();\r\n                    _.trys.pop(); continue;\r\n            }\r\n            op = body.call(thisArg, _);\r\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n    }\r\n};\r\n\r\nvar UDAClickObjects = [];\r\nvar UDARemovedClickObjects = [];\r\n// adding the clickobjects that were identified.\r\nfunction UDAAddNewElement(node) {\r\n    try {\r\n        var clickObject = { element: node };\r\n        // checking whether the element is window or not\r\n        if (clickObject.element === window) {\r\n            return;\r\n        }\r\n        var tag = clickObject.element.tagName;\r\n        if (tag &&\r\n            (tag.toLowerCase() === 'body' ||\r\n                tag.toLowerCase() === 'document' ||\r\n                tag.toLowerCase() === 'window' ||\r\n                tag.toLowerCase() === 'html')) {\r\n            return;\r\n        }\r\n        if (clickObject.element.hasAttribute &&\r\n            clickObject.element.hasAttribute('nist-voice')) {\r\n            return;\r\n        }\r\n        for (var _i = 0, UDAClickObjects_1 = UDAClickObjects; _i < UDAClickObjects_1.length; _i++) {\r\n            var i = UDAClickObjects_1[_i];\r\n            if (i.isSameNode(clickObject.element)) {\r\n                // todo, discuss , how better to call actions, if multiple actions should be stored, or selector better.\r\n                return;\r\n            }\r\n        }\r\n        clickObject.id = UDAClickObjects.length;\r\n        UDAClickObjects.push(clickObject);\r\n    }\r\n    catch (e) {\r\n        var htmlelement = node.innerHTML;\r\n        _config_error_log__WEBPACK_IMPORTED_MODULE_0__.UDAErrorLogger.error('Unable to process clickable object - ' + htmlelement, e);\r\n    }\r\n}\r\n// processing node from mutation and then send to clickbojects addition\r\nfunction UDAProcessNode(node) {\r\n    var _a;\r\n    var processchildren = true;\r\n    if (node.onclick != undefined) {\r\n        UDAAddNewElement(node);\r\n    }\r\n    // switched to switch case condition from if condition\r\n    if (node.tagName) {\r\n        switch (node.tagName.toLowerCase()) {\r\n            case 'a':\r\n                if (node instanceof HTMLAnchorElement && (node === null || node === void 0 ? void 0 : node.href) !== undefined) {\r\n                    UDAAddNewElement(node);\r\n                }\r\n                break;\r\n            case 'input':\r\n            case 'textarea':\r\n            case 'option':\r\n            case 'select':\r\n                UDAAddNewElement(node);\r\n                break;\r\n            case 'button':\r\n                if (node.hasAttribute('ng-click') || node.hasAttribute('onclick')) {\r\n                    UDAAddNewElement(node);\r\n                }\r\n                else if (node.hasAttribute('type') &&\r\n                    node.getAttribute('type') === 'submit') {\r\n                    UDAAddNewElement(node);\r\n                }\r\n                else if (node.classList &&\r\n                    (node.classList.contains('expand-button') ||\r\n                        node.classList.contains('btn-pill'))) {\r\n                    UDAAddNewElement(node);\r\n                }\r\n                else {\r\n                    _config_error_log__WEBPACK_IMPORTED_MODULE_0__.UDAConsoleLogger.info({ node: node });\r\n                }\r\n                break;\r\n            case 'span':\r\n                if (node.classList && node.classList.contains('select2-selection')) {\r\n                    UDAAddNewElement(node);\r\n                }\r\n                else if (node.hasAttribute('ng-click') ||\r\n                    node.hasAttribute('onclick')) {\r\n                    UDAAddNewElement(node);\r\n                }\r\n                break;\r\n            // fix for editor issue\r\n            case 'ckeditor':\r\n                UDAAddNewElement(node);\r\n                break;\r\n            case 'div':\r\n                if (node.hasAttribute('ng-click') || node.hasAttribute('onclick')) {\r\n                    UDAAddNewElement(node);\r\n                }\r\n                break;\r\n        }\r\n    }\r\n    if (node.classList && node.classList.contains('dropdown-toggle')) {\r\n        UDAAddNewElement(node);\r\n    }\r\n    if (node.children && ((_a = node === null || node === void 0 ? void 0 : node.children) === null || _a === void 0 ? void 0 : _a.length) && processchildren) {\r\n        for (var _i = 0, _b = Array.from(node === null || node === void 0 ? void 0 : node.children); _i < _b.length; _i++) {\r\n            var i = _b[_i];\r\n            UDAProcessNode(i);\r\n        }\r\n    }\r\n}\r\n// removal of clickbojects via mutation observer\r\nfunction UDAProcessRemovedNode(node) {\r\n    var _index = 0;\r\n    for (var _i = 0, UDAClickObjects_2 = UDAClickObjects; _i < UDAClickObjects_2.length; _i++) {\r\n        var j = UDAClickObjects_2[_i];\r\n        if (node.isEqualNode(j)) {\r\n            var addtoremovenodes = true;\r\n            // removedclickobjectcounter:\r\n            for (var _a = 0, UDARemovedClickObjects_1 = UDARemovedClickObjects; _a < UDARemovedClickObjects_1.length; _a++) {\r\n                var k = UDARemovedClickObjects_1[_a];\r\n                if (node.isEqualNode(k)) {\r\n                    addtoremovenodes = false;\r\n                    break;\r\n                }\r\n            }\r\n            if (addtoremovenodes) {\r\n                UDARemovedClickObjects.push(j);\r\n            }\r\n            UDAClickObjects.splice(_index, 1);\r\n            _index++;\r\n            break;\r\n        }\r\n    }\r\n    if (node.children) {\r\n        for (var _b = 0, _c = node.children; _b < _c.length; _b++) {\r\n            var i = _c[_b];\r\n            UDAProcessRemovedNode(i);\r\n        }\r\n    }\r\n}\r\nfunction UDAdigestMessage(textmessage, algorithm) {\r\n    return __awaiter(this, void 0, void 0, function () {\r\n        var encoder, data, hash, hashArray, hashHex;\r\n        return __generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    encoder = new TextEncoder();\r\n                    data = encoder.encode(textmessage);\r\n                    return [4 /*yield*/, crypto.subtle.digest(algorithm, data)];\r\n                case 1:\r\n                    hash = _a.sent();\r\n                    hashArray = Array.from(new Uint8Array(hash));\r\n                    hashHex = hashArray\r\n                        .map(function (b) { return b.toString(16).padStart(2, '0'); })\r\n                        .join('');\r\n                    return [2 /*return*/, hashHex];\r\n            }\r\n        });\r\n    });\r\n}\r\n// mutation observer initialization and adding the logic to process the clickobjects\r\nvar DSA_OBSERVER = new MutationObserver(function (mutations) {\r\n    // UDAConsoleLogger.info('------------ detected clicked objects-------------');\r\n    // UDAConsoleLogger.info(UDAClickObjects);\r\n    mutations.forEach(function (mutation) {\r\n        if (mutation.removedNodes.length) {\r\n            [].some.call(mutation.removedNodes, UDAProcessRemovedNode);\r\n        }\r\n        if (!mutation.addedNodes.length) {\r\n            return;\r\n        }\r\n        [].some.call(mutation.addedNodes, UDAProcessNode);\r\n    });\r\n    // UDAConsoleLogger.info('------------ removed clicked objects-------------');\r\n    // UDAConsoleLogger.info(UDAClickObjects);\r\n    UDALastMutationTime = Date.now();\r\n});\r\n\n\n//# sourceURL=webpack://udan-react/./src/util/index.ts?");

/***/ }),

/***/ "./node_modules/universalify/index.js":
/*!********************************************!*\
  !*** ./node_modules/universalify/index.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.fromCallback = function (fn) {\n  return Object.defineProperty(function (...args) {\n    if (typeof args[args.length - 1] === 'function') fn.apply(this, args)\n    else {\n      return new Promise((resolve, reject) => {\n        fn.call(\n          this,\n          ...args,\n          (err, res) => (err != null) ? reject(err) : resolve(res)\n        )\n      })\n    }\n  }, 'name', { value: fn.name })\n}\n\nexports.fromPromise = function (fn) {\n  return Object.defineProperty(function (...args) {\n    const cb = args[args.length - 1]\n    if (typeof cb !== 'function') return fn.apply(this, args)\n    else fn.apply(this, args.slice(0, -1)).then(r => cb(null, r), cb)\n  }, 'name', { value: fn.name })\n}\n\n\n//# sourceURL=webpack://udan-react/./node_modules/universalify/index.js?");

/***/ }),

/***/ "assert":
/*!*************************!*\
  !*** external "assert" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("assert");

/***/ }),

/***/ "cluster":
/*!**************************!*\
  !*** external "cluster" ***!
  \**************************/
/***/ ((module) => {

"use strict";
module.exports = require("cluster");

/***/ }),

/***/ "constants":
/*!****************************!*\
  !*** external "constants" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("constants");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("fs");

/***/ }),

/***/ "net":
/*!**********************!*\
  !*** external "net" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("net");

/***/ }),

/***/ "os":
/*!*********************!*\
  !*** external "os" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("os");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("path");

/***/ }),

/***/ "stream":
/*!*************************!*\
  !*** external "stream" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("stream");

/***/ }),

/***/ "tty":
/*!**********************!*\
  !*** external "tty" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("tty");

/***/ }),

/***/ "url":
/*!**********************!*\
  !*** external "url" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("url");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("util");

/***/ }),

/***/ "zlib":
/*!***********************!*\
  !*** external "zlib" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("zlib");

/***/ }),

/***/ "./node_modules/flatted/cjs/index.js":
/*!*******************************************!*\
  !*** ./node_modules/flatted/cjs/index.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n/*! (c) 2020 Andrea Giammarchi */\n\nconst {parse: $parse, stringify: $stringify} = JSON;\nconst {keys} = Object;\n\nconst Primitive = String;   // it could be Number\nconst primitive = 'string'; // it could be 'number'\n\nconst ignore = {};\nconst object = 'object';\n\nconst noop = (_, value) => value;\n\nconst primitives = value => (\n  value instanceof Primitive ? Primitive(value) : value\n);\n\nconst Primitives = (_, value) => (\n  typeof value === primitive ? new Primitive(value) : value\n);\n\nconst revive = (input, parsed, output, $) => {\n  const lazy = [];\n  for (let ke = keys(output), {length} = ke, y = 0; y < length; y++) {\n    const k = ke[y];\n    const value = output[k];\n    if (value instanceof Primitive) {\n      const tmp = input[value];\n      if (typeof tmp === object && !parsed.has(tmp)) {\n        parsed.add(tmp);\n        output[k] = ignore;\n        lazy.push({k, a: [input, parsed, tmp, $]});\n      }\n      else\n        output[k] = $.call(output, k, tmp);\n    }\n    else if (output[k] !== ignore)\n      output[k] = $.call(output, k, value);\n  }\n  for (let {length} = lazy, i = 0; i < length; i++) {\n    const {k, a} = lazy[i];\n    output[k] = $.call(output, k, revive.apply(null, a));\n  }\n  return output;\n};\n\nconst set = (known, input, value) => {\n  const index = Primitive(input.push(value) - 1);\n  known.set(value, index);\n  return index;\n};\n\nconst parse = (text, reviver) => {\n  const input = $parse(text, Primitives).map(primitives);\n  const value = input[0];\n  const $ = reviver || noop;\n  const tmp = typeof value === object && value ?\n              revive(input, new Set, value, $) :\n              value;\n  return $.call({'': tmp}, '', tmp);\n};\nexports.parse = parse;\n\nconst stringify = (value, replacer, space) => {\n  const $ = replacer && typeof replacer === object ?\n            (k, v) => (k === '' || -1 < replacer.indexOf(k) ? v : void 0) :\n            (replacer || noop);\n  const known = new Map;\n  const input = [];\n  const output = [];\n  let i = +set(known, input, $.call({'': value}, '', value));\n  let firstRun = !i;\n  while (i < input.length) {\n    firstRun = true;\n    output[i] = $stringify(input[i++], replace, space);\n  }\n  return '[' + output.join(',') + ']';\n  function replace(key, value) {\n    if (firstRun) {\n      firstRun = !firstRun;\n      return value;\n    }\n    const after = $.call(this, key, value);\n    switch (typeof after) {\n      case object:\n        if (after === null) return after;\n      case primitive:\n        return known.get(after) || set(known, input, after);\n    }\n    return after;\n  }\n};\nexports.stringify = stringify;\n\nconst toJSON = any => $parse(stringify(any));\nexports.toJSON = toJSON;\nconst fromJSON = any => parse($stringify(any));\nexports.fromJSON = fromJSON;\n\n\n//# sourceURL=webpack://udan-react/./node_modules/flatted/cjs/index.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = __webpack_module_cache__;
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// module cache are used so entry inlining is disabled
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	var __webpack_exports__ = __webpack_require__(__webpack_require__.s = "./src/header.ts");
/******/ 	
/******/ })()
;